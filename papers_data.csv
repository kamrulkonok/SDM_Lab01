field_query,paperId,title,url,venue,publicationTypes,abstract,year,citationCount,journal_name,journal_volume,journal_pages
NLP,29ddc1f43f28af7c846515e32cc167bc66886d0c,Parameter-Efficient Transfer Learning for NLP,https://www.semanticscholar.org/paper/29ddc1f43f28af7c846515e32cc167bc66886d0c,International Conference on Machine Learning,"['JournalArticle', 'Conference']","Fine-tuning large pre-trained models is an effective transfer mechanism in NLP. However, in the presence of many downstream tasks, fine-tuning is parameter inefficient: an entire new model is required for every task. As an alternative, we propose transfer with adapter modules. Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task, and new tasks can be added without revisiting previous ones. The parameters of the original network remain fixed, yielding a high degree of parameter sharing. To demonstrate adapter's effectiveness, we transfer the recently proposed BERT Transformer model to 26 diverse text classification tasks, including the GLUE benchmark. Adapters attain near state-of-the-art performance, whilst adding only a few parameters per task. On GLUE, we attain within 0.4% of the performance of full fine-tuning, adding only 3.6% parameters per task. By contrast, fine-tuning trains 100% of the parameters per task.",2019,2341,ArXiv,abs/1902.00751,
NLP,d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea,Energy and Policy Considerations for Deep Learning in NLP,https://www.semanticscholar.org/paper/d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",2019,2080,ArXiv,abs/1906.02243,
NLP,58ed1fbaabe027345f7bb3a6312d41c5aac63e22,Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks,https://www.semanticscholar.org/paper/58ed1fbaabe027345f7bb3a6312d41c5aac63e22,Neural Information Processing Systems,['JournalArticle'],"Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.",2020,1587,ArXiv,abs/2005.11401,
NLP,06d7cb8c8816360feb33c3367073e0ef66d7d0b0,Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks,https://www.semanticscholar.org/paper/06d7cb8c8816360feb33c3367073e0ef66d7d0b0,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions—training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones.Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.",2022,408,,,5085-5109
NLP,5471114e37448bea2457b74894b1ecb92bbcfdf6,From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models,https://www.semanticscholar.org/paper/5471114e37448bea2457b74894b1ecb92bbcfdf6,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Language models (LMs) are pretrained on diverse data sources—news, discussion forums, books, online encyclopedias. A significant portion of this data includes facts and opinions which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure media biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.",2023,62,ArXiv,abs/2305.08283,
NLP,33ec7eb2168e37e3007d1059aa96b9a63254b4da,Beyond Accuracy: Behavioral Testing of NLP Models with CheckList,https://www.semanticscholar.org/paper/33ec7eb2168e37e3007d1059aa96b9a63254b4da,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a task-agnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.",2020,859,,,4902-4912
NLP,13c4e5a6122f3fa2663f63e49537091da6532f35,Are NLP Models really able to Solve Simple Math Word Problems?,https://www.semanticscholar.org/paper/13c4e5a6122f3fa2663f63e49537091da6532f35,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","The problem of designing NLP solvers for math word problems (MWP) has seen sustained research activity and steady gains in the test accuracy. Since existing solvers achieve high performance on the benchmark datasets for elementary level MWPs containing one-unknown arithmetic word problems, such problems are often considered “solved” with the bulk of research attention moving to more complex MWPs. In this paper, we restrict our attention to English MWPs taught in grades four and lower. We provide strong evidence that the existing MWP solvers rely on shallow heuristics to achieve high performance on the benchmark datasets. To this end, we show that MWP solvers that do not have access to the question asked in the MWP can still solve a large fraction of MWPs. Similarly, models that treat MWPs as bag-of-words can also achieve surprisingly high accuracy. Further, we introduce a challenge dataset, SVAMP, created by applying carefully chosen variations over examples sampled from existing datasets. The best accuracy achieved by state-of-the-art models is substantially lower on SVAMP, thus showing that much remains to be done even for the simplest of the MWPs.",2021,374,,,2080-2094
NLP,97906df07855b029b7aae7c2a1c6c5e8df1d531c,BERT Rediscovers the Classical NLP Pipeline,https://www.semanticscholar.org/paper/97906df07855b029b7aae7c2a1c6c5e8df1d531c,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.",2019,1180,,,4593-4601
NLP,63d8426ba1f51a8525dd19fd8ec92934ec71aea5,A Survey of Data Augmentation Approaches for NLP,https://www.semanticscholar.org/paper/63d8426ba1f51a8525dd19fd8ec92934ec71aea5,Findings,"['JournalArticle', 'Review']","Data augmentation has recently seen increased interest in NLP due to more work in low-resource domains, new tasks, and the popularity of large-scale neural networks that require large amounts of training data. Despite this recent upsurge, this area is still relatively underexplored, perhaps due to the challenges posed by the discrete nature of language data. In this paper, we present a comprehensive and unifying survey of data augmentation for NLP by summarizing the literature in a structured manner. We first introduce and motivate data augmentation for NLP, and then discuss major methodologically representative approaches. Next, we highlight techniques that are used for popular NLP applications and tasks. We conclude by outlining current challenges and directions for future research. Overall, our paper aims to clarify the landscape of existing literature in data augmentation for NLP and motivate additional work in this area. We also present a GitHub repository with a paper list that will be continuously updated at https://github.com/styfeng/DataAug4NLP",2021,540,,,968-988
NLP,f4c4e148546089123f8da5db4fb246ab4062bd40,Evaluation of ChatGPT for NLP-based Mental Health Applications,https://www.semanticscholar.org/paper/f4c4e148546089123f8da5db4fb246ab4062bd40,arXiv.org,['JournalArticle'],"Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research. In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification). We obtained annotated social media posts for the three classification tasks from public datasets. Then ChatGPT API classified the social media posts with an input prompt for classification. We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively. A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a potential use of language models for mental health classification tasks.",2023,32,ArXiv,abs/2303.15727,
NLP,0d065e8688c38bb0148203a1738f47184a5b58d3,ChatGPT: Unlocking the Future of NLP in Finance,https://www.semanticscholar.org/paper/0d065e8688c38bb0148203a1738f47184a5b58d3,Social Science Research Network,"['JournalArticle', 'Review']","This paper reviews the current state of ChatGPT technology in finance and its potential to improve existing NLP-based financial applications. We discuss the ethical and regulatory considerations, as well as potential future research directions in the field. The literature suggests that ChatGPT has the potential to improve NLP-based financial applications, but also raises ethical and regulatory concerns that need to be addressed. The paper highlights the need for research in robustness, interpretability, and ethical considerations to ensure responsible use of ChatGPT technology in finance.",2023,34,SSRN Electronic Journal,,
NLP,d47a682723f710395454687319bb55635e653105,Language (Technology) is Power: A Critical Survey of “Bias” in NLP,https://www.semanticscholar.org/paper/d47a682723f710395454687319bb55635e653105,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","We survey 146 papers analyzing “bias” in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing “bias” is an inherently normative process. We further find that these papers’ proposed quantitative techniques for measuring or mitigating “bias” are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing “bias” in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of “bias”---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements—and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.",2020,820,ArXiv,abs/2005.14050,
NLP,c9b56cb026a38e39bb0228faac57accd6f65e6f7,"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP",https://www.semanticscholar.org/paper/c9b56cb026a38e39bb0228faac57accd6f65e6f7,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference', 'Review']","While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack’s modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness.TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack.",2020,511,,,119-126
NLP,0e141942fa265142f41a2a26eb17b6005d3af29e,The State and Fate of Linguistic Diversity and Inclusion in the NLP World,https://www.semanticscholar.org/paper/0e141942fa265142f41a2a26eb17b6005d3af29e,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the “language agnostic” status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.",2020,523,,,6282-6293
NLP,579476d19566efc842929ea6bdd18ab760c8cfa2,Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?,https://www.semanticscholar.org/paper/579476d19566efc842929ea6bdd18ab760c8cfa2,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is “defined” by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.",2020,399,,,4198-4205
NLP,4fcfe83c05402b5c5fb6e853082e74af6379d7f9,"Missing Information, Unresponsive Authors, Experimental Flaws: The Impossibility of Assessing the Reproducibility of Previous Human Evaluations in NLP",https://www.semanticscholar.org/paper/4fcfe83c05402b5c5fb6e853082e74af6379d7f9,First Workshop on Insights from Negative Results in NLP,['JournalArticle'],"We report our efforts in identifying a set of previous human evaluations in NLP that would be suitable for a coordinated study examining what makes human evaluations in NLP more/less reproducible. We present our results and findings, which include that just 13% of papers had (i) sufficiently low barriers to reproduction, and (ii) enough obtainable information, to be considered for reproduction, and that all but one of the experiments we selected for reproduction was discovered to have flaws that made the meaningfulness of conducting a reproduction questionable. As a result, we had to change our coordinated study design from a reproduce approach to a standardise-then-reproduce-twice approach. Our overall (negative) finding that the great majority of human evaluations in NLP is not repeatable and/or not reproducible and/or too flawed to justify reproduction, paints a dire picture, but presents an opportunity for a rethink about how to design and report human evaluations in NLP.",2023,19,ArXiv,abs/2305.01633,
NLP,83cebf919635504786fc220d569284842b0f0a09,A Survey of Adversarial Defenses and Robustness in NLP,https://www.semanticscholar.org/paper/83cebf919635504786fc220d569284842b0f0a09,ACM Computing Surveys,"['JournalArticle', 'Review']","In the past few years, it has become increasingly evident that deep neural networks are not resilient enough to withstand adversarial perturbations in input data, leaving them vulnerable to attack. Various authors have proposed strong adversarial attacks for computer vision and Natural Language Processing (NLP) tasks. As a response, many defense mechanisms have also been proposed to prevent these networks from failing. The significance of defending neural networks against adversarial attacks lies in ensuring that the model’s predictions remain unchanged even if the input data is perturbed. Several methods for adversarial defense in NLP have been proposed, catering to different NLP tasks such as text classification, named entity recognition, and natural language inference. Some of these methods not only defend neural networks against adversarial attacks but also act as a regularization mechanism during training, saving the model from overfitting. This survey aims to review the various methods proposed for adversarial defenses in NLP over the past few years by introducing a novel taxonomy. The survey also highlights the fragility of advanced deep neural networks in NLP and the challenges involved in defending them.",2023,16,ACM Computing Surveys,55,1 - 39
NLP,77a096d80eb4dd4ccd103d1660c5a5498f7d026b,Dynabench: Rethinking Benchmarking in NLP,https://www.semanticscholar.org/paper/77a096d80eb4dd4ccd103d1660c5a5498f7d026b,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","We introduce Dynabench, an open-source platform for dynamic dataset creation and model benchmarking. Dynabench runs in a web browser and supports human-and-model-in-the-loop dataset creation: annotators seek to create examples that a target model will misclassify, but that another person will not. In this paper, we argue that Dynabench addresses a critical need in our community: contemporary models quickly achieve outstanding performance on benchmark tasks but nonetheless fail on simple challenge examples and falter in real-world scenarios. With Dynabench, dataset creation, model development, and model assessment can directly inform each other, leading to more robust and informative benchmarks. We report on four initial NLP tasks, illustrating these concepts and highlighting the promise of the platform, and address potential objections to dynamic benchmarking as a new standard for the field.",2021,255,ArXiv,abs/2104.14337,
NLP,03532123ccffae8d411264320e8a5ae2b6eddea0,Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP,https://www.semanticscholar.org/paper/03532123ccffae8d411264320e8a5ae2b6eddea0,arXiv.org,['JournalArticle'],"Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM). Existing work has combined these in simple""retrieve-then-read""pipelines in which the RM retrieves passages that are inserted into the LM prompt. To begin to fully realize the potential of frozen LMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM. DSP can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the LM and RM can handle more reliably. We have written novel DSP programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art in-context learning results and delivering 37-120%, 8-39%, and 80-290% relative gains against the vanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a contemporaneous self-ask pipeline, respectively. We release DSP at https://github.com/stanfordnlp/dsp",2022,118,ArXiv,abs/2212.14024,
NLP,087dd95e13efd47aef2a6582e6801b39fc0f83d8,ERASER: A Benchmark to Evaluate Rationalized NLP Models,https://www.semanticscholar.org/paper/087dd95e13efd47aef2a6582e6801b39fc0f83d8,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the ‘reasoning’ behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER a benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of “rationales” (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/",2019,456,,,4443-4458
NLP,3a7bbc46795929f0eace82b64c44c92a48682fb5,FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP,https://www.semanticscholar.org/paper/3a7bbc46795929f0eace82b64c44c92a48682fb5,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","We present FLAIR, an NLP framework designed to facilitate training and distribution of state-of-the-art sequence labeling, text classification and language models. The core idea of the framework is to present a simple, unified interface for conceptually very different types of word and document embeddings. This effectively hides all embedding-specific engineering complexity and allows researchers to “mix and match” various embeddings with little effort. The framework also implements standard model training and hyperparameter selection routines, as well as a data fetching module that can download publicly available NLP datasets and convert them into data structures for quick set up of experiments. Finally, FLAIR also ships with a “model zoo” of pre-trained models to allow researchers to use state-of-the-art NLP models in their applications. This paper gives an overview of the framework and its functionality. The framework is available on GitHub at https://github.com/zalandoresearch/flair .",2019,670,,,54-59
NLP,a747e8f2659df479c0092301b9658fc582423df1,"One Country, 700+ Languages: NLP Challenges for Underrepresented Languages and Dialects in Indonesia",https://www.semanticscholar.org/paper/a747e8f2659df479c0092301b9658fc582423df1,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","NLP research is impeded by a lack of resources and awareness of the challenges presented by underrepresented languages and dialects. Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia’s 700+ languages. We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems. Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia but also other underrepresented languages.",2022,52,ArXiv,abs/2203.13357,
NLP,598231eb906b183f7a2a408ef4536127e11e3de9,Challenges and Strategies in Cross-Cultural NLP,https://www.semanticscholar.org/paper/598231eb906b183f7a2a408ef4536127e11e3de9,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.",2022,66,ArXiv,abs/2203.10020,
NLP,ce9ca56036307217ea565644d3d3bd74b879e045,Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP,https://www.semanticscholar.org/paper/ce9ca56036307217ea565644d3d3bd74b879e045,Transactions of the Association for Computational Linguistics,['JournalArticle'],"Abstract ⚠ This paper contains prompts and model outputs that are offensive in nature. When trained on large, unfiltered crawls from the Internet, language models pick up and reproduce all kinds of undesirable biases that can be found in the data: They often generate racist, sexist, violent, or otherwise toxic language. As large models require millions of training examples to achieve good performance, it is difficult to completely prevent them from being exposed to such content. In this paper, we first demonstrate a surprising finding: Pretrained language models recognize, to a considerable degree, their undesirable biases and the toxicity of the content they produce. We refer to this capability as self-diagnosis. Based on this finding, we then propose a decoding algorithm that, given only a textual description of the undesired behavior, reduces the probability of a language model producing problematic text. We refer to this approach as self-debiasing. Self-debiasing does not rely on manually curated word lists, nor does it require any training data or changes to the model’s parameters. While we by no means eliminate the issue of language models generating biased text, we believe our approach to be an important step in this direction.1",2021,239,Transactions of the Association for Computational Linguistics,9,1408-1424
NLP,808e9ce4e86e79098edea7f00b5b91663b87a5e6,A taxonomy and review of generalization research in NLP,https://www.semanticscholar.org/paper/808e9ce4e86e79098edea7f00b5b91663b87a5e6,Nature Machine Intelligence,"['JournalArticle', 'Review']",,2022,48,Nature Machine Intelligence,5,1161 - 1174
NLP,be7cb8f79bc018e57467168fc0c7f8ad59bba04f,Adaptive Testing and Debugging of NLP Models,https://www.semanticscholar.org/paper/be7cb8f79bc018e57467168fc0c7f8ad59bba04f,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Current approaches to testing and debugging NLP models rely on highly variable human creativity and extensive labor, or only work for a very restrictive class of bugs. We present AdaTest, a process which uses large scale language models (LMs) in partnership with human feedback to automatically write unit tests highlighting bugs in a target model. Such bugs are then addressed through an iterative text-fix-retest loop, inspired by traditional software development. In experiments with expert and non-expert users and commercial / research models for 8 different tasks, AdaTest makes users 5-10x more effective at finding bugs than current approaches, and helps users effectively fix bugs without adding new bugs.",2022,53,,,3253-3267
NLP,08aaaf7ae3d61875e7bcf5c1bb0df4f17066e300,Piccolo: Exposing Complex Backdoors in NLP Transformer Models,https://www.semanticscholar.org/paper/08aaaf7ae3d61875e7bcf5c1bb0df4f17066e300,IEEE Symposium on Security and Privacy,['JournalArticle'],"Backdoors can be injected to NLP models such that they misbehave when the trigger words or sentences appear in an input sample. Detecting such backdoors given only a subject model and a small number of benign samples is very challenging because of the unique nature of NLP applications, such as the discontinuity of pipeline and the large search space. Existing techniques work well for backdoors with simple triggers such as single character/word triggers but become less effective when triggers and models become complex (e.g., transformer models). We propose a new backdoor scanning technique. It transforms a subject model to an equivalent but differentiable form. It then uses optimization to invert a distribution of words denoting their likelihood in the trigger. It leverages a novel word discriminativity analysis to determine if the subject model is particularly discriminative for the presence of likely trigger words. Our evaluation on 3839 NLP models from the TrojAI competition and existing works with 7 state-of-art complex structures such as BERT and GPT, and 17 different attack types including two latest dynamic attacks, shows that our technique is highly effective, achieving over 0.9 detection accuracy in most scenarios and substantially outperforming two state-of-the-art scanners. Our submissions to TrojAI leaderboard achieve top performance in 2 out of the 3 rounds for NLP backdoor scanning.",2022,38,2022 IEEE Symposium on Security and Privacy (SP),,2025-2042
NLP,18a1c21f35153c45d0ef30c564bffb7d70a13ccc,Universal Adversarial Triggers for Attacking and Analyzing NLP,https://www.semanticscholar.org/paper/18a1c21f35153c45d0ef30c564bffb7d70a13ccc,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94% to 0.55%, 72% of “why” questions in SQuAD to be answered “to kill american people”, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.",2019,618,,,2153-2162
NLP,011095a0082e5e301f9bf30267b193c1c9e7e370,Perturbation Augmentation for Fairer NLP,https://www.semanticscholar.org/paper/011095a0082e5e301f9bf30267b193c1c9e7e370,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask whether training on demographically perturbed data leads to fairer language models. We collect a large dataset of human annotated text perturbations and train a neural perturbation model, which we show outperforms heuristic alternatives. We find that (i) language models (LMs) pre-trained on demographically perturbed corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE datasets exhibit less demographic bias on downstream tasks, and (iii) fairness improvements do not come at the expense of performance on downstream tasks. Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models. We hope that this exploration of neural demographic perturbation will help drive more improvement towards fairer NLP.",2022,33,,,9496-9521
NLP,d235a9085e0543fcbe502fbc269f9a8ee01dcbab,AdaPrompt: Adaptive Model Training for Prompt-based NLP,https://www.semanticscholar.org/paper/d235a9085e0543fcbe502fbc269f9a8ee01dcbab,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Prompt-based learning, with its capability to tackle zero-shot and few-shot NLP tasks, has gained much attention in community. The main idea is to bridge the gap between NLP downstream tasks and language modeling (LM), by mapping these tasks into natural language prompts, which are then filled by pre-trained language models (PLMs). However, for prompt learning, there are still two salient gaps between NLP tasks and pretraining. First, prompt information is not necessarily sufficiently present during LM pretraining. Second, task-specific data are not necessarily well represented during pretraining. We address these two issues by proposing AdaPrompt, adaptively retrieving external data for continual pretraining of PLMs by making use of both task and prompt characteristics. In addition, we make use of knowledge in Natural Language Inference models for deriving adaptive verbalizers. Experimental results on five NLP benchmarks show that AdaPrompt can improve over standard PLMs in few-shot settings. In addition, in zero-shot settings, our method outperforms standard prompt-based methods by up to 26.35\% relative error reduction.",2022,32,ArXiv,abs/2202.04824,
NLP,b651d67502790e1d6d41c589e1d93e996ba7b935,Pretrained Biomedical Language Models for Clinical NLP in Spanish,https://www.semanticscholar.org/paper/b651d67502790e1d6d41c589e1d93e996ba7b935,Workshop on Biomedical Natural Language Processing,['JournalArticle'],"This work presents the first large-scale biomedical Spanish language models trained from scratch, using large biomedical corpora consisting of a total of 1.1B tokens and an EHR corpus of 95M tokens. We compared them against general-domain and other domain-specific models for Spanish on three clinical NER tasks. As main results, our models are superior across the NER tasks, rendering them more convenient for clinical NLP applications. Furthermore, our findings indicate that when enough data is available, pre-training from scratch is better than continual pre-training when tested on clinical tasks, raising an exciting research question about which approach is optimal. Our models and fine-tuning scripts are publicly available at HuggingFace and GitHub.",2022,34,,,193-199
NLP,950850e22e42201f152d90dc6f53d53e39d37657,Deep Sentiment Classification and Topic Discovery on Novel Coronavirus or COVID-19 Online Discussions: NLP Using LSTM Recurrent Neural Network Approach,https://www.semanticscholar.org/paper/950850e22e42201f152d90dc6f53d53e39d37657,bioRxiv,['JournalArticle'],"Internet forums and public social media, such as online healthcare forums, provide a convenient channel for users (people/patients) concerned about health issues to discuss and share information with each other. In late December 2019, an outbreak of a novel coronavirus (infection from which results in the disease named COVID-19) was reported, and, due to the rapid spread of the virus in other parts of the world, the World Health Organization declared a state of emergency. In this paper, we used automated extraction of COVID-19–related discussions from social media and a natural language process (NLP) method based on topic modeling to uncover various issues related to COVID-19 from public opinions. Moreover, we also investigate how to use LSTM recurrent neural network for sentiment classification of COVID-19 comments. Our findings shed light on the importance of using public opinions and suitable computational techniques to understand issues surrounding COVID-19 and to guide related decision-making.",2020,261,bioRxiv,,
NLP,09797949fc70fbad8f3fed4f6cf4a91a9c709652,New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology,https://www.semanticscholar.org/paper/09797949fc70fbad8f3fed4f6cf4a91a9c709652,British Journal of Ophthalmology,"['Review', 'JournalArticle']","Natural language processing (NLP) is a subfield of machine intelligence focused on the interaction of human language with computer systems. NLP has recently been discussed in the mainstream media and the literature with the advent of Generative Pre-trained Transformer 3 (GPT-3), a language model capable of producing human-like text. The release of GPT-3 has also sparked renewed interest on the applicability of NLP to contemporary healthcare problems. This article provides an overview of NLP models, with a focus on GPT-3, as well as discussion of applications specific to ophthalmology. We also outline the limitations of GPT-3 and the challenges with its integration into routine ophthalmic care.",2022,43,British Journal of Ophthalmology,106,889 - 892
NLP,e57aeb158a38ccf33d2f0f5a8f63f1209497e329,What Do NLP Researchers Believe? Results of the NLP Community Metasurvey,https://www.semanticscholar.org/paper/e57aeb158a38ccf33d2f0f5a8f63f1209497e329,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","We present the results of the NLP Community Metasurvey. Run from May to June 2022, it elicited opinions on controversial issues, including industry influence in the field, concerns about AGI, and ethics. Our results put concrete numbers to several controversies: For example, respondents are split in half on the importance of artificial general intelligence, whether language models understand language, and the necessity of linguistic structure and inductive bias for solving NLP problems. In addition, the survey posed meta-questions, asking respondents to predict the distribution of survey responses. This allows us to uncover false sociological beliefs where the community’s predictions don’t match reality. Among other results, we find that the community greatly overestimates its own belief in the usefulness of benchmarks and the potential for scaling to solve real-world problems, while underestimating its belief in the importance of linguistic structure, inductive bias, and interdisciplinary science.",2022,26,,,16334-16368
NLP,7fa273f450251523e6b7fcc2eb3fdbdfd4a30493,CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP,https://www.semanticscholar.org/paper/7fa273f450251523e6b7fcc2eb3fdbdfd4a30493,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Humans can learn a new language task efficiently with only few examples, by leveraging their knowledge obtained when learning prior tasks. In this paper, we explore whether and how such cross-task generalization ability can be acquired, and further applied to build better few-shot learners across diverse NLP tasks. We introduce CrossFit, a problem setup for studying cross-task generalization ability, which standardizes seen/unseen task partitions, data access during different learning stages, and the evaluation protocols. To instantiate different seen/unseen task partitions in CrossFit and facilitate in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse few-shot NLP tasks created from open-access NLP datasets and converted to a unified text-to-text format. Our analysis reveals that the few-shot learning ability on unseen tasks can be improved via an upstream learning stage using a set of seen tasks. We also observe that the selection of upstream learning tasks can significantly influence few-shot performance on unseen tasks, asking further analysis on task similarity and transferability.",2021,140,ArXiv,abs/2104.08835,
NLP,185e7d2a761594451b02ace240356dadad2aef78,Dice Loss for Data-imbalanced NLP Tasks,https://www.semanticscholar.org/paper/185e7d2a761594451b02ace240356dadad2aef78,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Many NLP tasks such as tagging and machine reading comprehension are faced with the severe data imbalance issue: negative examples significantly outnumber positive examples, and the huge number of easy-negative examples overwhelms the training. The most commonly used cross entropy (CE) criteria is actually an accuracy-oriented objective, and thus creates a discrepancy between training and test: at training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples. In this paper, we propose to use dice loss in replacement of the standard cross-entropy objective for data-imbalanced NLP tasks. Dice loss is based on the Sørensen--Dice coefficient or Tversky index , which attaches similar importance to false positives and false negatives, and is more immune to the data-imbalance issue. To further alleviate the dominating influence from easy-negative examples in training, we propose to associate training examples with dynamically adjusted weights to deemphasize easy-negative examples. Theoretical analysis shows that this strategy narrows down the gap between the F1 score in evaluation and the dice loss in training. With the proposed training objective, we observe significant performance boost on a wide range of data imbalanced NLP tasks. Notably, we are able to achieve SOTA results on CTB5, CTB6 and UD1.4 for the part of speech tagging task; SOTA results on CoNLL03, OntoNotes5.0, MSRA and OntoNotes4.0 for the named entity recognition task; along with competitive results on the tasks of machine reading comprehension and paraphrase identification.",2019,355,ArXiv,abs/1911.02855,
NLP,7e9905710a5991a017ffc0473dd612cfce4b7b2e,Re-contextualizing Fairness in NLP: The Case of India,https://www.semanticscholar.org/paper/7e9905710a5991a017ffc0473dd612cfce4b7b2e,AACL,['JournalArticle'],"Recent research has revealed undesirable biases in NLP data and models. However, these efforts focus of social disparities in West, and are not directly portable to other geo-cultural contexts. In this paper, we focus on NLP fairness in the context of India. We start with a brief account of the prominent axes of social disparities in India. We build resources for fairness evaluation in the Indian context and use them to demonstrate prediction biases along some of the axes. We then delve deeper into social stereotypes for Region and Religion, demonstrating its prevalence in corpora and models. Finally, we outline a holistic research agenda to re-contextualize NLP fairness research for the Indian context, accounting for Indian societal context, bridging technological gaps in NLP capabilities and resources, and adapting to Indian cultural values. While we focus on India, this framework can be generalized to other geo-cultural contexts.",2022,32,,,727-740
NLP,b2563d102456d5140ecb4111e7f08481f720d9a4,Theories of “Gender” in NLP Bias Research,https://www.semanticscholar.org/paper/b2563d102456d5140ecb4111e7f08481f720d9a4,"Conference on Fairness, Accountability and Transparency","['Book', 'JournalArticle', 'Review']","The rise of concern around Natural Language Processing (NLP) technologies containing and perpetuating social biases has led to a rich and rapidly growing area of research. Gender bias is one of the central biases being analyzed, but to date there is no comprehensive analysis of how “gender” is theorized in the field. We survey nearly 200 articles concerning gender bias in NLP to discover how the field conceptualizes gender both explicitly (e.g. through definitions of terms) and implicitly (e.g. through how gender is operationalized in practice). In order to get a better idea of emerging trajectories of thought, we split these articles into two sections by time. We find that the majority of the articles do not make their theorization of gender explicit, even if they clearly define “bias.” Almost none use a model of gender that is intersectional or inclusive of nonbinary genders; and many conflate sex characteristics, social gender, and linguistic gender in ways that disregard the existence and experience of trans, nonbinary, and intersex people. There is an increase between the two time-sections in statements acknowledging that gender is a complicated reality, however, very few articles manage to put this acknowledgment into practice. In addition to analyzing these findings, we provide specific recommendations to facilitate interdisciplinary work, and to incorporate theory and methodology from Gender Studies. Our hope is that this will produce more inclusive gender bias research in NLP.",2022,33,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",,
NLP,d6f002d88638de71114dab083f0ea8ceea6b6a5a,Benchmarking Intersectional Biases in NLP,https://www.semanticscholar.org/paper/d6f002d88638de71114dab083f0ea8ceea6b6a5a,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","There has been a recent wave of work assessing the fairness of machine learning models in general, and more specifically, on natural language processing (NLP) models built using machine learning techniques. While much work has highlighted biases embedded in state-of-the-art language models, and more recent efforts have focused on how to debias, research assessing the fairness and performance of biased/debiased models on downstream prediction tasks has been limited. Moreover, most prior work has emphasized bias along a single dimension such as gender or race. In this work, we benchmark multiple NLP models with regards to their fairness and predictive performance across a variety of NLP tasks. In particular, we assess intersectional bias - fairness across multiple demographic dimensions. The results show that while current debiasing strategies fare well in terms of the fairness-accuracy trade-off (generally preserving predictive power in debiased models), they are unable to effectively alleviate bias in downstream tasks. Furthermore, this bias is often amplified across dimensions (i.e., intersections). We conclude by highlighting possible causes and making recommendations for future NLP debiasing research.",2022,29,,,3598-3609
NLP,eadb1e7da375939e25083ae3936c4f4ef1f2a719,Post-hoc Interpretability for Neural NLP: A Survey,https://www.semanticscholar.org/paper/eadb1e7da375939e25083ae3936c4f4ef1f2a719,ACM Computing Surveys,"['JournalArticle', 'Review']","Neural networks for NLP are becoming increasingly complex and widespread, and there is a growing concern if these models are responsible to use. Explaining models helps to address the safety and ethical concerns and is essential for accountability. Interpretability serves to provide these explanations in terms that are understandable to humans. Additionally, post-hoc methods provide explanations after a model is learned and are generally model-agnostic. This survey provides a categorization of how recent post-hoc interpretability methods communicate explanations to humans, it discusses each method in-depth, and how they are validated, as the latter is often a common concern.",2021,122,ACM Computing Surveys,55,1 - 42
NLP,97f456643712e9618edd7465676c62af3c8ae690,A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models,https://www.semanticscholar.org/paper/97f456643712e9618edd7465676c62af3c8ae690,arXiv.org,"['JournalArticle', 'Review']","With the increasing of model capacity brought by pre-trained language models, there emerges boosting needs for more knowledgeable natural language processing (NLP) models with advanced functionalities including providing and making flexible use of encyclopedic and commonsense knowledge. The mere pre-trained language models, however, lack the capacity of handling such knowledge-intensive NLP tasks alone. To address this challenge, large numbers of pre-trained language models augmented with external knowledge sources are proposed and in rapid development. In this paper, we aim to summarize the current progress of pre-trained language model-based knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we present the challenges of PLMKEs based on the discussion regarding the three elements and attempt to provide NLP practitioners with potential directions for further research.",2022,28,ArXiv,abs/2202.08772,
NLP,285d13bf3cbe6a8a0f164f584d84f8b74067271f,Towards Faithful Model Explanation in NLP: A Survey,https://www.semanticscholar.org/paper/285d13bf3cbe6a8a0f164f584d84f8b74067271f,Computational Linguistics,"['JournalArticle', 'Review']","
 End-to-end neural Natural Language Processing (NLP) models are notoriously difficult to understand. This has given rise to numerous efforts towards model explainability in recent years. One desideratum of model explanation is faithfulness, i.e. an explanation should accurately represent the reasoning process behind the model’s prediction. In this survey, we review over 110 model explanation methods in NLP through the lens of faithfulness. We first discuss the definition and evaluation of faithfulness, as well as its significance for explainability. We then introduce recent advances in faithful explanation, grouping existing approaches into five categories: similarity-based methods, analysis of model-internal structures, backpropagation-based methods, counterfactual intervention, and self-explanatory models. For each category, we synthesize its representative studies, strengths, and weaknesses. Finally, we summarize their common virtues and remaining challenges, and reflect on future work directions towards faithful explainability in NLP.",2022,28,ArXiv,abs/2209.11326,
NLP,152877c51df17cdd4a87d19e452c6daecfadf6c3,An overview and empirical comparison of natural language processing (NLP) models and an introduction to and empirical application of autoencoder models in marketing,https://www.semanticscholar.org/paper/152877c51df17cdd4a87d19e452c6daecfadf6c3,Journal of the Academy of Marketing Science,['Review'],,2022,23,Journal of the Academy of Marketing Science,50,1324 - 1350
NLP,322d91190acd8ac8c64598f5126947b0485ba249,Quantified Reproducibility Assessment of NLP Results,https://www.semanticscholar.org/paper/322d91190acd8ac8c64598f5126947b0485ba249,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","This paper describes and tests a method for carrying out quantified reproducibility assessment (QRA) that is based on concepts and definitions from metrology. QRA produces a single score estimating the degree of reproducibility of a given system and evaluation measure, on the basis of the scores from, and differences between, different reproductions. We test QRA on 18 different system and evaluation measure combinations (involving diverse NLP tasks and types of evaluation), for each of which we have the original results and one to seven reproduction results. The proposed QRA method produces degree-of-reproducibility scores that are comparable across multiple reproductions not only of the same, but also of different, original studies. We find that the proposed method facilitates insights into causes of variation between reproductions, and as a result, allows conclusions to be drawn about what aspects of system and/or evaluation design need to be changed in order to improve reproducibility.",2022,24,,,16-28
NLP,0e6e8274d0dcbc1c3c1ccdbd87f3e5d53fdf62b4,QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension,https://www.semanticscholar.org/paper/0e6e8274d0dcbc1c3c1ccdbd87f3e5d53fdf62b4,ACM Computing Surveys,"['JournalArticle', 'Review']","Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with more than 80 new datasets appearing in the past 2 years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of “skills” that question answering/reading comprehension systems are supposed to acquire and propose a new taxonomy. The supplementary materials survey the current multilingual resources and monolingual resources for languages other than English, and we discuss the implications of overfocusing on English. The study is aimed at both practitioners looking for pointers to the wealth of existing data and at researchers working on new resources.",2021,119,ACM Computing Surveys,55,1 - 45
NLP,472644c5f4155635cf9e9e37540bfa53c20e7610,Semantically Equivalent Adversarial Rules for Debugging NLP models,https://www.semanticscholar.org/paper/472644c5f4155635cf9e9e37540bfa53c20e7610,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Complex machine learning models for NLP are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) – semantic-preserving perturbations that induce changes in the model’s predictions. We generalize these adversaries into semantically equivalent adversarial rules (SEARs) – simple, universal replacement rules that induce adversaries on many instances. We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains: machine comprehension, visual question-answering, and sentiment analysis. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable: retraining models using data augmentation significantly reduces bugs, while maintaining accuracy.",2018,435,,,856-865
NLP,9b54941de1e21826ecc28b32730ac3f69991ede4,Robustness Gym: Unifying the NLP Evaluation Landscape,https://www.semanticscholar.org/paper/9b54941de1e21826ecc28b32730ac3f69991ede4,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Despite impressive performance on standard benchmarks, natural language processing (NLP) models are often brittle when deployed in real-world systems. In this work, we identify challenges with evaluating NLP systems and propose a solution in the form of Robustness Gym (RG), a simple and extensible evaluation toolkit that unifies 4 standard evaluation paradigms: subpopulations, transformations, evaluation sets, and adversarial attacks. By providing a common platform for evaluation, RG enables practitioners to compare results from disparate evaluation paradigms with a single click, and to easily develop and share novel evaluation methods using a built-in set of abstractions. RG is under active development and we welcome feedback & contributions from the community.",2021,115,ArXiv,abs/2101.04840,
NLP,6a1b25f7a67395ad1e676027322913acbb0a0635,CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review,https://www.semanticscholar.org/paper/6a1b25f7a67395ad1e676027322913acbb0a0635,NeurIPS Datasets and Benchmarks,"['JournalArticle', 'Review']","Many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. We address this bottleneck within the legal domain by introducing the Contract Understanding Atticus Dataset (CUAD), a new dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review. We find that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. Despite these promising results, there is still substantial room for improvement. As one of the only large, specialized NLP benchmarks annotated by experts, CUAD can serve as a challenging research benchmark for the broader NLP community.",2021,109,ArXiv,abs/2103.06268,
NLP,8d0f755dea90f35f4b126a01fa3cce96b3bdd344,Towards Climate Awareness in NLP Research,https://www.semanticscholar.org/paper/8d0f755dea90f35f4b126a01fa3cce96b3bdd344,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference', 'Review']","The climate impact of AI, and NLP research in particular, has become a serious issue given the enormous amount of energy that is increasingly being used for training and running computational models. Consequently, increasing focus is placed on efficient NLP. However, this important initiative lacks simple guidelines that would allow for systematic climate reporting of NLP research. We argue that this deficiency is one of the reasons why very few publications in NLP report key figures that would allow a more thorough examination of environmental impact, and present a quantitative survey to demonstrate this. As a remedy, we propose a climate performance model card with the primary purpose of being practically usable with only limited information about experiments and the underlying computer hardware. We describe why this step is essential to increase awareness about the environmental impact of NLP research and, thereby, paving the way for more thorough discussions.",2022,22,,,2480-2494
NLP,ef25b02f3be31c699255ee05aa90a4a17461d95d,"The language of proteins: NLP, machine learning & protein sequences",https://www.semanticscholar.org/paper/ef25b02f3be31c699255ee05aa90a4a17461d95d,Computational and Structural Biotechnology Journal,"['Review', 'JournalArticle']",,2021,163,Computational and Structural Biotechnology Journal,19,1750 - 1758
NLP,8bb9db78b4413b92cdeeae9e24e955aab9c87ae1,A Survey of Adversarial Defences and Robustness in NLP,https://www.semanticscholar.org/paper/8bb9db78b4413b92cdeeae9e24e955aab9c87ae1,,['Review'],"In the past few years, it has become increasingly evident that deep neural networks are not resilient enough to withstand adversarial perturbations in input data, leaving them vulnerable to attack. Various authors have proposed strong adversarial attacks for computer vision and Natural Language Processing (NLP) tasks. As a response, many defense mechanisms have also been proposed to prevent these networks from failing. The significance of defending neural networks against adversarial attacks lies in ensuring that the model's predictions remain unchanged even if the input data is perturbed. Several methods for adversarial defense in NLP have been proposed, catering to different NLP tasks such as text classification, named entity recognition, and natural language inference. Some of these methods not only defend neural networks against adversarial attacks but also act as a regularization mechanism during training, saving the model from overfitting. This survey aims to review the various methods proposed for adversarial defenses in NLP over the past few years by introducing a novel taxonomy. The survey also highlights the fragility of advanced deep neural networks in NLP and the challenges involved in defending them.",2022,21,,,
NLP,7571ed4cf1bbdcf891b576a0da12c910b1f0c72f,Concealed Data Poisoning Attacks on NLP Models,https://www.semanticscholar.org/paper/7571ed4cf1bbdcf891b576a0da12c910b1f0c72f,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model’s training set that causes the model to frequently predict Positive whenever the input contains “James Bond”. Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to language modeling (“Apple iPhone” triggers negative generations) and machine translation (“iced coffee” mistranslated as “hot coffee”). We conclude by proposing three defenses that can mitigate our attack at some cost in prediction accuracy or extra human annotation.",2021,102,,,139-150
NLP,a0f788f6de0fb83d623c875a98120e3f347f70d1,Biomedical and clinical English model packages for the Stanza Python NLP library,https://www.semanticscholar.org/paper/a0f788f6de0fb83d623c875a98120e3f347f70d1,J. Am. Medical Informatics Assoc.,['JournalArticle'],"Abstract Objective The study sought to develop and evaluate neural natural language processing (NLP) packages for the syntactic analysis and named entity recognition of biomedical and clinical English text. Materials and Methods We implement and train biomedical and clinical English NLP pipelines by extending the widely used Stanza library originally designed for general NLP tasks. Our models are trained with a mix of public datasets such as the CRAFT treebank as well as with a private corpus of radiology reports annotated with 5 radiology-domain entities. The resulting pipelines are fully based on neural networks, and are able to perform tokenization, part-of-speech tagging, lemmatization, dependency parsing, and named entity recognition for both biomedical and clinical text. We compare our systems against popular open-source NLP libraries such as CoreNLP and scispaCy, state-of-the-art models such as the BioBERT models, and winning systems from the BioNLP CRAFT shared task. Results For syntactic analysis, our systems achieve much better performance compared with the released scispaCy models and CoreNLP models retrained on the same treebanks, and are on par with the winning system from the CRAFT shared task. For NER, our systems substantially outperform scispaCy, and are better or on par with the state-of-the-art performance from BioBERT, while being much more computationally efficient. Conclusions We introduce biomedical and clinical NLP packages built for the Stanza library. These packages offer performance that is similar to the state of the art, and are also optimized for ease of use. To facilitate research, we make all our models publicly available. We also provide an online demonstration (http://stanza.run/bio).",2021,100,Journal of the American Medical Informatics Association : JAMIA,28,1892 - 1899
NLP,dca4d9abbc82e57dfa52f932e893d467a63e0682,Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation,https://www.semanticscholar.org/paper/dca4d9abbc82e57dfa52f932e893d467a63e0682,ACM Conference on Recommender Systems,"['JournalArticle', 'Book']","Much of the recent progress in sequential and session-based recommendation has been driven by improvements in model architecture and pretraining techniques originating in the field of Natural Language Processing. Transformer architectures in particular have facilitated building higher-capacity models and provided data augmentation and training techniques which demonstrably improve the effectiveness of sequential recommendation. But with a thousandfold more research going on in NLP, the application of transformers for recommendation understandably lags behind. To remedy this we introduce Transformers4Rec, an open-source library built upon HuggingFace’s Transformers library with a similar goal of opening up the advances of NLP based Transformers to the recommender system community and making these advancements immediately accessible for the tasks of sequential and session-based recommendation. Like its core dependency, Transformers4Rec is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. In order to demonstrate the usefulness of the library and the applicability of Transformer architectures in next-click prediction for user sessions, where sequence lengths are much shorter than those commonly found in NLP, we have leveraged Transformers4Rec to win two recent session-based recommendation competitions. In addition, we present in this paper the first comprehensive empirical analysis comparing many Transformer architectures and training approaches for the task of session-based recommendation. We demonstrate that the best Transformer architectures have superior performance across two e-commerce datasets while performing similarly to the baselines on two news datasets. We further evaluate in isolation the effectiveness of the different training techniques used in causal language modeling, masked language modeling, permutation language modeling and replacement token detection for a single Transformer architecture, XLNet. We establish that training XLNet with replacement token detection performs well across all datasets. Finally, we explore techniques to include side information such as item and user context features in order to establish best practices and show that the inclusion of side information uniformly improves recommendation performance. Transformers4Rec library is available at https://github.com/NVIDIA-Merlin/Transformers4Rec/",2021,96,Proceedings of the 15th ACM Conference on Recommender Systems,,
NLP,c0e6cd2ec3bc9eb46c7d45bb708854da3327339e,A Survey on Bias in Deep NLP,https://www.semanticscholar.org/paper/c0e6cd2ec3bc9eb46c7d45bb708854da3327339e,Applied Sciences,['Review'],"Deep neural networks are hegemonic approaches to many machine learning areas, including natural language processing (NLP). Thanks to the availability of large corpora collections and the capability of deep architectures to shape internal language mechanisms in self-supervised learning processes (also known as “pre-training”), versatile and performing models are released continuously for every new network design. These networks, somehow, learn a probability distribution of words and relations across the training collection used, inheriting the potential flaws, inconsistencies and biases contained in such a collection. As pre-trained models have been found to be very useful approaches to transfer learning, dealing with bias has become a relevant issue in this new scenario. We introduce bias in a formal way and explore how it has been treated in several networks, in terms of detection and correction. In addition, available resources are identified and a strategy to deal with bias in deep NLP is proposed.",2021,104,Applied Sciences,11,3184
NLP,5e31fa4e69d1a3587230f5d134c0b7e2ed84a742,Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models,https://www.semanticscholar.org/paper/5e31fa4e69d1a3587230f5d134c0b7e2ed84a742,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Recent studies have revealed a security threat to natural language processing (NLP) models, called the Backdoor Attack. Victim models can maintain competitive performance on clean samples while behaving abnormally on samples with a specific trigger word inserted. Previous backdoor attacking methods usually assume that attackers have a certain degree of data knowledge, either the dataset which users would use or proxy datasets for a similar task, for implementing the data poisoning procedure. However, in this paper, we find that it is possible to hack the model in a data-free way by modifying one single word embedding vector, with almost no accuracy sacrificed on clean samples. Experimental results on sentiment analysis and sentence-pair classification tasks show that our method is more efficient and stealthier. We hope this work can raise the awareness of such a critical security risk hidden in the embedding layers of NLP models. Our code is available at https://github.com/lancopku/Embedding-Poisoning.",2021,92,ArXiv,abs/2103.15543,
NLP,f91dbd39d4c742ba675e447b04a0b0c70b33e836,Measure and Improve Robustness in NLP Models: A Survey,https://www.semanticscholar.org/paper/f91dbd39d4c742ba675e447b04a0b0c70b33e836,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","As NLP models achieved state-of-the-art performances over benchmarks and gained wide applications, it has been increasingly important to ensure the safe deployment of these models in the real world, e.g., making sure the models are robust against unseen or challenging scenarios. Despite robustness being an increasingly studied topic, it has been separately explored in applications like vision and NLP, with various definitions, evaluation and mitigation strategies in multiple lines of research. In this paper, we aim to provide a unifying survey of how to define, measure and improve robustness in NLP. We first connect multiple definitions of robustness, then unify various lines of work on identifying robustness failures and evaluating models’ robustness. Correspondingly, we present mitigation strategies that are data-driven, model-driven, and inductive-prior-based, with a more systematic view of how to effectively improve robustness in NLP models. Finally, we conclude by outlining open challenges and future directions to motivate further research in this area.",2021,85,ArXiv,abs/2112.08313,
NLP,013eb12ce5468f79d58bf859653f4929c5a2bd14,An Empirical Survey of Data Augmentation for Limited Data Learning in NLP,https://www.semanticscholar.org/paper/013eb12ce5468f79d58bf859653f4929c5a2bd14,Transactions of the Association for Computational Linguistics,"['JournalArticle', 'Review']","NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP.",2021,89,Transactions of the Association for Computational Linguistics,11,191-211
NLP,5406e153957dd7a165264da6e6e5d81251997404,State-of-the-art augmented NLP transformer models for direct and single-step retrosynthesis,https://www.semanticscholar.org/paper/5406e153957dd7a165264da6e6e5d81251997404,Nature Communications,['JournalArticle'],,2020,210,Nature Communications,11,
NLP,1109d62ebd2b29a7dc148bc30dd6cfc803a63dec,IndoLEM and IndoBERT: A Benchmark Dataset and Pre-trained Language Model for Indonesian NLP,https://www.semanticscholar.org/paper/1109d62ebd2b29a7dc148bc30dd6cfc803a63dec,International Conference on Computational Linguistics,"['JournalArticle', 'Conference']","Although the Indonesian language is spoken by almost 200 million people and the 10th most spoken language in the world, it is under-represented in NLP research. Previous work on Indonesian has been hampered by a lack of annotated datasets, a sparsity of language resources, and a lack of resource standardization. In this work, we release the IndoLEM dataset comprising seven tasks for the Indonesian language, spanning morpho-syntax, semantics, and discourse. We additionally release IndoBERT, a new pre-trained language model for Indonesian, and evaluate it over IndoLEM, in addition to benchmarking it against existing resources. Our experiments show that IndoBERT achieves state-of-the-art performance over most of the tasks in IndoLEM.",2020,152,,,757-770
NLP,3cc2f69951cd24fe61be4cf32d62afbac297bc2b,Social Biases in NLP Models as Barriers for Persons with Disabilities,https://www.semanticscholar.org/paper/3cc2f69951cd24fe61be4cf32d62afbac297bc2b,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.",2020,219,ArXiv,abs/2005.00813,
NLP,25761ba4bdc054bfe902fe7c5d6338be6d00d491,Sentiment Analysis of Students’ Feedback with NLP and Deep Learning: A Systematic Mapping Study,https://www.semanticscholar.org/paper/25761ba4bdc054bfe902fe7c5d6338be6d00d491,Applied Sciences,['Review'],"In the last decade, sentiment analysis has been widely applied in many domains, including business, social networks and education. Particularly in the education domain, where dealing with and processing students’ opinions is a complicated task due to the nature of the language used by students and the large volume of information, the application of sentiment analysis is growing yet remains challenging. Several literature reviews reveal the state of the application of sentiment analysis in this domain from different perspectives and contexts. However, the body of literature is lacking a review that systematically classifies the research and results of the application of natural language processing (NLP), deep learning (DL), and machine learning (ML) solutions for sentiment analysis in the education domain. In this article, we present the results of a systematic mapping study to structure the published information available. We used a stepwise PRISMA framework to guide the search process and searched for studies conducted between 2015 and 2020 in the electronic research databases of the scientific literature. We identified 92 relevant studies out of 612 that were initially found on the sentiment analysis of students’ feedback in learning platform environments. The mapping results showed that, despite the identified challenges, the field is rapidly growing, especially regarding the application of DL, which is the most recent trend. We identified various aspects that need to be considered in order to contribute to the maturity of research and development in the field. Among these aspects, we highlighted the need of having structured datasets, standardized solutions and increased focus on emotional expression and detection.",2021,85,Applied Sciences,11,3986
NLP,2ee03e28208a9310a9be4032c2b04ebdddb83cc7,FLEX: Unifying Evaluation for Few-Shot NLP,https://www.semanticscholar.org/paper/2ee03e28208a9310a9be4032c2b04ebdddb83cc7,Neural Information Processing Systems,['JournalArticle'],"Few-shot NLP research is highly active, yet conducted in disjoint research threads with evaluation suites that lack challenging-yet-realistic testing setups and fail to employ careful experimental design. Consequently, the community does not know which techniques perform best or even if they outperform simple baselines. In response, we formulate the FLEX Principles, a set of requirements and best practices for unified, rigorous, valid, and cost-sensitive few-shot NLP evaluation. These principles include Sample Size Design, a novel approach to benchmark design that optimizes statistical accuracy and precision while keeping evaluation costs manageable. Following the principles, we release the FLEX benchmark, which includes four few-shot transfer settings, zero-shot evaluation, and a public leaderboard that covers diverse NLP tasks. In addition, we present UniFew, a prompt-based model for few-shot learning that unifies pretraining and finetuning prompt formats, eschewing complex machinery of recent prompt-based approaches in adapting downstream task formats to language model pretraining objectives. We demonstrate that despite simplicity, UniFew achieves results competitive with both popular meta-learning and prompt-based approaches.",2021,83,,,15787-15800
NLP,28a5a53dafacebad8a7c47773079caeffb9a5baa,Representing Numbers in NLP: a Survey and a Vision,https://www.semanticscholar.org/paper/28a5a53dafacebad8a7c47773079caeffb9a5baa,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","NLP systems rarely give special consideration to numbers found in text. This starkly contrasts with the consensus in neuroscience that, in the brain, numbers are represented differently from words. We arrange recent NLP work on numeracy into a comprehensive taxonomy of tasks and methods. We break down the subjective notion of numeracy into 7 subtasks, arranged along two dimensions: granularity (exact vs approximate) and units (abstract vs grounded). We analyze the myriad representational choices made by over a dozen previously published number encoders and decoders. We synthesize best practices for representing numbers in text and articulate a vision for holistic numeracy in NLP, comprised of design trade-offs and a unified evaluation.",2021,81,ArXiv,abs/2103.13136,
NLP,d617f51833860dc50d202af7f80be71304b2e994,Between words and characters: A Brief History of Open-Vocabulary Modeling and Tokenization in NLP,https://www.semanticscholar.org/paper/d617f51833860dc50d202af7f80be71304b2e994,arXiv.org,"['JournalArticle', 'Review']","What are the units of text that we want to model? From bytes to multi-word expressions, text can be analyzed and generated at many granularities. Until recently, most natural language processing (NLP) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (BPE), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. Is the end of the road character-level model or byte-level processing? In this survey, we connect several lines of work from the pre-neural and neural era, by showing how hybrid approaches of words and characters as well as subword-based approaches based on learned segmentation have been proposed and evaluated. We conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications.",2021,79,ArXiv,abs/2112.10508,
NLP,11342d45911ee8a7c9e3a94117ce774ad7036172,Neural Unsupervised Domain Adaptation in NLP—A Survey,https://www.semanticscholar.org/paper/11342d45911ee8a7c9e3a94117ce774ad7036172,International Conference on Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","Deep neural networks excel at learning from labeled data and achieve state-of-the-art results on a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge. Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future NLP.",2020,206,ArXiv,abs/2006.00632,
NLP,fa7b8acd47631bada5b66049824bfd335ac6bf8f,Towards Improving Adversarial Training of NLP Models,https://www.semanticscholar.org/paper/fa7b8acd47631bada5b66049824bfd335ac6bf8f,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Adversarial training, a method for learning robust deep neural networks, constructs adversarial examples during training. However, recent methods for generating NLP adversarial examples involve combinatorial search and expensive sentence encoders for constraining the generated instances. As a result, it remains challenging to use vanilla adversarial training to improve NLP models' performance, and the benefits are mainly uninvestigated. This paper proposes a simple and improved vanilla adversarial training process for NLP models, which we name Attacking to Training (A2T). The core part of A2T is a new and cheaper word substitution attack optimized for vanilla adversarial training. We use A2T to train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI datasets. Our results empirically show that it is possible to train robust NLP models using a much cheaper adversary. We demonstrate that vanilla adversarial training with A2T can improve an NLP model's robustness to the attack it was originally trained with and also defend the model against other types of word substitution attacks. Furthermore, we show that A2T can improve NLP models' standard accuracy, cross-domain generalization, and interpretability. Code is available at https://github.com/QData/Textattack-A2T .",2021,75,ArXiv,abs/2109.00544,
NLP,9b529fe170823f95509585d5aa39fa01a43558fd,How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence,https://www.semanticscholar.org/paper/9b529fe170823f95509585d5aa39fa01a43558fd,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we introduce the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.",2020,185,,,5218-5230
NLP,353c88c231ce156d604e074af276422422fc73f7,"A Survey of Race, Racism, and Anti-Racism in NLP",https://www.semanticscholar.org/paper/353c88c231ce156d604e074af276422422fc73f7,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.",2021,77,ArXiv,abs/2106.11410,
NLP,cbc1e8bbfe98f94c0d13d111b824cf603b62712c,Bad Characters: Imperceptible NLP Attacks,https://www.semanticscholar.org/paper/cbc1e8bbfe98f94c0d13d111b824cf603b62712c,IEEE Symposium on Security and Privacy,['JournalArticle'],"Several years of research have shown that machine-learning systems are vulnerable to adversarial examples, both in theory and in practice. Until now, such attacks have primarily targeted visual models, exploiting the gap between human and machine perception. Although text-based models have also been attacked with adversarial examples, such attacks struggled to preserve semantic meaning and indistinguishability. In this paper, we explore a large class of adversarial examples that can be used to attack text-based models in a black-box setting without making any human-perceptible visual modification to inputs. We use encoding-specific perturbations that are imperceptible to the human eye to manipulate the outputs of a wide range of Natural Language Processing (NLP) systems from neural machine-translation pipelines to web search engines. We find that with a single imperceptible encoding injection – representing one invisible character, homoglyph, reordering, or deletion – an attacker can significantly reduce the performance of vulnerable models, and with three injections most models can be functionally broken. Our attacks work against currently-deployed commercial systems, including those produced by Microsoft and Google, in addition to open source models published by Facebook, IBM, and HuggingFace. This novel series of attacks presents a significant threat to many language processing systems: an attacker can affect systems in a targeted manner without any assumptions about the underlying model. We conclude that text-based NLP systems require careful input sanitization, just like conventional applications, and that given such systems are now being deployed rapidly at scale, the urgent attention of architects and operators is required.",2021,78,2022 IEEE Symposium on Security and Privacy (SP),,1987-2004
NLP,9a0424bdd12cdcdf45b556b0b9dcc6fc5a55520b,FORCES NLP: an efficient implementation of interior-point methods for multistage nonlinear nonconvex programs,https://www.semanticscholar.org/paper/9a0424bdd12cdcdf45b556b0b9dcc6fc5a55520b,International Journal of Control,['JournalArticle'],"ABSTRACT Real-time implementation of optimisation-based control and trajectory planning can be very challenging for nonlinear systems. As a result, if an implementation based on a fixed linearisation is not suitable, the nonlinear problems are typically locally approximated online, in order to leverage the speed and robustness of embedded solvers for convex quadratic programs (QP) developed during the last decade. The purpose of this paper is to demonstrate that, using simple standard building blocks from nonlinear programming, combined with a structure-exploiting linear system solver, it is possible to achieve computation times in the range typical of solvers for QPs, while retaining nonlinearities and solving the nonlinear programs (NLP) to local optimality. The implemented algorithm is an interior-point method with approximate Hessians and adaptive barrier rules, and is provided as an extension to the C code generator FORCES. Three detailed examples are provided that illustrate a significant improvement in control performance when solving NLPs, with computation times that are comparable with those achieved by fast approximate schemes and up to an order of magnitude faster than the state-of-the-art interior-point solver IPOPT.",2020,162,International Journal of Control,93,13 - 29
NLP,db528269ef800727245c0fcb35b692d29c1ccdc9,Natural language processing (NLP) in management research: A literature review,https://www.semanticscholar.org/paper/db528269ef800727245c0fcb35b692d29c1ccdc9,,['Review'],"Natural language processing (NLP) is gaining momentum in management research for its ability to automatically analyze and comprehend human language. Yet, despite its extensive application in manage...",2020,167,,7,139-172
NLP,5290d7921f0266c8b50b79fc8a0b7d22868f4f60,The Cost of Training NLP Models: A Concise Overview,https://www.semanticscholar.org/paper/5290d7921f0266c8b50b79fc8a0b7d22868f4f60,arXiv.org,"['JournalArticle', 'Review']","We review the cost of training large-scale language models, and the drivers of these costs. The intended audience includes engineers and scientists budgeting their model-training experiments, as well as non-practitioners trying to make sense of the economics of modern-day Natural Language Processing (NLP).",2020,156,ArXiv,abs/2004.08900,
NLP,c30c0092bf4eb8a44faec3fc60cdd5006276bcdc,Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking,https://www.semanticscholar.org/paper/c30c0092bf4eb8a44faec3fc60cdd5006276bcdc,International Conference on Learning Representations,['JournalArticle'],"Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",2020,153,ArXiv,abs/2010.00577,
NLP,8dce62b18bdea587c07cb4769a05ca0a816d09ba,"The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models",https://www.semanticscholar.org/paper/8dce62b18bdea587c07cb4769a05ca0a816d09ba,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior: Why did my model make this prediction? When does it perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring counterfactuals for sentiment analysis, measuring gender bias in coreference systems, and exploring local behavior in text generation. LIT supports a wide range of models—including classification, seq2seq, and structured prediction—and is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.",2020,149,,,107-118
NLP,68a3d32416977e88cf1bfa4ad548d403f5f089d6,Rethinking Stealthiness of Backdoor Attack against NLP Models,https://www.semanticscholar.org/paper/68a3d32416977e88cf1bfa4ad548d403f5f089d6,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Recent researches have shown that large natural language processing (NLP) models are vulnerable to a kind of security threat called the Backdoor Attack. Backdoor attacked models can achieve good performance on clean test sets but perform badly on those input sentences injected with designed trigger words. In this work, we point out a potential problem of current backdoor attacking research: its evaluation ignores the stealthiness of backdoor attacks, and most of existing backdoor attacking methods are not stealthy either to system deployers or to system users. To address this issue, we first propose two additional stealthiness-based metrics to make the backdoor attacking evaluation more credible. We further propose a novel word-based backdoor attacking method based on negative data augmentation and modifying word embeddings, making an important step towards achieving stealthy backdoor attacking. Experiments on sentiment analysis and toxic detection tasks show that our method is much stealthier while maintaining pretty good attacking performance. Our code is available at https://github.com/lancopku/SOS.",2021,66,,,5543-5557
NLP,6ea4bd1d842d7ab689b7ceb22927e48b9e5ad786,BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models,https://www.semanticscholar.org/paper/6ea4bd1d842d7ab689b7ceb22927e48b9e5ad786,International Conference on Learning Representations,['JournalArticle'],"Pre-trained Natural Language Processing (NLP) models can be easily adapted to a variety of downstream language tasks. This significantly accelerates the development of language models. However, NLP models have been shown to be vulnerable to backdoor attacks, where a pre-defined trigger word in the input text causes model misprediction. Previous NLP backdoor attacks mainly focus on some specific tasks. This makes those attacks less general and applicable to other kinds of NLP models and tasks. In this work, we propose \Name, the first task-agnostic backdoor attack against the pre-trained NLP models. The key feature of our attack is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the pre-trained model. When this malicious model is released, any downstream models transferred from it will also inherit the backdoor, even after the extensive transfer learning process. We further design a simple yet effective strategy to bypass a state-of-the-art defense. Experimental results indicate that our approach can compromise a wide range of downstream NLP tasks in an effective and stealthy way.",2021,60,ArXiv,abs/2110.02467,
NLP,e5d720767b7a539bb2edaa98eaf572a4506a79c6,Beyond Fair Pay: Ethical Implications of NLP Crowdsourcing,https://www.semanticscholar.org/paper/e5d720767b7a539bb2edaa98eaf572a4506a79c6,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","The use of crowdworkers in NLP research is growing rapidly, in tandem with the exponential increase in research production in machine learning and AI. Ethical discussion regarding the use of crowdworkers within the NLP research community is typically confined in scope to issues related to labor conditions such as fair pay. We draw attention to the lack of ethical considerations related to the various tasks performed by workers, including labeling, evaluation, and production. We find that the Final Rule, the common ethical framework used by researchers, did not anticipate the use of online crowdsourcing platforms for data collection, resulting in gaps between the spirit and practice of human-subjects ethics in NLP research. We enumerate common scenarios where crowdworkers performing NLP tasks are at risk of harm. We thus recommend that researchers evaluate these risks by considering the three ethical principles set up by the Belmont Report. We also clarify some common misconceptions regarding the Institutional Review Board (IRB) application. We hope this paper will serve to reopen the discussion within our community regarding the ethical use of crowdworkers.",2021,62,,,3758-3769
NLP,10aa2be24951e6de76b630482a645d79354c4cde,Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics,https://www.semanticscholar.org/paper/10aa2be24951e6de76b630482a645d79354c4cde,Transactions of the Association for Computational Linguistics,['JournalArticle'],"Abstract Measuring bias is key for better understanding and addressing unfairness in NLP/ML models. This is often done via fairness metrics, which quantify the differences in a model’s behaviour across a range of demographic groups. In this work, we shed more light on the differences and similarities between the fairness metrics used in NLP. First, we unify a broad range of existing metrics under three generalized fairness metrics, revealing the connections between them. Next, we carry out an extensive empirical comparison of existing metrics and demonstrate that the observed differences in bias measurement can be systematically explained via differences in parameter choices for our generalized metrics.",2021,64,Transactions of the Association for Computational Linguistics,9,1249-1267
NLP,c50a909e20bd07f4aea09dc6dae539b45b406a96,Evaluation of BERT and ALBERT Sentence Embedding Performance on Downstream NLP Tasks,https://www.semanticscholar.org/paper/c50a909e20bd07f4aea09dc6dae539b45b406a96,International Conference on Pattern Recognition,"['JournalArticle', 'Conference']","Contextualized representations from a pre-trained language model are central to achieve a high performance on downstream NLP task. The pre-trained BERT and A Lite BERT (ALBERT) models can be fine-tuned to give state-of-the-art results in sentence-pair regressions such as semantic textual similarity (STS) and natural language inference (NLI). Although BERT-based models yield the [CLS] token vector as a reasonable sentence embedding, the search for an optimal sentence embedding scheme remains an active research area in computational linguistics. This paper explores on sentence embedding models for BERT and ALBERT. In particular, we take a modified BERT network with siamese and triplet network structures called Sentence-BERT (SBERT) and replace BERT with ALBERT to create Sentence-ALBERT (SALBERT). We also experiment with an outer CNN sentence-embedding network for SBERT and SALBERT. We evaluate performances of all sentence-embedding models considered using the STS and NLI datasets. The empirical results indicate that our CNN architecture improves ALBERT models substantially more than BERT models for STS benchmark. Despite significantly fewer model parameters, ALBERT sentence embedding is highly competitive to BERT in downstream NLP evaluations.",2021,64,2020 25th International Conference on Pattern Recognition (ICPR),,5482-5487
NLP,0427110f0e79f41e69a8eb00a3ec8868bac26a4f,Do NLP Models Know Numbers? Probing Numeracy in Embeddings,https://www.semanticscholar.org/paper/0427110f0e79f41e69a8eb00a3ec8868bac26a4f,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","The ability to understand and work with numbers (numeracy) is critical for many complex reasoning tasks. Currently, most NLP models treat numbers in text in the same way as other tokens—they embed them as distributed vectors. Is this enough to capture numeracy? We begin by investigating the numerical reasoning capabilities of a state-of-the-art question answering model on the DROP dataset. We find this model excels on questions that require numerical reasoning, i.e., it already captures numeracy. To understand how this capability emerges, we probe token embedding methods (e.g., BERT, GloVe) on synthetic list maximum, number decoding, and addition tasks. A surprising degree of numeracy is naturally present in standard embeddings. For example, GloVe and word2vec accurately encode magnitude for numbers up to 1,000. Furthermore, character-level embeddings are even more precise—ELMo captures numeracy the best for all pre-trained methods—but BERT, which uses sub-word units, is less exact.",2019,218,,,5306-5314
NLP,d84ed05ab860b75f9e6b28e717abf4bc12da03d7,Explanation-Based Human Debugging of NLP Models: A Survey,https://www.semanticscholar.org/paper/d84ed05ab860b75f9e6b28e717abf4bc12da03d7,Transactions of the Association for Computational Linguistics,"['JournalArticle', 'Review']","Abstract Debugging a machine learning model is hard since the bug usually involves the training data and the learning process. This becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. In this survey, we review papers that exploit explanations to enable humans to give feedback and debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing work along three dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect the feedback providers, and highlight open problems that could be future research directions.",2021,63,Transactions of the Association for Computational Linguistics,9,1508-1528
NLP,9eea59c34f139f3d2153226c8cf026e975622074,Memorization vs. Generalization : Quantifying Data Leakage in NLP Performance Evaluation,https://www.semanticscholar.org/paper/9eea59c34f139f3d2153226c8cf026e975622074,Conference of the European Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Public datasets are often used to evaluate the efficacy and generalizability of state-of-the-art methods for many tasks in natural language processing (NLP). However, the presence of overlap between the train and test datasets can lead to inflated results, inadvertently evaluating the model’s ability to memorize and interpreting it as the ability to generalize. In addition, such data sets may not provide an effective indicator of the performance of these methods in real world scenarios. We identify leakage of training data into test data on several publicly available datasets used to evaluate NLP tasks, including named entity recognition and relation extraction, and study them to assess the impact of that leakage on the model’s ability to memorize versus generalize.",2021,56,,,1325-1335
NLP,2743e66939b30c43affb3c9e31f20cfac2109045,Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks,https://www.semanticscholar.org/paper/2743e66939b30c43affb3c9e31f20cfac2109045,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference', 'Review']","Labelled data is the foundation of most natural language processing tasks. However, labelling data is difficult and there often are diverse valid beliefs about what the correct data labels should be. So far, dataset creators have acknowledged annotator subjectivity, but rarely actively managed it in the annotation process. This has led to partly-subjective datasets that fail to serve a clear downstream use. To address this issue, we propose two contrasting paradigms for data annotation. The descriptive paradigm encourages annotator subjectivity, whereas the prescriptive paradigm discourages it. Descriptive annotation allows for the surveying and modelling of different beliefs, whereas prescriptive annotation enables the training of models that consistently apply one belief. We discuss benefits and challenges in implementing both paradigms, and argue that dataset creators should explicitly aim for one or the other to facilitate the intended use of their dataset. Lastly, we conduct an annotation experiment using hate speech data that illustrates the contrast between the two paradigms.",2021,79,,,61-76
NLP,fafa541419b3756968fe5b3156c6f0257cb29c23,Visualizing and Understanding Neural Models in NLP,https://www.semanticscholar.org/paper/fafa541419b3756968fe5b3156c6f0257cb29c23,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","While neural networks have been successfully applied to many NLP tasks the resulting vector-based models are very difficult to interpret. For example it's not clear how they achieve {\em compositionality}, building sentence meaning from the meanings of words and phrases. In this paper we describe four strategies for visualizing compositionality in neural models for NLP, inspired by similar work in computer vision. We first plot unit values to visualize compositionality of negation, intensification, and concessive clauses, allow us to see well-known markedness asymmetries in negation. We then introduce three simple and straightforward methods for visualizing a unit's {\em salience}, the amount it contributes to the final composed meaning: (1) gradient back-propagation, (2) the variance of a token from the average word node, (3) LSTM-style gates that measure information flow. We test our methods on sentiment using simple recurrent nets and LSTMs. Our general-purpose methods may have wide applications for understanding compositionality and other semantic properties of deep networks , and also shed light on why LSTMs outperform simple recurrent nets,",2015,631,,,681-691
NLP,43bafb4997515d2904abfca8214f2fc806680fc3,Teach Me to Explain: A Review of Datasets for Explainable NLP,https://www.semanticscholar.org/paper/43bafb4997515d2904abfca8214f2fc806680fc3,arXiv.org,"['JournalArticle', 'Review']","Explainable NLP (E X NLP) has increasingly focused on collecting human-annotated explanations. These explanations are used downstream in three ways: as data augmentation to improve performance on a predictive task, as a loss signal to train models to produce explanations for their predictions, and as a means to evaluate the quality of model-generated explanations. In this review, we identify three predominant classes of explanations (highlights, free-text, and structured), organize the literature on annotating each type, point to what has been learned to date, and give recommendations for collecting E X NLP datasets in the future.",2021,52,ArXiv,abs/2102.12060,
NLP,1cf2e9e198feef3893da2800a7949f6880ddc084,ExplainaBoard: An Explainable Leaderboard for NLP,https://www.semanticscholar.org/paper/1cf2e9e198feef3893da2800a7949f6880ddc084,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","With the rapid development of NLP research, leaderboards have emerged as one tool to track the performance of various systems on various NLP tasks. They are effective in this goal to some extent, but generally present a rather simplistic one-dimensional view of the submitted systems, communicated only through holistic accuracy numbers. In this paper, we present a new conceptualization and implementation of NLP evaluation: the ExplainaBoard, which in addition to inheriting the functionality of the standard leaderboard, also allows researchers to (i) diagnose strengths and weaknesses of a single system (e.g. what is the best-performing system bad at?) (ii) interpret relationships between multiple systems. (e.g. where does system A outperform system B? What if we combine systems A, B and C?) and (iii) examine prediction results closely (e.g. what are common errors made by multiple systems or in what contexts do particular errors occur?). So far, ExplainaBoard covers more than 400 systems, 50 datasets, 40 languages, and 12 tasks. We not only released an online platform at the website but also make our evaluation tool an API with MIT Licence at Github and PyPi that allows users to conveniently assess their models offline. We additionally release all output files from systems that we have run or collected to motivate “output-driven” research in the future.",2021,50,,,280-289
NLP,d88c1255876b62fb5f5a8b292098ca430710a540,The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures,https://www.semanticscholar.org/paper/d88c1255876b62fb5f5a8b292098ca430710a540,IEEE Access,['JournalArticle'],"In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.",2021,50,IEEE Access,9,68675-68702
NLP,ca115a9eb54e2875b9d4c4c3d5ed8adcb399dbf8,RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models,https://www.semanticscholar.org/paper/ca115a9eb54e2875b9d4c4c3d5ed8adcb399dbf8,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Backdoor attacks, which maliciously control a well-trained model’s outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods. Our code is available at https://github.com/lancopku/RAP.",2021,48,,,8365-8381
NLP,da5d78b3e3a1544fde98fba86088e1215e97cbe8,All NLP Tasks Are Generation Tasks: A General Pretraining Framework,https://www.semanticscholar.org/paper/da5d78b3e3a1544fde98fba86088e1215e97cbe8,arXiv.org,['JournalArticle'],"There have been various types of pretraining architectures including autoregressive models (e.g., GPT), autoencoding models (e.g., BERT), and encoder-decoder models (e.g., T5). On the other hand, NLP tasks are different in nature, with three main categories being classification, unconditional generation, and conditional generation. However, none of the pretraining frameworks performs the best for all tasks, which introduces inconvenience for model development and selection. We propose a novel pretraining framework GLM (General Language Model) to address this challenge. Compared to previous work, our architecture has three major benefits: (1) it performs well on classification, unconditional generation, and conditional generation tasks with one single pretrained model; (2) it outperforms BERT-like models on classification due to improved pretrain-finetune consistency; (3) it naturally handles variable-length blank filling which is crucial for many downstream tasks. Empirically, GLM substantially outperforms BERT on the SuperGLUE natural language understanding benchmark with the same amount of pre-training data. Moreover, GLM with 1.25× parameters of BERTLarge achieves the best performance in NLU, conditional and unconditional generation at the same time, which demonstrates its generalizability to different downstream tasks.1 Equal contribution Department of Computer Science and Technology, Tsinghua Univerisity, Beijing, China Beijing Academy of Artificial Intelligence, Beijing, China Massachusetts Institute of Technology, Cambridge, U.S.A. Recurrent AI, Ltd.. Correspondence to: Zhilin Yang <kimi_yang@rcrai.com>, Jie Tang <jietang@tsinghua.edu.cn>. The codes and pre-trained models are available at https: //github.com/THUDM/GLM All [START] NLP tasks are generation tasks All NLP tasks [END] are generation tasks",2021,48,ArXiv,abs/2103.10360,
NLP,d1206ccabd1980848f14472d6548251c2fab7963,Exploring and Predicting Transferability across NLP Tasks,https://www.semanticscholar.org/paper/d1206ccabd1980848f14472d6548251c2fab7963,Conference on Empirical Methods in Natural Language Processing,"['JournalArticle', 'Conference']","Recent advances in NLP demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these models on tasks other than language modeling further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, question answering, and sequence labeling). Our results show that transfer learning is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even when the source task is small or differs substantially from the target task (e.g., part-of-speech tagging transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as source data size, task and domain similarity, and task complexity all play a role in determining transferability.",2020,130,ArXiv,abs/2005.00770,
NLP,30f233eecca2239ee1dd754914324092e53f8f19,Evaluation Examples are not Equally Informative: How should that change NLP Leaderboards?,https://www.semanticscholar.org/paper/30f233eecca2239ee1dd754914324092e53f8f19,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Leaderboards are widely used in NLP and push the field forward. While leaderboards are a straightforward ranking of NLP models, this simplicity can mask nuances in evaluation items (examples) and subjects (NLP models). Rather than replace leaderboards, we advocate a re-imagining so that they better highlight if and where progress is made. Building on educational testing, we create a Bayesian leaderboard model where latent subject skill and latent item difficulty predict correct responses. Using this model, we analyze the ranking reliability of leaderboards. Afterwards, we show the model can guide what to annotate, identify annotation errors, detect overfitting, and identify informative examples. We conclude with recommendations for future benchmark tasks.",2021,47,,,4486-4503
NLP,df7336844a31165db0ae08f1cd0f560c9e3faeea,BadNL: Backdoor Attacks Against NLP Models,https://www.semanticscholar.org/paper/df7336844a31165db0ae08f1cd0f560c9e3faeea,arXiv.org,['JournalArticle'],"Machine learning (ML) has progressed rapidly during the past decade and ML models have been deployed in various real-world applications. Meanwhile, machine learning models have been shown to be vulnerable to various security and privacy attacks. One attack that has attracted a great deal of attention recently is the backdoor attack. Specifically, the adversary poisons the target model training set, to mislead any input with an added secret trigger to a target class, while keeping the accuracy for original inputs unchanged. 
Previous backdoor attacks mainly focus on computer vision tasks. In this paper, we present the first systematic investigation of the backdoor attack against models designed for natural language processing (NLP) tasks. Specifically, we propose three methods to construct triggers in the NLP setting, including Char-level, Word-level, and Sentence-level triggers. Our Attacks achieve an almost perfect success rate without jeopardizing the original model utility. For instance, using the word-level triggers, our backdoor attack achieves 100% backdoor accuracy with only a drop of 0.18%, 1.26%, and 0.19% in the models utility, for the IMDB, Amazon, and Stanford Sentiment Treebank datasets, respectively.",2020,129,ArXiv,abs/2006.01043,
NLP,c4cdf2e0d89aadb13bf9c61654ff9e17be2b01b9,BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements,https://www.semanticscholar.org/paper/c4cdf2e0d89aadb13bf9c61654ff9e17be2b01b9,Asia-Pacific Computer Systems Architecture Conference,"['Book', 'JournalArticle', 'Conference']","Deep neural networks (DNNs) have progressed rapidly during the past decade and have been deployed in various real-world applications. Meanwhile, DNN models have been shown to be vulnerable to security and privacy attacks. One such attack that has attracted a great deal of attention recently is the backdoor attack. Specifically, the adversary poisons the target model’s training set to mislead any input with an added secret trigger to a target class. Previous backdoor attacks predominantly focus on computer vision (CV) applications, such as image classification. In this paper, we perform a systematic investigation of backdoor attack on NLP models, and propose BadNL, a general NLP backdoor attack framework including novel attack methods. Specifically, we propose three methods to construct triggers, namely BadChar, BadWord, and BadSentence, including basic and semantic-preserving variants. Our attacks achieve an almost perfect attack success rate with a negligible effect on the original model’s utility. For instance, using the BadChar, our backdoor attack achieves a 98.9% attack success rate with yielding a utility improvement of 1.5% on the SST-5 dataset when only poisoning 3% of the original set. Moreover, we conduct a user study to prove that our triggers can well preserve the semantics from humans perspective.",2020,119,Proceedings of the 37th Annual Computer Security Applications Conference,,
NLP,e02a757617c2c42eb62889cc4d4aee3765928303,The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus,https://www.semanticscholar.org/paper/e02a757617c2c42eb62889cc4d4aee3765928303,arXiv.org,['JournalArticle'],"In order to address increasing demands of real-world applications, the research for knowledge-intensive NLP (KI-NLP) should advance by capturing the challenges of a truly open-domain environment: web-scale knowledge, lack of structure, inconsistent quality and noise. To this end, we propose a new setup for evaluating existing knowledge intensive tasks in which we generalize the background corpus to a universal web snapshot. We investigate a slate of NLP tasks which rely on knowledge - either factual or common sense, and ask systems to use a subset of CCNet - the Sphere corpus - as a knowledge source. In contrast to Wikipedia, otherwise a common background corpus in KI-NLP, Sphere is orders of magnitude larger and better reflects the full diversity of knowledge on the web. Despite potential gaps in coverage, challenges of scale, lack of structure and lower quality, we find that retrieval from Sphere enables a state of the art system to match and even outperform Wikipedia-based models on several tasks. We also observe that while a dense index can outperform a sparse BM25 baseline on Wikipedia, on Sphere this is not yet possible. To facilitate further research and minimise the community's reliance on proprietary, black-box search engines, we share our indices, evaluation metrics and infrastructure.",2021,46,ArXiv,abs/2112.09924,
NLP,3924aa213ff891812c66a6909ab902684d3eb107,AraVec: A set of Arabic Word Embedding Models for use in Arabic NLP,https://www.semanticscholar.org/paper/3924aa213ff891812c66a6909ab902684d3eb107,International Conference on Arabic Computational Linguistics,['JournalArticle'],,2017,402,,,256-265
NLP,00cd2650a89734105fa0c0aba3bf07935b318290,GLUECoS: An Evaluation Benchmark for Code-Switched NLP,https://www.semanticscholar.org/paper/00cd2650a89734105fa0c0aba3bf07935b318290,Annual Meeting of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks.",2020,110,,,3575-3585
NLP,e1e43d6bdb1419e08af833cf4899a460f70da26c,AlBERTo: Italian BERT Language Understanding Model for NLP Challenging Tasks Based on Tweets,https://www.semanticscholar.org/paper/e1e43d6bdb1419e08af833cf4899a460f70da26c,Italian Conference on Computational Linguistics,['JournalArticle'],"English. Recent scientific studies on natural language processing (NLP) report the outstanding effectiveness observed in the use of context-dependent and task-free language understanding models such as ELMo, GPT, and BERT. Specifically, they have proved to achieve state of the art performance in numerous complex NLP tasks such as question answering and sentiment analysis in the English language. Following the great popularity and effectiveness that these models are gaining in the scientific community, we trained a BERT language understanding model for the Italian language (AlBERTo). In particular, AlBERTo is focused on the language used in social networks, specifically on Twitter. To demonstrate its robustness, we evaluated AlBERTo on the EVALITA 2016 task SENTIPOLC (SENTIment POLarity Classification) obtaining state of the art results in subjectivity, polarity and irony detection on Italian tweets. The pre-trained AlBERTo model will be publicly distributed through the GitHub platform at the following web address: https://github.com/ marcopoli/AlBERTo-it in order to facilitate future research.",2019,187,,,
NLP,3ca3ff98405b43fab32dcd7cbd6bd34261386e35,Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models,https://www.semanticscholar.org/paper/3ca3ff98405b43fab32dcd7cbd6bd34261386e35,NAACL-HLT,['JournalArticle'],"Recently, NLP models have achieved remarkable progress across a variety of tasks; however, they have also been criticized for being not robust. Many robustness problems can be attributed to models exploiting spurious correlations, or shortcuts between the training data and the task labels. Most existing work identifies a limited set of task-specific shortcuts via human priors or error analyses, which requires extensive expertise and efforts. In this paper, we aim to automatically identify such spurious correlations in NLP models at scale. We first leverage existing interpretability methods to extract tokens that significantly affect model's decision process from the input text. We then distinguish""genuine""tokens and""spurious""tokens by analyzing model predictions across multiple corpora and further verify them through knowledge-aware perturbations. We show that our proposed method can effectively and efficiently identify a scalable set of""shortcuts"", and mitigating these leads to more robust models in multiple applications.",2021,45,,,1719-1729
NLP,b48cf1158ea6fb8347aac390ac3303efe697e305,Triggerless Backdoor Attack for NLP Tasks with Clean Labels,https://www.semanticscholar.org/paper/b48cf1158ea6fb8347aac390ac3303efe697e305,North American Chapter of the Association for Computational Linguistics,"['JournalArticle', 'Conference']","Backdoor attacks pose a new threat to NLP models. A standard strategy to construct poisoned data in backdoor attacks is to insert triggers (e.g., rare words) into selected sentences and alter the original label to a target label. This strategy comes with a severe flaw of being easily detected from both the trigger and the label perspectives: the trigger injected, which is usually a rare word, leads to an abnormal natural language expression, and thus can be easily detected by a defense model; the changed target label leads the example to be mistakenly labeled, and thus can be easily detected by manual inspections. To deal with this issue, in this paper, we propose a new strategy to perform textual backdoor attack which does not require an external trigger and the poisoned samples are correctly labeled. The core idea of the proposed strategy is to construct clean-labeled examples, whose labels are correct but can lead to test label changes when fused with the training set. To generate poisoned clean-labeled examples, we propose a sentence generation model based on the genetic algorithm to cater to the non-differentiable characteristic of text data. Extensive experiments demonstrate that the proposed attacking strategy is not only effective, but more importantly, hard to defend due to its triggerless and clean-labeled nature. Our work marks the first step towards developing triggerless attacking strategies in NLP.",2021,41,ArXiv,abs/2111.07970,
Quantum Computing,f3d594544126e202dbd81c186ca3ce448af5255c,Quantum Computing in the NISQ era and beyond,https://www.semanticscholar.org/paper/f3d594544126e202dbd81c186ca3ce448af5255c,Quantum,,"Noisy Intermediate-Scale Quantum (NISQ) technology will be available in the near future. Quantum computers with 50-100 qubits may be able to perform tasks which surpass the capabilities of today's classical digital computers, but noise in quantum gates will limit the size of quantum circuits that can be executed reliably. NISQ devices will be useful tools for exploring many-body quantum physics, and may have other useful applications, but the 100-qubit quantum computer will not change the world right away - we should regard it as a significant step toward the more powerful quantum technologies of the future. Quantum technologists should continue to strive for more accurate quantum gates and, eventually, fully fault-tolerant quantum computing.",2018,5248,Quantum,,
Quantum Computing,f9253a3e2627f1c2a0a7e2cea320a4ec4e4d2ff9,Evidence for the utility of quantum computing before fault tolerance,https://www.semanticscholar.org/paper/f9253a3e2627f1c2a0a7e2cea320a4ec4e4d2ff9,Nature,['JournalArticle'],,2023,284,Nature,618,500 - 505
Quantum Computing,ea160adc0d78e54669281b8b145bcd832e648fee,Quantum computing for finance,https://www.semanticscholar.org/paper/ea160adc0d78e54669281b8b145bcd832e648fee,Nature Reviews Physics,"['JournalArticle', 'Review']",,2023,38,Nature Reviews Physics,5,450-465
Quantum Computing,194073c405e9c362c955e9ac31979ddbc037ff8d,Quantum Computing for High-Energy Physics: State of the Art and Challenges. Summary of the QC4HEP Working Group,https://www.semanticscholar.org/paper/194073c405e9c362c955e9ac31979ddbc037ff8d,,,"Quantum computers offer an intriguing path for a paradigmatic change of computing in the natural sciences and beyond, with the potential for achieving a so-called quantum advantage, namely a significant (in some cases exponential) speed-up of numerical simulations. The rapid development of hardware devices with various realizations of qubits enables the execution of small scale but representative applications on quantum computers. In particular, the high-energy physics community plays a pivotal role in accessing the power of quantum computing, since the field is a driving source for challenging computational problems. This concerns, on the theoretical side, the exploration of models which are very hard or even impossible to address with classical techniques and, on the experimental side, the enormous data challenge of newly emerging experiments, such as the upgrade of the Large Hadron Collider. In this roadmap paper, led by CERN, DESY and IBM, we provide the status of high-energy physics quantum computations and give examples for theoretical and experimental target benchmark applications, which can be addressed in the near future. Having the IBM 100 x 100 challenge in mind, where possible, we also provide resource estimates for the examples given using error mitigated quantum computing.",2023,33,,,
Quantum Computing,53103ae318a19569ac82cee5062de2cf73bf386c,Splitting phonons: Building a platform for linear mechanical quantum computing,https://www.semanticscholar.org/paper/53103ae318a19569ac82cee5062de2cf73bf386c,Science,['JournalArticle'],"Linear optical quantum computing provides a desirable approach to quantum computing, with only a short list of required computational elements. The similarity between photons and phonons points to the interesting potential for linear mechanical quantum computing using phonons in place of photons. Although single-phonon sources and detectors have been demonstrated, a phononic beam splitter element remains an outstanding requirement. Here we demonstrate such an element, using two superconducting qubits to fully characterize a beam splitter with single phonons. We further use the beam splitter to demonstrate two-phonon interference, a requirement for two-qubit gates in linear computing. This advances a new solid-state system for implementing linear quantum computing, further providing straightforward conversion between itinerant phonons and superconducting qubits. Description Editor’s summary Phonons are the fundamental quantum vibrations within materials, with individual phonons representing the collective motion of many trillions of atoms. Efforts are underway to determine whether these mechanical vibrations can be developed into a quantum-computing architecture just like their optical cousin, photons. Qiao et al. demonstrate a beam splitter for single phonons and controlled two-phonon interference. Adding to the ability to launch and detect single phonons, a beam splitter now provides the final piece in the toolbox to develop a mechanically based platform for quantum computing. —Ian S. Osborne A beam splitter for phonons completes the toolbox required to develop a mechanically based quantum computing system.",2023,21,Science,380,1030 - 1033
Quantum Computing,6e74403ab75d0080c056fd66702ab1f54f04d9b1,The state of quantum computing applications in health and medicine,https://www.semanticscholar.org/paper/6e74403ab75d0080c056fd66702ab1f54f04d9b1,Research Directions: Quantum Technologies,"['JournalArticle', 'Review']","
 Quantum computing hardware and software have made enormous strides over the last years1. Questions around quantum computing’s impact on research and society have changed from “if” to “when/how”. The 2020s have been described as the “quantum decade”, and the first production solutions that drive scientific and business value are expected to become available over the next years. Medicine, including fields in healthcare and life sciences, has seen a flurry of quantum-related activities and experiments in the last few years (although medicine and quantum theory have arguably been entangled ever since Schrödinger’s cat2). The initial focus was on biochemical and computational biology problems3,4,5,6,7,8; recently, however, clinical and medical quantum solutions have drawn increasing interest. The rapid emergence of quantum computing in health and medicine necessitates a mapping of the landscape.
 In this review, clinical and medical proof-of-concept quantum computing applications are outlined and put into perspective. These consist of over 40 experimental and theoretical studies from the last few years. The use case areas span genomics, clinical research and discovery, diagnostics, and treatments and interventions. Quantum machine learning (QML) in particular has rapidly evolved and shown to be competitive with classical benchmarks in recent medical research. Near-term QML algorithms, for instance, quantum support vector classifiers and quantum neural networks, have been trained with diverse clinical and real-world data sets. This includes studies in generating new molecular entities as drug candidates, diagnosing based on medical image classification, predicting patient persistence, forecasting treatment effectiveness, and tailoring radiotherapy. The use cases and the applied algorithms are summarized.
 In addition, this review provides an outlook on medicine in the quantum era. There has been much discussion about healthcare’s journey towards precision medicine and the quadruple aim (better health, lower costs, enhanced patient experiences, and improved healthcare practitioner work lives)9. While a range of technical and ethical challenges remain, quantum computing is poised to become a key enabler for advancing towards the holy grail: keeping people healthy through proactive medical care and guidance at the level of an individual.",2023,13,Research Directions: Quantum Technologies,,
Quantum Computing,89a30b5dab02c9c390a632acad481fa602859272,The future of quantum computing with superconducting qubits,https://www.semanticscholar.org/paper/89a30b5dab02c9c390a632acad481fa602859272,Journal of Applied Physics,,"For the first time in history, we are seeing a branching point in computing paradigms with the emergence of quantum processing units (QPUs). Extracting the full potential of computation and realizing quantum algorithms with a super-polynomial speedup will most likely require major advances in quantum error correction technology. Meanwhile, achieving a computational advantage in the near term may be possible by combining multiple QPUs through circuit knitting techniques, improving the quality of solutions through error suppression and mitigation, and focusing on heuristic versions of quantum algorithms with asymptotic speedups. For this to happen, the performance of quantum computing hardware needs to improve and software needs to seamlessly integrate quantum and classical processors together to form a new architecture that we are calling quantum-centric supercomputing. In the long term, we see hardware that exploits qubit connectivity in higher than 2D topologies to realize more efficient quantum error correcting codes, modular architectures for scaling QPUs and parallelizing workloads, and software that evolves to make the intricacies of the technology invisible to the users and realize the goal of ubiquitous, frictionless quantum computing.",2022,109,Journal of Applied Physics,,
Quantum Computing,fb5413afba689d16543215c5a2ddbc5b78a52007,A Survey of Quantum Computing for Finance,https://www.semanticscholar.org/paper/fb5413afba689d16543215c5a2ddbc5b78a52007,,['Review'],"Quantum computers are expected to surpass the computational capabilities of classical computers during this decade and have transformative impact on numerous industry sectors, particularly finance. In fact, finance is estimated to be the first industry sector to benefit from quantum computing, not only in the medium and long terms, but even in the short term. This survey paper presents a comprehensive summary of the state of the art of quantum computing for financial applications, with particular emphasis on stochastic modeling, optimization, and machine learning, describing how these solutions, adapted to work on a quantum computer, can potentially help to solve financial problems, such as derivative pricing, risk modeling, portfolio optimization, natural language processing, and fraud detection, more efficiently and accurately. We also discuss the feasibility of these algorithms on nearterm quantum computers with various hardware implementations and demonstrate how they relate to a wide range of use cases in finance. We hope this article will not only serve as a reference for academic researchers and industry practitioners but also inspire new ideas for future research. These authors contributed equally to this work. i ar X iv :2 20 1. 02 77 3v 4 [ qu an tph ] 2 7 Ju n 20 22",2022,89,,,
Quantum Computing,e5194ae88d63c7549678b1b73cfdaf7112164272,Erasure conversion for fault-tolerant quantum computing in alkaline earth Rydberg atom arrays,https://www.semanticscholar.org/paper/e5194ae88d63c7549678b1b73cfdaf7112164272,Nature Communications,['JournalArticle'],,2022,73,Nature Communications,13,
Quantum Computing,6c260fb515bd0a75b4c49bd40ab7a7cf9c9262f5,MQT Bench: Benchmarking Software and Design Automation Tools for Quantum Computing,https://www.semanticscholar.org/paper/6c260fb515bd0a75b4c49bd40ab7a7cf9c9262f5,Quantum,['JournalArticle'],"Quantum software tools for a wide variety of design tasks on and across different levels of abstraction are crucial in order to eventually realize useful quantum applications. This requires practical and relevant benchmarks for new software tools to be empirically evaluated and compared to the current state of the art. Although benchmarks for specific design tasks are commonly available, the demand for an overarching cross-level benchmark suite has not yet been fully met and there is no mutual consolidation in how quantum software tools are evaluated thus far. In this work, we propose the MQT Bench benchmark suite (as part of the Munich Quantum Toolkit, MQT) based on four core traits: (1) cross-level support for different abstraction levels, (2) accessibility via an easy-to-use web interface (https://www.cda.cit.tum.de/mqtbench/) and a Python package, (3) provision of a broad selection of benchmarks to facilitate generalizability, as well as (4) extendability to future algorithms, gate-sets, and hardware architectures. By comprising more than 70,000 benchmark circuits ranging from 2 to 130 qubits on four abstraction levels, MQT Bench presents a first step towards benchmarking different abstraction levels with a single benchmark suite to increase comparability, reproducibility, and transparency.",2022,41,Quantum,7,1062
Quantum Computing,f8e57fa370fe10147aa22714e08409fc1b7dae4b,Perspective on the Current State-of-the-Art of Quantum Computing for Drug Discovery Applications,https://www.semanticscholar.org/paper/f8e57fa370fe10147aa22714e08409fc1b7dae4b,Journal of Chemical Theory and Computation,"['Review', 'JournalArticle']","Computational chemistry is an essential tool in the pharmaceutical industry. Quantum computing is a fast evolving technology that promises to completely shift the computational capabilities in many areas of chemical research by bringing into reach currently impossible calculations. This perspective illustrates the near-future applicability of quantum computation of molecules to pharmaceutical problems. We briefly summarize and compare the scaling properties of state-of-the-art quantum algorithms and provide novel estimates of the quantum computational cost of simulating progressively larger embedding regions of a pharmaceutically relevant covalent protein–drug complex involving the drug Ibrutinib. Carrying out these calculations requires an error-corrected quantum architecture that we describe. Our estimates showcase that recent developments on quantum phase estimation algorithms have dramatically reduced the quantum resources needed to run fully quantum calculations in active spaces of around 50 orbitals and electrons, from estimated over 1000 years using the Trotterization approach to just a few days with sparse qubitization, painting a picture of fast and exciting progress in this nascent field.",2022,40,Journal of Chemical Theory and Computation,18,7001 - 7023
Quantum Computing,2ddcd47b28eb4b43317a34cf56e83309f5347699,Polariton condensates for classical and quantum computing,https://www.semanticscholar.org/paper/2ddcd47b28eb4b43317a34cf56e83309f5347699,Nature Reviews Physics,['Review'],,2022,63,Nature Reviews Physics,4,435 - 451
Quantum Computing,e2e7d964c09e27d334fcb8761d69918630629387,"Near-term quantum computing techniques: Variational quantum algorithms, error mitigation, circuit compilation, benchmarking and classical simulation",https://www.semanticscholar.org/paper/e2e7d964c09e27d334fcb8761d69918630629387,Science China Physics Mechanics and Astronomy,"['JournalArticle', 'Review']",,2022,30,"Science China Physics, Mechanics & Astronomy",66,1-50
Quantum Computing,ef35da3a3c471a6a15c7a3b09586483eb50cbef0,Practical application-specific advantage through hybrid quantum computing,https://www.semanticscholar.org/paper/ef35da3a3c471a6a15c7a3b09586483eb50cbef0,arXiv.org,['JournalArticle'],"Quantum computing promises to tackle technological and industrial problems insurmountable for classical computers. However, today's quantum computers still have limited demonstrable functionality, and it is expected that scaling up to millions of qubits is required for them to live up to this touted promise. The feasible route in achieving practical quantum advantage goals is to implement a hybrid operational mode that realizes the cohesion of quantum and classical computers. Here we present a hybrid quantum cloud based on a memory-centric and heterogeneous multiprocessing architecture, integrated into a high-performance computing data center grade environment. We demonstrate that utilizing the quantum cloud, our hybrid quantum algorithms including Quantum Encoding (QuEnc), Hybrid Quantum Neural Networks and Tensor Networks enable advantages in optimization, machine learning, and simulation fields. We show the advantage of hybrid algorithms compared to standard classical algorithms in both the computational speed and quality of the solution. The achieved advance in hybrid quantum hardware and software makes quantum computing useful in practice today.",2022,28,ArXiv,abs/2205.04858,
Quantum Computing,dd5fc2d34af35c6c7428205fff04c8f527b9e8d4,Distributed Quantum Computing: a Survey,https://www.semanticscholar.org/paper/dd5fc2d34af35c6c7428205fff04c8f527b9e8d4,arXiv.org,"['JournalArticle', 'Review']","Nowadays, quantum computing has reached the engineering phase, with fully-functional quantum processors integrating hundred of noisy qubits available. Yet – to fully unveil the potential of quantum computing out of the labs and into business reality – the challenge ahead is to substantially scale the qubit number, reaching orders of magnitude exceeding the thousands (if not millions) of noise-free qubits. To this aim, there exists a broad consensus among both academic and industry communities about considering the distributed computing paradigm as the key solution for achieving such a scaling, by envision multiple moderate-to-small-scale quantum processors communicating and cooperating to execute computational tasks exceeding the computational resources available within a single processing device. The aim of this survey is to provide the reader with an overview about the main challenges and open problems arising with distributed quantum computing, and with an easy access and guide towards the relevant literature and the prominent results from a computer/communications engineering perspective.",2022,28,ArXiv,abs/2212.10609,
Quantum Computing,b000a4b30f6206f6cfb033a79aad1ba810c972a4,Perceval: A Software Platform for Discrete Variable Photonic Quantum Computing,https://www.semanticscholar.org/paper/b000a4b30f6206f6cfb033a79aad1ba810c972a4,Quantum,['JournalArticle'],"We introduce Perceval, an open-source software platform for simulating and interfacing with discrete-variable photonic quantum computers, and describe its main features and components. Its Python front-end allows photonic circuits to be composed from basic photonic building blocks like photon sources, beam splitters, phase-shifters and detectors. A variety of computational back-ends are available and optimised for different use-cases. These use state-of-the-art simulation techniques covering both weak simulation, or sampling, and strong simulation. We give examples of Perceval in action by reproducing a variety of photonic experiments and simulating photonic implementations of a range of quantum algorithms, from Grover's and Shor's to examples of quantum machine learning. Perceval is intended to be a useful toolkit for experimentalists wishing to easily model, design, simulate, or optimise a discrete-variable photonic experiment, for theoreticians wishing to design algorithms and applications for discrete-variable photonic quantum computing platforms, and for application designers wishing to evaluate algorithms on available state-of-the-art photonic quantum computers.",2022,26,Quantum,7,931
Quantum Computing,0258bab20bc8574ee602012081a17db89339f12d,Materials challenges and opportunities for quantum computing hardware,https://www.semanticscholar.org/paper/0258bab20bc8574ee602012081a17db89339f12d,Science,"['Review', 'JournalArticle']","Combatting noise on the platform The potential of quantum computers to solve problems that are intractable for classical computers has driven advances in hardware fabrication. In practice, the main challenge in realizing quantum computers is that general, many-particle quantum states are highly sensitive to noise, which inevitably causes errors in quantum algorithms. Some noise sources are inherent to the current materials platforms. de Leon et al. review some of the materials challenges for five platforms for quantum computers and propose directions for their solution. Science, this issue p. eabb2823 BACKGROUND The past two decades have seen intense efforts aimed at building quantum computing hardware with the potential to solve problems that are intractable on classical computers. Several hardware platforms for quantum information processing (QIP) are under active development. To realize large-scale systems based on these technologies, we must achieve error rates much lower than have been demonstrated thus far in a scalable platform, or devise a new platform entirely. These activities will require major advances in materials science and engineering, new fabrication and synthesis techniques, and new measurement and materials analysis techniques. We identify key materials challenges that currently limit progress in five quantum computing hardware platforms, propose how to tackle these problems, and discuss some new areas for exploration. Addressing these materials challenges will necessitate interdisciplinary approaches from scientists and engineers beyond the current boundaries of the quantum computing field. ADVANCES This Review constitutes a roadmap of the current challenges and opportunities for materials science in quantum information processing. We provide a comprehensive review of materials issues in each physical platform by describing the evidence that has led to the current understanding of each problem. For each platform, we present reasons for particular material choices, survey the current understanding of sources of noise and dissipation, describe materials limitations to scaling, and discuss potential new material platforms. Despite major differences among physical implementations in each hardware technology, there are several common themes: Material selection is driven by heterogeneity, impurities, and defects in available materials. Poorly controlled and characterized surfaces lead to noise and dissipation beyond limits imposed by bulk properties. Scaling to larger systems gives rise to new materials problems that are not evident in single-qubit measurements. OUTLOOK We identify three principal materials research frontiers of interest in this context. First, understanding the microscopic mechanisms that lead to noise, loss, and decoherence is crucial. This would be accelerated by developing high-throughput methods for correlating qubit measurement with direct materials spectroscopy and characterization. Second, relatively few material platforms for solid-state QIP have been explored thus far, and the discovery of a new platform is often serendipitous. It is thus important to develop materials discovery pipelines that exploit directed, rational material searches in concert with high-throughput characterization approaches aimed at rapid screening for properties relevant to QIP. Third, there are several materials issues that do not affect single-qubit operations but appear as limitations in scaling to larger systems. Many problems faced by these platforms are reminiscent of some that have been addressed over the past five decades for complementary metal-oxide semiconductor electronics and other areas of the semiconductor industry, and approaches and solutions adopted by that industry may be applicable to QIP platforms. Materials issues will be critical to address in the coming years as we transition from noisy intermediate-scale systems to large-scale, fault-tolerant systems. Quantum computing began as a fundamentally interdisciplinary effort involving computer science, information science, and quantum physics; the time is now ripe for expanding the field by including new collaborations and partnerships with materials science. Five quantum computing hardware platforms. From top left: Optical image of an IBM superconducting qubit processor (inset: cartoon of a Josephson junction); SEM image of gate-defined semiconductor quantum dots (inset: cartoon depicting the confining potential); ultraviolet photoluminescence image showing emission from color centers in diamond (inset: atomistic model of defects); picture of a surface-electrode ion trap (inset: cartoon of ions confined above the surface); false-colored SEM image of a hybrid semiconductor/superconductor [inset: cartoon of an epitaxial superconducting Al shell (blue) on a faceted semiconducting InAs nanowire (orange)]. IBM IMAGE, CC BY-ND 2.0; SEM IMAGE COURTESY OF S. NEYENS AND M. A. ERIKSSON; PHOTOLUMINESCENCE IMAGE COURTESY OF N. P. DE LEON; FALSE-COLORED SEM IMAGE COURTESY OF C. MARCUS, P. KROGSTRUP, AND D. RAZMADZE Quantum computing hardware technologies have advanced during the past two decades, with the goal of building systems that can solve problems that are intractable on classical computers. The ability to realize large-scale systems depends on major advances in materials science, materials engineering, and new fabrication techniques. We identify key materials challenges that currently limit progress in five quantum computing hardware platforms, propose how to tackle these problems, and discuss some new areas for exploration. Addressing these materials challenges will require scientists and engineers to work together to create new, interdisciplinary approaches beyond the current boundaries of the quantum computing field.",2021,215,Science,372,
Quantum Computing,b977e8de38dc0d13817bca1ed20036badfe2a58c,Pulse based Variational Quantum Optimal Control for hybrid quantum computing,https://www.semanticscholar.org/paper/b977e8de38dc0d13817bca1ed20036badfe2a58c,Quantum,['JournalArticle'],"This work studies pulse based variational quantum algorithms (VQAs), which are designed to determine the ground state of a quantum mechanical system by combining classical and quantum hardware. In contrast to more standard gate based methods, pulse based methods aim to directly optimize the laser pulses interacting with the qubits, instead of using some parametrized gate based circuit. Using the mathematical formalism of optimal control, these laser pulses are optimized. This method has been used in quantum computing to optimize pulses for quantum gate implementations, but has only recently been proposed for full optimization in VQAs. Pulse based methods have several advantages over gate based methods such as faster state preparation, simpler implementation and more freedom in moving through the state space. Based on these ideas, we present the development of a novel adjoint based variational method. This method can be tailored towards and applied in neutral atom quantum computers. This method of pulse based variational quantum optimal control is able to approximate molecular ground states of simple molecules up to chemical accuracy and is able to compete with the gate based variational quantum eigensolver in terms of total number of quantum evaluations. The total evolution time T and the form of the control Hamiltonian Hc are important factors in the convergence behavior to the ground state energy, both having influence on the quantum speed limit and the controllability of the system.",2022,15,Quantum,7,908
Quantum Computing,dc10a3f4dae2db48148ff6781454ddcc856ae8da,Software Architecture for Quantum Computing Systems - A Systematic Review,https://www.semanticscholar.org/paper/dc10a3f4dae2db48148ff6781454ddcc856ae8da,Journal of Systems and Software,"['JournalArticle', 'Review']","Quantum computing systems rely on the principles of quantum mechanics to perform a multitude of computationally challenging tasks more efficiently than their classical counterparts. The architecture of software-intensive systems can empower architects who can leverage architecture-centric processes, practices, description languages, etc., to model, develop, and evolve quantum computing software (quantum software for short) at higher abstraction levels. We conducted a systematic literature review (SLR) to investigate (i) architectural process, (ii) modeling notations, (iii) architecture design patterns, (iv) tool support, and (iv) challenging factors for quantum software architecture. Results of the SLR indicate that quantum software represents a new genre of software-intensive systems; however, existing processes and notations can be tailored to derive the architecting activities and develop modeling languages for quantum software. Quantum bits (Qubits) mapped to Quantum gates (Qugates) can be represented as architectural components and connectors that implement quantum software. Tool-chains can incorporate reusable knowledge and human roles (e.g., quantum domain engineers, quantum code developers) to automate and customize the architectural process. Results of this SLR can facilitate researchers and practitioners to develop new hypotheses to be tested, derive reference architectures, and leverage architecture-centric principles and practices to engineer emerging and next generations of quantum software.",2022,20,J. Syst. Softw.,201,111682
Quantum Computing,4b1280229ced73f6c86550f24ef01490fde52285,Multicore Quantum Computing,https://www.semanticscholar.org/paper/4b1280229ced73f6c86550f24ef01490fde52285,Physical Review Applied,,"Any architecture for practical quantum computing must be scalable. An attractive approach is to create multiple cores , computing regions of ﬁxed size that are well-spaced but interlinked with communication channels. This exploded architecture can relax the demands associated with a single monolithic device: the complexity of control, cooling and power infrastructure as well as the diﬃculties of cross-talk suppression and near-perfect component yield. Here we explore interlinked multicore architectures through analytic and numerical modelling. While elements of our analysis are relevant to diverse platforms, our focus is on semiconductor electron spin systems in which numerous cores may exist on a single chip within a single fridge. We model shuttling and microwave-based interlinks and estimate the achievable ﬁdelities, ﬁnding values that are encouraging but markedly inferior to intra-core operations. We therefore introduce optimised entanglement puriﬁcation to enable high-ﬁdelity communication, ﬁnding that 99 . 5% is a very realistic goal. We then assess the prospects for quantum advantage using such devices in the NISQ-era and beyond: we simulate recently proposed exponentially-powerful error mitigation schemes in the multicore environment and conclude that these techniques impressively suppress imperfections in both the inter- and intra-core operations.",2022,22,Physical Review Applied,,
Quantum Computing,329d31f881a17861eedeef6a9d8fd509cddd2b7c,QUARK: A Framework for Quantum Computing Application Benchmarking,https://www.semanticscholar.org/paper/329d31f881a17861eedeef6a9d8fd509cddd2b7c,International Conference on Quantum Computing and Engineering,"['JournalArticle', 'Conference']","Quantum computing (QC) is anticipated to provide a speedup over classical approaches for specific problems in optimization, simulation, and machine learning. With the advances in quantum computing toward practical applications, the need to analyze and compare different quantum solutions is increasing. While different low-level benchmarks exist, they often do not provide sufficient insights into real-world application-level performance. We propose an application-centric benchmark method and the QUantum computing Application benchmaRK (QUARK) framework to foster the investigation and creation of application benchmarks for QC. This paper establishes three significant contributions: (1) it makes a case for application-level benchmarks and provides an in-depth ""pen and paper"" benchmark formulation of two reference problems: robot path and vehicle option optimization from the industrial domain; (2) it proposes the open-source QUARK framework for designing, implementing, executing, and analyzing benchmarks; (3) it provides multiple reference implementations for these two reference problems based on different known, and where needed, extended, classical and quantum algorithmic approaches and analyzes their performance on different types of infrastructures.",2022,19,2022 IEEE International Conference on Quantum Computing and Engineering (QCE),,226-237
Quantum Computing,f397b593de771752e7002a954eb531f3ef6a975e,A Systematic Literature Review of Quantum Computing for Routing Problems,https://www.semanticscholar.org/paper/f397b593de771752e7002a954eb531f3ef6a975e,IEEE Access,"['JournalArticle', 'Review']","Quantum Computing is drawing a significant attention from the current scientific community. The potential advantages offered by this revolutionary paradigm has led to an upsurge of scientific production in different fields such as economics, industry, or logistics. The main purpose of this paper is to collect, organize and systematically examine the literature published so far on the application of Quantum Computing to routing problems. To do this, we embrace the well-established procedure named as Systematic Literature Review. Specifically, we provide a unified, self-contained, and end-to-end review of 18 years of research (from 2004 to 2021) in the intersection of Quantum Computing and routing problems through the analysis of 53 different papers. Several interesting conclusions have been drawn from this analysis, which has been formulated to give a comprehensive summary of the current state of the art by providing answers related to the most recurrent type of study (practical or theoretical), preferred solving approaches (dedicated or hybrid), detected open challenges or most used Quantum Computing device, among others.",2022,19,IEEE Access,10,55805-55817
Quantum Computing,3994334c81478a4b17341eb1f494dbccbb73d999,40 years of quantum computing,https://www.semanticscholar.org/paper/3994334c81478a4b17341eb1f494dbccbb73d999,,,,2022,17,Nature Reviews Physics,4,1
Quantum Computing,0574de8b7ea2048a78ae9d2b5d26f315e6fa1ee7,Space-efficient binary optimization for variational quantum computing,https://www.semanticscholar.org/paper/0574de8b7ea2048a78ae9d2b5d26f315e6fa1ee7,npj Quantum Information,,,2022,26,npj Quantum Information,8,
Quantum Computing,1ddb24103c5089fd2bdfc05af41c69f39cfacc88,Demonstration of quantum volume 64 on a superconducting quantum computing system,https://www.semanticscholar.org/paper/1ddb24103c5089fd2bdfc05af41c69f39cfacc88,Quantum Science and Technology,,"We improve the quality of quantum circuits on superconducting quantum computing systems, as measured by the quantum volume (QV), with a combination of dynamical decoupling, compiler optimizations, shorter two-qubit gates, and excited state promoted readout. This result shows that the path to larger QV systems requires the simultaneous increase of coherence, control gate fidelities, measurement fidelities, and smarter software which takes into account hardware details, thereby demonstrating the need to continue to co-design the software and hardware stack for the foreseeable future.",2020,357,Quantum Science & Technology,6,
Quantum Computing,6fed828456964d29517f6caf31b700d8aec82153,Enabling multi-programming mechanism for quantum computing in the NISQ era,https://www.semanticscholar.org/paper/6fed828456964d29517f6caf31b700d8aec82153,Quantum,['JournalArticle'],"NISQ devices have several physical limitations and unavoidable noisy quantum operations, and only small circuits can be executed on a quantum machine to get reliable results. This leads to the quantum hardware under-utilization issue. Here, we address this problem and improve the quantum hardware throughput by proposing a Quantum Multi-programming Compiler (QuMC) to execute multiple quantum circuits on quantum hardware simultaneously. This approach can also reduce the total runtime of circuits. We first introduce a parallelism manager to select an appropriate number of circuits to be executed at the same time. Second, we present two different qubit partitioning algorithms to allocate reliable partitions to multiple circuits – a greedy and a heuristic. Third, we use the Simultaneous Randomized Benchmarking protocol to characterize the crosstalk properties and consider them in the qubit partition process to avoid the crosstalk effect during simultaneous executions. Finally, we enhance the mapping transition algorithm to make circuits executable on hardware using a decreased number of inserted gates. We demonstrate the performance of our QuMC approach by executing circuits of different sizes on IBM quantum hardware simultaneously. We also investigate this method on VQE algorithm to reduce its overhead.",2021,139,ArXiv,abs/2102.05321,
Quantum Computing,410fba9f03212257d0881811802e6620e59bc827,"Quantum Computing: Fundamentals, Implementations and Applications",https://www.semanticscholar.org/paper/410fba9f03212257d0881811802e6620e59bc827,IEEE Open Journal of Nanotechnology,,"Quantum Computing is a technology, which promises to overcome the drawbacks of conventional CMOS technology for high density and high performance applications. Its potential to revolutionize today's computing world is attracting more and more researchers towards this field. However, due to the involvement of quantum properties, many beginners find it difficult to follow the field. Therefore, in this research note an effort has been made to introduce the various aspects of quantum computing to researchers, quantum engineers and scientists. The historical background and basic concepts necessary to understand quantum computation and information processing have been introduced in a lucid manner. Various physical implementations and potential application areas of quantum computation have also been discussed in this paper. Recent developments in each realization, in the context of the DiVincenzo criteria, including ion traps based quantum computing, superconducting quantum computing, nuclear magnetic resonance (NMR) quantum computing, spintronics and semiconductor based quantum computing have been discussed.",2022,15,IEEE Open Journal of Nanotechnology,3,61-77
Quantum Computing,25adff0bb9691b46fee5c0591300d6f3ccf117ab,Quantum computing,https://www.semanticscholar.org/paper/25adff0bb9691b46fee5c0591300d6f3ccf117ab,Electronic Markets,"['JournalArticle', 'Review']",,2022,15,Electronic Markets,32,2525-2536
Quantum Computing,fc77048474ccd34c6507701591c2e6ab3ca647ef,Is quantum computing green? An estimate for an energy-efficiency quantum advantage,https://www.semanticscholar.org/paper/fc77048474ccd34c6507701591c2e6ab3ca647ef,Quantum Science and Technology,,"The quantum advantage threshold determines when a quantum processing unit (QPU) is more efficient with respect to classical computing hardware in terms of algorithmic complexity. The ‘green’ quantum advantage threshold—based on a comparison of energetic efficiency between the two—is going to play a fundamental role in the comparison between quantum and classical hardware. Indeed, its characterization would enable better decisions on energy-saving strategies, e.g. for distributing the workload in hybrid quantum–classical algorithms. Here, we show that the green quantum advantage threshold crucially depends on (a) the quality of the experimental quantum gates and (b) the entanglement generated in the QPU. Indeed, for noisy intermediate-scale quantum hardware and algorithms requiring a moderate amount of entanglement, a classical tensor network emulation can be more energy-efficient at equal final state fidelity than quantum computation. We compute the green quantum advantage threshold for a few paradigmatic examples in terms of algorithms and hardware platforms, and identify algorithms with a power-law decay of singular values of bipartitions—with power-law exponent α≲1 —as the green quantum advantage threshold in the near future.",2022,20,Quantum Science and Technology,8,
Quantum Computing,047286f5b9315a8e8bf56c4fc936e62f21495892,Resource Allocation in Quantum Networks for Distributed Quantum Computing,https://www.semanticscholar.org/paper/047286f5b9315a8e8bf56c4fc936e62f21495892,International Conference on Smart Computing,"['JournalArticle', 'Conference']","The evolution of quantum computing technologies has been advancing at a steady pace in the recent years, and the current trend suggests that it will become available at scale for commercial purposes in the near future. The acceleration can be boosted by pooling compute infrastructures to either parallelize algorithm execution or solve bigger instances that are not feasible on a single quantum computer, which requires an underlying Quantum Internet: the interconnection of quantum computers by quantum links and repeaters to exchange entangled quantum bits. However, Quantum Internet research so far has been focused on provisioning point-to-point flows only, which is suitable for (e.g.) quantum sensing and metrology, but not for distributed quantum computing. In this paper, after a primer on quantum computing and networking, we investigate the requirements and objectives of smart computing on distributed nodes from the perspective of quantum network provisioning. We then design a resource allocation strategy that is evaluated through a comprehensive simulation campaign, whose results highlight the key features and performance issues, and lead the way to further investigation in this direction.",2022,14,2022 IEEE International Conference on Smart Computing (SMARTCOMP),,124-132
Quantum Computing,dec26f0640e3a4fdb116735526302ccb9f49867e,Quantum Computing in a Statistical Context,https://www.semanticscholar.org/paper/dec26f0640e3a4fdb116735526302ccb9f49867e,Annual Review of Statistics and Its Application,['Review'],"Quantum computing is widely considered a frontier of interdisciplinary research and involves fields ranging from computer science to physics and from chemistry to engineering. On the one hand, the stochastic essence of quantum physics results in the random nature of quantum computing; thus, there is an important role for statistics to play in the development of quantum computing. On the other hand, quantum computing has great potential to revolutionize computational statistics and data science. This article provides an overview of the statistical aspect of quantum computing. We review the basic concepts of quantum computing and introduce quantum research topics such as quantum annealing and quantum machine learning, which require statistics to be understood.",2022,11,Annual Review of Statistics and Its Application,,
Quantum Computing,eff6546819d25df0bccdc89f02554a43a4f1c464,Trapped-ion quantum computing: Progress and challenges,https://www.semanticscholar.org/paper/eff6546819d25df0bccdc89f02554a43a4f1c464,Applied Physics Reviews,['Review'],"Trapped ions are among the most promising systems for practical quantum computing (QC). The basic requirements for universal QC have all been demonstrated with ions, and quantum algorithms using few-ion-qubit systems have been implemented. We review the state of the field, covering the basics of how trapped ions are used for QC and their strengths and limitations as qubits. In addition, we discuss what is being done, and what may be required, to increase the scale of trapped ion quantum computers while mitigating decoherence and control errors. Finally, we explore the outlook for trapped-ion QC. In particular, we discuss near-term applications, considerations impacting the design of future systems of trapped ions, and experiments and demonstrations that may further inform these considerations.Trapped ions are among the most promising systems for practical quantum computing (QC). The basic requirements for universal QC have all been demonstrated with ions, and quantum algorithms using few-ion-qubit systems have been implemented. We review the state of the field, covering the basics of how trapped ions are used for QC and their strengths and limitations as qubits. In addition, we discuss what is being done, and what may be required, to increase the scale of trapped ion quantum computers while mitigating decoherence and control errors. Finally, we explore the outlook for trapped-ion QC. In particular, we discuss near-term applications, considerations impacting the design of future systems of trapped ions, and experiments and demonstrations that may further inform these considerations.",2019,773,Applied Physics Reviews,,
Quantum Computing,55fa5be5288f6097ae5bd2dfe58fc07b3b39bfb6,Quantum Computing,https://www.semanticscholar.org/paper/55fa5be5288f6097ae5bd2dfe58fc07b3b39bfb6,,,,2023,0,,,
Quantum Computing,74b63c4cdc719a646ce014d084a0ce0ac66d9139,Compact Ion-Trap Quantum Computing Demonstrator,https://www.semanticscholar.org/paper/74b63c4cdc719a646ce014d084a0ce0ac66d9139,PRX Quantum,,"Quantum information processing is steadily progressing from a purely academic discipline towards applications throughout science and industry. Transitioning from lab-based, proof-of-concept experiments to robust, integrated realizations of quantum information processing hardware is an important step in this process. However, the nature of traditional laboratory setups does not offer itself readily to scaling up system sizes or allow for applications outside of laboratory-grade environments. This transition requires overcoming challenges in engineering and integration without sacrificing the state-of-the-art performance of laboratory implementations. Here, we present a 19-inch rack quantum computing demonstrator based on $^{40}\textrm{Ca}^+$ optical qubits in a linear Paul trap to address many of these challenges. We outline the mechanical, optical, and electrical subsystems. Further, we describe the automation and remote access components of the quantum computing stack. We conclude by describing characterization measurements relevant to digital quantum computing including entangling operations mediated by the Molmer-Sorenson interaction. Using this setup we produce maximally-entangled Greenberger-Horne-Zeilinger states with up to 24 ions without the use of post-selection or error mitigation techniques; on par with well-established conventional laboratory setups.",2021,163,PRX Quantum,,
Quantum Computing,a1ef4052acb63356928bb440874c470ad48cb40c,Application-Oriented Performance Benchmarks for Quantum Computing,https://www.semanticscholar.org/paper/a1ef4052acb63356928bb440874c470ad48cb40c,IEEE Transactions on Quantum Engineering,,"In this work, we introduce an open-source suite of quantum application-oriented performance benchmarks that is designed to measure the effectiveness of quantum computing hardware at executing quantum applications. These benchmarks probe a quantum computer's performance on various algorithms and small applications as the problem size is varied, by mapping out the fidelity of the results as a function of circuit width and depth using the framework of volumetric benchmarking. In addition to estimating the fidelity of results generated by quantum execution, the suite is designed to benchmark certain aspects of the execution pipeline in order to provide end users with a practical measure of both the quality of and the time to solution. Our methodology is constructed to anticipate advances in quantum computing hardware that are likely to emerge in the next five years. This benchmarking suite is designed to be readily accessible to a broad audience of users and provides benchmarks that correspond to many well-known quantum computing algorithms.",2021,95,IEEE Transactions on Quantum Engineering,4,1-32
Quantum Computing,cb03b665069dad5e895a2c244929ea427f1fb9d1,"Emerging GaN technologies for power, RF, digital, and quantum computing applications: Recent advances and prospects",https://www.semanticscholar.org/paper/cb03b665069dad5e895a2c244929ea427f1fb9d1,Journal of Applied Physics,,"GaN technology is not only gaining traction in power and RF electronics but is rapidly expanding into other application areas including digital and quantum computing electronics. This paper provides a glimpse of future GaN device technologies and advanced modeling approaches that can push the boundaries of these applications in terms of performance and reliability. While GaN power devices have recently been commercialized in the 15-900 V classes, new GaN devices are greatly desirable to explore both the higher-voltage and ultralow-voltage power applications. Moving into the RF domain, ultra-high frequency GaN devices are being used to implement digitized power amplifier circuits, and further advances using hardware-software co-design approach can be expected. On the horizon is the GaN CMOS technology, a key missing piece to realize the full-GaN platform with integrated digital, power and RF electronics technologies. Although currently a challenge, high-performance p-type GaN technology will be crucial to realize high-performance GaN CMOS circuits. Due to its excellent transport characteristics and ability to generate free carriers via polarization doping, GaN is expected to be an important technology for ultra-low temperature and quantum computing electronics. Finally, given the increasing cost of hardware prototyping of new devices and circuits, the use of high-fidelity device models and data-driven modeling approaches for technology-circuit co-design are projected to be the trends of the future. In this regard, physically inspired, mathematically robust, less computationally taxing, and predictive modeling approaches are indispensable. With all these and future efforts, we envision GaN to become the next Si for electronics. Journal of Applied Physics 2021 c © 2022 MERL. This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Mitsubishi Electric Research Laboratories, Inc. 201 Broadway, Cambridge, Massachusetts 02139 Emerging GaN technologies for power, RF, digital, and quantum computing applications: recent advances and prospects Koon Hoo Teo,1, a) Yuhao Zhang,2, a) Nadim Chowdhury,3, a) Shaloo Rakheja,4, a) Rui Ma,1, a) Qingyun Xie,3 Eiji Yagyu,5 Koji Yamanaka,6 Kexin Li,4 and Tomas Palacios3 1)Mitsubishi Electric Research Laboratories (MERL), 201 Broadway, 8th floor, Cambridge, MA 02139, USA 2)Center for Power Electronics Systems, the Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA 24060, USA 3)Microsystems Technology Laboratories, Massachusetts Institute of Technology (MIT), 77 Mass. Ave. Cambridge, MA 02139, USA 4)Department of Electrical and Computer Engineering, Holonyak Micro and Nanotechnology Laboratory, University of Illinois at Urbana-Champaign, 208 N Wright St, Urbana, IL 61801, USA 5)Mitsubishi Electric Corporation, Advanced Technology R&D Center, 8-1-1, Tsukaguchi-honmachi, Amagasaki City, 661-8661, Japan 6)Mitsubishi Electric Corporation, Information Technology R&D Center, 5-1-1, Ofuna, Kamakura City, 247-8501, Japan (Dated: 18 September 2021) GaN technology is not only gaining traction in power and RF electronics but is rapidly expanding into other application areas including digital and quantum computing electronics. This paper provides a glimpse of future GaN device technologies and advanced modeling approaches that can push the boundaries of these applications in terms of performance and reliability. While GaN power devices have recently been commercialized in the 15-900 V classes, new GaN devices are greatly desirable to explore both the higher-voltage and ultra-low-voltage power applications. Moving into the RF domain, ultra-high frequency GaN devices are being used to implement digitized power amplifier circuits, and further advances using hardware-software co-design approach can be expected. On the horizon is the GaN CMOS technology, a key missing piece to realize the full-GaN platform with integrated digital, power and RF electronics technologies. Although currently a challenge, high-performance p-type GaN technology will be crucial to realize high-performance GaN CMOS circuits. Due to its excellent transport characteristics and ability to generate free carriers via polarization doping, GaN is expected to be an important technology for ultra-low temperature and quantum computing electronics. Finally, given the increasing cost of hardware prototyping of new devices and circuits, the use of high-fidelity device models and data-driven modeling approaches for technology-circuit co-design are projected to be the trends of the future. In this regard, physically inspired, mathematically robust, less computationally taxing, and predictive modeling approaches are indispensable. With all these and future efforts, we envision GaN to become the next Si for electronics.",2021,100,Journal of Applied Physics,,
Quantum Computing,b4af1cbb4d3a03d3ad7930b906fc7bf6870180cc,Quantum computing,https://www.semanticscholar.org/paper/b4af1cbb4d3a03d3ad7930b906fc7bf6870180cc,,,,2022,1,,,
Quantum Computing,119a9e5b563cf1134897553ee49325b5a5bd9fb9,Applications of single photons to quantum communication and computing,https://www.semanticscholar.org/paper/119a9e5b563cf1134897553ee49325b5a5bd9fb9,Nature Reviews Physics,"['JournalArticle', 'Review']",,2023,35,Nature Reviews Physics,5,326-338
Quantum Computing,549e933821fdf7cd0309dacaae99c8284cbfcc24,Commercial applications of quantum computing,https://www.semanticscholar.org/paper/549e933821fdf7cd0309dacaae99c8284cbfcc24,EPJ Quantum Technology,['JournalArticle'],,2021,71,Epj Quantum Technology,8,
Quantum Computing,ec7f5dc077480df149bcd4358a3aa8441878ca59,Quantum computing models for artificial neural networks,https://www.semanticscholar.org/paper/ec7f5dc077480df149bcd4358a3aa8441878ca59,Europhysics letters,['Review'],"Neural networks are computing models that have been leading progress in Machine Learning (ML) and Artificial Intelligence (AI) applications. In parallel, the first small-scale quantum computing devices have become available in recent years, paving the way for the development of a new paradigm in information processing. Here we give an overview of the most recent proposals aimed at bringing together these ongoing revolutions, and particularly at implementing the key functionalities of artificial neural networks on quantum architectures. We highlight the exciting perspectives in this context, and discuss the potential role of near-term quantum hardware in the quest for quantum machine learning advantage.",2021,57,Europhysics Letters,134,
Quantum Computing,d2a505586c0da20752b98f63c7760b6a5c41e28d,Industry quantum computing applications,https://www.semanticscholar.org/paper/d2a505586c0da20752b98f63c7760b6a5c41e28d,EPJ Quantum Technology,['Review'],,2021,59,EPJ Quantum Technology,8,
Quantum Computing,8f2cf30f9c825d8ef7d622601dbd525ace95e025,Quantum computing 40 years later,https://www.semanticscholar.org/paper/8f2cf30f9c825d8ef7d622601dbd525ace95e025,,,"Forty years ago, Richard Feynman proposed harnessing quantum physics to build a more powerful kind of computer. Realizing Feynman's vision is one of the grand challenges facing 21st century science and technology. In this article, we'll recall Feynman's contribution that launched the quest for a quantum computer, and assess where the field stands 40 years later.",2021,91,,,
Quantum Computing,d2a5dcecd2ffdf03473df1688091f08fadb114a3,Emerging quantum computing algorithms for quantum chemistry,https://www.semanticscholar.org/paper/d2a5dcecd2ffdf03473df1688091f08fadb114a3,WIREs Computational Molecular Science,['Review'],"Digital quantum computers provide a computational framework for solving the Schrödinger equation for a variety of many‐particle systems. Quantum computing algorithms for the quantum simulation of these systems have recently witnessed remarkable growth, notwithstanding the limitations of existing quantum hardware, especially as a tool for electronic structure computations in molecules. In this review, we provide a self‐contained introduction to emerging algorithms for the simulation of Hamiltonian dynamics and eigenstates, with emphasis on their applications to the electronic structure in molecular systems. Theoretical foundations and implementation details of the method are discussed, and their strengths, limitations, and recent advances are presented.",2021,53,Wiley Interdisciplinary Reviews: Computational Molecular Science,12,
Quantum Computing,42543dc42e65609bbbf2be470d54dd923532c36a,Qudits and High-Dimensional Quantum Computing,https://www.semanticscholar.org/paper/42543dc42e65609bbbf2be470d54dd923532c36a,Frontiers of Physics,['Review'],"Qudit is a multi-level computational unit alternative to the conventional 2-level qubit. Compared to qubit, qudit provides a larger state space to store and process information, and thus can provide reduction of the circuit complexity, simplification of the experimental setup and enhancement of the algorithm efficiency. This review provides an overview of qudit-based quantum computing covering a variety of topics ranging from circuit building, algorithm design, to experimental methods. We first discuss the qudit gate universality and a variety of qudit gates including the pi/8 gate, the SWAP gate, and the multi-level controlled-gate. We then present the qudit version of several representative quantum algorithms including the Deutsch-Jozsa algorithm, the quantum Fourier transform, and the phase estimation algorithm. Finally we discuss various physical realizations for qudit computation such as the photonic platform, iron trap, and nuclear magnetic resonance.",2020,227,,8,
Quantum Computing,1bb022b27ddb987352bfc002c8381a6f646d0ebb,Quantum Computing for Finance: State-of-the-Art and Future Prospects,https://www.semanticscholar.org/paper/1bb022b27ddb987352bfc002c8381a6f646d0ebb,IEEE Transactions on Quantum Engineering,['Review'],"This article outlines our point of view regarding the applicability, state-of-the-art, and potential of quantum computing for problems in finance. We provide an introduction to quantum computing as well as a survey on problem classes in finance that are computationally challenging classically and for which quantum computing algorithms are promising. In the main part, we describe in detail quantum algorithms for specific applications arising in financial services, such as those involving simulation, optimization, and machine learning problems. In addition, we include demonstrations of quantum algorithms on IBM Quantum back-ends and discuss the potential benefits of quantum algorithms for problems in financial services. We conclude with a summary of technical challenges and future prospects.",2020,182,IEEE Transactions on Quantum Engineering,1,1-24
Quantum Computing,beb890d47bbc21a96967f9993c9d6e15686b2eac,Interleaving: Modular architectures for fault-tolerant photonic quantum computing,https://www.semanticscholar.org/paper/beb890d47bbc21a96967f9993c9d6e15686b2eac,,,"Useful fault-tolerant quantum computers require very large numbers of physical qubits. Quantum computers are often designed as arrays of static qubits executing gates and measurements. Photonic qubits require a different approach. In photonic fusion-based quantum computing (FBQC), the main hardware components are resource-state generators (RSGs) and fusion devices connected via waveguides and switches. RSGs produce small entangled states of a few photonic qubits, whereas fusion devices perform entangling measurements between different resource states, thereby executing computations. In addition, low-loss photonic delays such as optical fiber can be used as fixed-time quantum memories simultaneously storing thousands of photonic qubits. Here, we present a modular architecture for FBQC in which these components are combined to form""interleaving modules""consisting of one RSG with its associated fusion devices and a few fiber delays. Exploiting the multiplicative power of delays, each module can add thousands of physical qubits to the computational Hilbert space. Networks of modules are universal fault-tolerant quantum computers, which we demonstrate using surface codes and lattice surgery as a guiding example. Our numerical analysis shows that in a network of modules containing 1-km-long fiber delays, each RSG can generate four logical distance-35 surface-code qubits while tolerating photon loss rates above 2% in addition to the fiber-delay loss. We illustrate how the combination of interleaving with further uses of non-local fiber connections can reduce the cost of logical operations and facilitate the implementation of unconventional geometries such as periodic boundaries or stellated surface codes. Interleaving applies beyond purely optical architectures, and can also turn many small disconnected matter-qubit devices with transduction to photons into a large-scale quantum computer.",2021,46,,,
Quantum Computing,e7354193f0e7fdd1b72725935ff2741cc7b8eeb7,Quantum federated learning through blind quantum computing,https://www.semanticscholar.org/paper/e7354193f0e7fdd1b72725935ff2741cc7b8eeb7,Science China Physics Mechanics and Astronomy,,,2021,46,"Science China Physics, Mechanics & Astronomy",64,
Quantum Computing,239bf45c13b3f6d38c74026b535f785febf9cd08,Towards Post-Quantum Blockchain: A Review on Blockchain Cryptography Resistant to Quantum Computing Attacks,https://www.semanticscholar.org/paper/239bf45c13b3f6d38c74026b535f785febf9cd08,IEEE Access,"['JournalArticle', 'Review']","Blockchain and other Distributed Ledger Technologies (DLTs) have evolved significantly in the last years and their use has been suggested for numerous applications due to their ability to provide transparency, redundancy and accountability. In the case of blockchain, such characteristics are provided through public-key cryptography and hash functions. However, the fast progress of quantum computing has opened the possibility of performing attacks based on Grover’s and Shor’s algorithms in the near future. Such algorithms threaten both public-key cryptography and hash functions, forcing to redesign blockchains to make use of cryptosystems that withstand quantum attacks, thus creating which are known as post-quantum, quantum-proof, quantum-safe or quantum-resistant cryptosystems. For such a purpose, this article first studies current state of the art on post-quantum cryptosystems and how they can be applied to blockchains and DLTs. Moreover, the most relevant post-quantum blockchain systems are studied, as well as their main challenges. Furthermore, extensive comparisons are provided on the characteristics and performance of the most promising post-quantum public-key encryption and digital signature schemes for blockchains. Thus, this article seeks to provide a broad view and useful guidelines on post-quantum blockchain security to future blockchain researchers and developers.",2020,179,IEEE Access,8,21091-21116
Quantum Computing,208ac1f2ec9bf367a9981fedb6d9ea6aa9889099,Low-overhead fault-tolerant quantum computing using long-range connectivity,https://www.semanticscholar.org/paper/208ac1f2ec9bf367a9981fedb6d9ea6aa9889099,Science Advances,['JournalArticle'],"Vast numbers of qubits will be needed for large-scale quantum computing because of the overheads associated with error correction. We present a scheme for low-overhead fault-tolerant quantum computation based on quantum low-density parity-check (LDPC) codes, where long-range interactions enable many logical qubits to be encoded with a modest number of physical qubits. In our approach, logic gates operate via logical Pauli measurements that preserve both the protection of the LDPC codes and the low overheads in terms of the required number of additional qubits. Compared with surface codes with the same code distance, we estimate order-of-magnitude improvements in the overheads for processing around 100 logical qubits using this approach. Given the high thresholds demonstrated by LDPC codes, our estimates suggest that fault-tolerant quantum computation at this scale may be achievable with a few thousand physical qubits at comparable error rates to what is needed for current approaches.",2021,40,Science Advances,8,
Quantum Computing,c997ed5ac5772bb0fce8bb11b8c86bc33310f39a,Quantum computing enhanced computational catalysis,https://www.semanticscholar.org/paper/c997ed5ac5772bb0fce8bb11b8c86bc33310f39a,Physical Review Research,,"The quantum computation of electronic energies can break the curse of dimensionality that plagues many-particle quantum mechanics. It is for this reason that a universal quantum computer has the potential to fundamentally change computational chemistry and materials science, areas in which strong electron correlations present severe hurdles for traditional electronic structure methods. Here, we present a state-of-the-art analysis of accurate energy measurements on a quantum computer for computational catalysis, using improved quantum algorithms with more than an order of magnitude improvement over the best previous algorithms. As a prototypical example of local catalytic chemical reactivity we consider the case of a ruthenium catalyst that can bind, activate, and transform carbon dioxide to the high-value chemical methanol. We aim at accurate resource estimates for the quantum computing steps required for assessing the electronic energy of key intermediates and transition states of its catalytic cycle. In particular, we present new quantum algorithms for double-factorized representations of the four-index integrals that can significantly reduce the computational cost over previous algorithms, and we discuss the challenges of increasing active space sizes to accurately deal with dynamical correlations. We address the requirements for future quantum hardware in order to make a universal quantum computer a successful and reliable tool for quantum computing enhanced computational materials science and chemistry, and identify open questions for further research.",2020,135,Physical Review Research,,
Quantum Computing,1eaab9b33f1261744567455a14830e8a92796cf5,Quantum Chemistry in the Age of Quantum Computing.,https://www.semanticscholar.org/paper/1eaab9b33f1261744567455a14830e8a92796cf5,Chemical Reviews,"['JournalArticle', 'Review']","Practical challenges in simulating quantum systems on classical computers have been widely recognized in the quantum physics and quantum chemistry communities over the past century. Although many approximation methods have been introduced, the complexity of quantum mechanics remains hard to appease. The advent of quantum computation brings new pathways to navigate this challenging and complex landscape. By manipulating quantum states of matter and taking advantage of their unique features such as superposition and entanglement, quantum computers promise to efficiently deliver accurate results for many important problems in quantum chemistry, such as the electronic structure of molecules. In the past two decades, significant advances have been made in developing algorithms and physical hardware for quantum computing, heralding a revolution in simulation of quantum systems. This Review provides an overview of the algorithms and results that are relevant for quantum chemistry. The intended audience is both quantum chemists who seek to learn more about quantum computing and quantum computing researchers who would like to explore applications in quantum chemistry.",2018,931,Chemical reviews,,
Quantum Computing,8fd8cb4951ae9634a378383a880fbf16ac5d6926,"Matrix-Model Simulations Using Quantum Computing, Deep Learning, and Lattice Monte Carlo",https://www.semanticscholar.org/paper/8fd8cb4951ae9634a378383a880fbf16ac5d6926,PRX Quantum,['Review'],"Matrix quantum mechanics plays various important roles in theoretical physics, such as a holographic description of quantum black holes. Understanding quantum black holes and the role of entanglement in a holographic setup is of paramount importance for the development of better quantum algorithms (quantum error correction codes) and for the realization of a quantum theory of gravity. Quantum computing and deep learning offer us potentially useful approaches to study the dynamics of matrix quantum mechanics. In this paper we perform a systematic survey for quantum computing and deep learning approaches to matrix quantum mechanics, comparing them to Lattice Monte Carlo simulations. In particular, we test the performance of each method by calculating the low-energy spectrum.",2021,37,PRX Quantum,,
Quantum Computing,b2ee139c1a3c2c53ac2b603070bdfbcd26b50ddc,Data Encoding Patterns for Quantum Computing,https://www.semanticscholar.org/paper/b2ee139c1a3c2c53ac2b603070bdfbcd26b50ddc,,,"Quantum computers have the potential to solve certain problems faster than classical computers. However, loading data into a quantum computer is not trivial. To load the data, it must be encoded in quantum bits (qubits). There are several ways how qubits can represent the data and, thus, multiple data encodings are possible. Both the data itself and the chosen encoding inﬂuence the runtime of the loading process. In the worst case, loading requires exponential time. This is critical because quantum algorithms that promise a speed-up assume that loading data can be done faster, in logarithmic or linear time. To outline abstract knowledge about encodings and the consequences of choosing a particular data encoding, we present three common encodings as patterns. Especially in complex domains like quantum computing, patterns can contribute to making this new technology and its broad potential accessible to users with different backgrounds. In particular, they facilitate the development of quantum applications for software developers.",2021,36,,,
Quantum Computing,89858723bec341178f2b00d34ea3016baaaf71a6,Superconducting quantum computing: a review,https://www.semanticscholar.org/paper/89858723bec341178f2b00d34ea3016baaaf71a6,Science China Information Sciences,"['JournalArticle', 'Review']",,2020,175,Science China Information Sciences,63,
Quantum Computing,3a9f7c5bdd7f9560bf150332e97d6b1facdfce9b,Quantum PUF for Security and Trust in Quantum Computing,https://www.semanticscholar.org/paper/3a9f7c5bdd7f9560bf150332e97d6b1facdfce9b,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,['JournalArticle'],"Quantum computing is a promising paradigm to solve computationally intractable problems. Various companies such as, IBM, Rigetti and D-Wave offer quantum computers using a cloud-based platform that possess several interesting features namely, (i) quantum hardware with various number of qubits and coupling maps exist at the cloud end that offer different computing capabilities; (ii) multiple hardware with identical coupling maps exist in the suite; (iii) coupling map of larger hardware with more number of qubits can fit the coupling map of many smaller hardware; (iv) the quality of each of the hardware is distinct; (v) user cannot validate the origination of the result obtained from a quantum hardware. In other words, the user relies on the scheduler of the cloud provider to allocate the requested hardware; (vi) the queue of quantum programs at the cloud end is typically long and maximizing the throughput, which is the key to reducing costs and helping the scientific community in their explorations. The above factors motivate a new threat model with following possibilities: (a) in future, less-trustworthy quantum computers from 3rd parties can allocate poor quality hardware to save on cost or towards satisfying their falsely-advertised qubit or quantum hardware specifications; (b) the workload scheduling algorithm could have a bug or malicious code segment which will try to maximize throughput at the cost of allocation to poor fidelity hardware. Such bugs are possible for trustworthy providers; (c) a rogue employee in trusted cloud vendor could try to sabotage the vendor’s reputation by degrading the user compute fidelity just by tampering with the scheduling algorithm or rerouting the program; (d) a rogue employee can steal information by redirecting the programs to a 3rd party quantum hardware where they have full control. If the allocated hardware is inferior in quality, the user will suffer from poor quality result or longer convergence time. We propose two flavors of a Quantum Physically Unclonable Function (QuPUF) to address this issue- one based on superposition and another based on decoherence. Our experiments on real quantum hardware reveal that temporal variations in qubit quality can degrade the quality of the proposed QuPUF. We add a parametric rotation to the QuPUF for stability. Experiments on real IBM quantum hardware show that the proposed QuPUF can achieve inter-die Hamming Distance (HD) of 55% and intra-HD as low as 4%, as compared to ideal cases of 50% and 0% respectively. The proposed QuPUFs can also be used as a standalone solution for any other application.",2021,34,IEEE Journal on Emerging and Selected Topics in Circuits and Systems,11,333-342
Quantum Computing,71ba8a8c75e0826f94eb53ee7a4566d4fc5b5256,Distributed Quantum Computing and Network Control for Accelerated VQE,https://www.semanticscholar.org/paper/71ba8a8c75e0826f94eb53ee7a4566d4fc5b5256,IEEE Transactions on Quantum Engineering,['JournalArticle'],"Interconnecting small quantum computers will be essential in the future for creating large-scale, robust quantum computers. Methods for distributing monolithic quantum algorithms efficiently are, thus, needed. In this article, we consider an approach for distributing the accelerated variational quantum eigensolver algorithm over arbitrary sized—in terms of number of qubits—distributed quantum computers. We consider approaches for distributing qubit assignments of the Ansatz states required to estimate the expectation value of Hamiltonian operators in quantum chemistry in a parallelized computation and provide a systematic approach to generate distributed quantum circuits for distributed quantum computing. Moreover, we propose an architecture for a distributed quantum control system in the context of centralized and decentralized network control.",2021,32,IEEE Transactions on Quantum Engineering,2,1-21
Quantum Computing,215fc60307f741b9db059204e41db8bfb879e606,Quantum Computing with Circular Rydberg Atoms,https://www.semanticscholar.org/paper/215fc60307f741b9db059204e41db8bfb879e606,PRX Quantum,,"Rydberg atom arrays are a leading platform for quantum computing and simulation, combining strong interactions with highly coherent operations and flexible geometries. However, the achievable fidelities are limited by the finite lifetime of the Rydberg states, as well as technical imperfections such as atomic motion. In this work, we propose a novel approach to Rydberg atom arrays using long-lived circular Rydberg states in optical traps. Based on the extremely long lifetime of these states, exceeding seconds in cryogenic microwave cavities that suppress radiative transitions, and gate protocols that are robust to finite atomic temperature, we project that arrays of hundreds of circular Rydberg atoms with two-qubit gate errors around 10−5 can be realized using current technology. This approach combines several key elements, including a quantum nondemolition detection technique for circular Rydberg states, local manipulation using the ponderomotive potential of focused optical beams, a gate protocol using multiple circular levels to encode qubits, and robust dynamical decoupling sequences to suppress unwanted interactions and errors from atomic motion. This represents a significant improvement on the current state-of-the-art in quantum computing and simulation with neutral atoms.",2021,33,PRX Quantum,,
Quantum Computing,5cb8f417d171ae329adf446820bd32d8b49d8c04,Towards a Distributed Quantum Computing Ecosystem,https://www.semanticscholar.org/paper/5cb8f417d171ae329adf446820bd32d8b49d8c04,IET Quantum Communication,"['JournalArticle', 'Review']","The Quantum Internet, by enabling quantum communications among remote quantum nodes, is a network capable of supporting functionalities with no direct counterpart in the classical world. Indeed, with the network and communications functionalities provided by the Quantum Internet, remote quantum devices can communicate and cooperate for solving challenging computational tasks by adopting a distributed computing approach. The aim of this paper is to provide the reader with an overview about the main challenges and open problems arising with the design of a Distributed Quantum Computing ecosystem. For this, we provide a survey, following a bottom-up approach, from a communications engineering perspective. We start by introducing the Quantum Internet as the fundamental underlying infrastructure of the Distributed Quantum Computing ecosystem. Then we go further, by elaborating on a high-level system abstraction of the Distributed Quantum Computing ecosystem. Such an abstraction is described through a set of logical layers. Thereby, we clarify dependencies among the aforementioned layers and, at the same time, a road-map emerges.",2020,148,IET Quantum Commun.,1,3-8
Quantum Computing,dde4abfd83fb61a794bd6c7d6e1991a67467c7ee,Quantum Computing for Healthcare: A Review,https://www.semanticscholar.org/paper/dde4abfd83fb61a794bd6c7d6e1991a67467c7ee,Future Internet,"['JournalArticle', 'Review']","Quantum computing is an emerging field of research that can provide a “quantum leap” in terms of computing performance and thereby enable many new exciting healthcare applications such as rapid DNA sequencing, drug research and discovery, personalized medicine, molecular simulations, diagnosis assistance, efficient radiotherapy. In this paper, we provide a taxonomy of existing literature on quantum healthcare systems and identify the key requirements of quantum computing implementations in the healthcare paradigm. We also provide a through exploration of the application areas where quantum computing could transform traditional healthcare systems. Finally, we perform an extensive study of quantum cryptography from the perspective of healthcare systems to identify security vulnerabilities in traditional cryptography systems.",2021,30,Future Internet,15,94
Quantum Computing,a926093ef103c02fd5ef7310e0d41b83d1958ed5,"Quantum computing: A taxonomy, systematic review and future directions",https://www.semanticscholar.org/paper/a926093ef103c02fd5ef7310e0d41b83d1958ed5,"Software, Practice & Experience","['JournalArticle', 'Review']","Quantum computing (QC) is an emerging paradigm with the potential to offer significant computational advantage over conventional classical computing by exploiting quantum‐mechanical principles such as entanglement and superposition. It is anticipated that this computational advantage of QC will help to solve many complex and computationally intractable problems in several application domains such as drug design, data science, clean energy, finance, industrial chemical development, secure communications, and quantum chemistry. In recent years, tremendous progress in both quantum hardware development and quantum software/algorithm has brought QC much closer to reality. Indeed, the demonstration of quantum supremacy marks a significant milestone in the Noisy Intermediate Scale Quantum (NISQ) era—the next logical step being the quantum advantage whereby quantum computers solve a real‐world problem much more efficiently than classical computing. As the quantum devices are expected to steadily scale up in the next few years, quantum decoherence and qubit interconnectivity are two of the major challenges to achieve quantum advantage in the NISQ era. QC is a highly topical and fast‐moving field of research with significant ongoing progress in all facets. A systematic review of the existing literature on QC will be invaluable to understand the state‐of‐the‐art of this emerging field and identify open challenges for the QC community to address in the coming years. This article presents a comprehensive review of QC literature and proposes taxonomy of QC. The proposed taxonomy is used to map various related studies to identify the research gaps. A detailed overview of quantum software tools and technologies, post‐quantum cryptography, and quantum computer hardware development captures the current state‐of‐the‐art in the respective areas. The article identifies and highlights various open challenges and promising future directions for research and innovation in QC.",2020,140,Software: Practice and Experience,52,114 - 66
Quantum Computing,f497c1ece7b6f3560bb39958e2673f476d608f98,The Quantum Internet : Networking Challenges in Distributed Quantum Computing,https://www.semanticscholar.org/paper/f497c1ece7b6f3560bb39958e2673f476d608f98,,,"The Quantum Internet is envisioned as the final stage of the quantum revolution, opening fundamentally new communications and computing capabilities, including the distributed quantum computing. But the Quantum Internet is governed by the laws of quantum mechanics. Phenomena with no counterpart in classical networks, such as no-cloning, quantum measurement, entanglement and teleporting, impose very challenging constraints for the network design. Specifically, classical network functionalities, ranging from error-control mechanisms to overhead-control strategies, are based on the assumption that classical information can be safely read and copied. But this assumption does not hold in the Quantum Internet. As a consequence, the design of the Quantum Internet requires a major network-paradigm shift to harness the quantum mechanics specificities. The goal of this work is to shed light on the challenges and the open problems of the Quantum Internet design. To this aim, we first introduce some basic knowledge of quantum mechanics, needed to understand the differences between a classical and a quantum network. Then, we introduce quantum teleportation as the key strategy for transmitting quantum information without physically transferring the particle that stores the quantum information or violating the principles of the quantum mechanics. Finally, the key research challenges to design quantum communication networks are described.",2019,226,,,
Quantum Computing,3ea34401909978d3d3d0c25c8746e02c7d2a7c77,Optimal Layout Synthesis for Quantum Computing,https://www.semanticscholar.org/paper/3ea34401909978d3d3d0c25c8746e02c7d2a7c77,2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD),"['Book', 'JournalArticle', 'Conference']","Recent years have witnessed the fast development of quantum computing. Researchers around the world are eager to run larger and larger quantum algorithms that promise speedups impossible to any classical algorithm. However, the available quantum computers are still volatile and error-prone. Thus, layout synthesis, which transforms quantum programs to meet these hardware limitations, is a crucial step in the realization of quantum computing. In this paper, we present two synthesizers, one optimal and one approximate but nearly optimal. Although a few optimal approaches to this problem have been published, our optimal synthesizer explores a larger solution space, thus is optimal in a stronger sense. In addition, it reduces time and space complexity exponentially compared to some leading optimal approaches. The key to this success is a more efficient spacetime-based variable encoding of the layout synthesis problem as a mathematical programming problem. By slightly changing our formulation, we arrive at an approximate synthesizer that is even more efficient and outperforms some leading heuristic approaches, in terms of additional gate cost, by up to 100%, and also fidelity by up to 10x on a comprehensive set of benchmark programs and architectures. For a specific family of quantum programs named QAOA, which is deemed to be a promising application for near-term quantum computers, we further adjust the approximate synthesizer by taking commutation into consideration, achieving up to 75% reduction in depth and up to 65% reduction in additional cost compared to the tool used in a leading QAOA study.",2020,94,2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD),,1-9
Quantum Computing,bcc82ce554942880814243fc8c08a88b9d2aad09,Reading the road: challenges and opportunities on the path to responsible innovation in quantum computing,https://www.semanticscholar.org/paper/bcc82ce554942880814243fc8c08a88b9d2aad09,Technology Analysis & Strategic Management,['JournalArticle'],"ABSTRACT
 Novel technologies such as quantum computing present new opportunities to support societal needs, but societal engagement is vital to secure public trust. Quantum computing technologies are at a pivotal point in their journey from foundational research to deployment, creating a moment for society to investigate, reflect, and consult on their implications. Responsible Innovation (RI) is one method for considering impacts, engaging with societal needs, reflecting on any concerns, and influencing the trajectory of the innovation in response. This paper draws on the empirical work of the RI team embedded in the Networked Quantum Information Technologies Hub. The team investigated researchers’ perceptions of RI and their understanding of societal impacts of quantum technologies, and sought to gauge the challenges of embedding RI across a multi-disciplinary, large-scale enterprise such as the UK quantum programme. The work demonstrated some of the difficulties involved in embedding RI approaches, and in creating a dialogue between innovators and societies. Finally, the authors offer recommendations to policymakers, researchers, and industrial organisations, for better practice in responsible quantum computing, and to ensure that societal considerations are discussed alongside commercial motivations. Applying RI to quantum computing at this pivotal point has implications for RI in other emerging technologies.",2021,27,Technology Analysis & Strategic Management,35,844 - 856
Quantum Computing,e576a2d97950b1f6831f88575dd3f370053f6af7,Distributed Quantum Computing with QMPI,https://www.semanticscholar.org/paper/e576a2d97950b1f6831f88575dd3f370053f6af7,"International Conference for High Performance Computing, Networking, Storage and Analysis","['Book', 'JournalArticle', 'Conference']","Practical applications of quantum computers require millions of physical qubits and it will be challenging for individual quantum processors to reach such qubit numbers. It is therefore timely to investigate the resource requirements of quantum algorithms in a distributed setting, where multiple quantum processors are inter-connected by a coherent network. We introduce an extension of the Message Passing Interface (MPI) to enable high-performance implementations of distributed quantum algorithms. In turn, these implementations can be used for testing, debugging, and resource estimation. In addition to a prototype implementation of quantum MPI, we present a performance model for distributed quantum computing, SENDQ. The model is inspired by the classical LogP model, making it useful to inform algorithmic decisions when program-ming distributed quantum computers. Specifically, we consider several optimizations of two quantum algorithms for problems in physics and chemistry, and we detail their effects on performance in the SENDQ model.",2021,25,"SC21: International Conference for High Performance Computing, Networking, Storage and Analysis",,1-15
Quantum Computing,3db1841fd5f2561a11dfbd8173616b3e695c84a1,Prospects of quantum computing for molecular sciences,https://www.semanticscholar.org/paper/3db1841fd5f2561a11dfbd8173616b3e695c84a1,Materials Theory,,,2021,29,Materials Theory,6,1-17
Quantum Computing,86d3beff240b6c882058455e098a571de86564f5,Quantum computing opportunities in renewable energy,https://www.semanticscholar.org/paper/86d3beff240b6c882058455e098a571de86564f5,Nature Computational Science,['LettersAndComments'],,2021,28,Nature Computational Science,1,90 - 91
Quantum Computing,cf5fddf6717e88e2bbed6b0bfe54dfeb311e6789,Quantum Computing in the Cloud: Analyzing job and machine characteristics,https://www.semanticscholar.org/paper/cf5fddf6717e88e2bbed6b0bfe54dfeb311e6789,IEEE International Symposium on Workload Characterization,['JournalArticle'],"As the popularity of quantum computing continues to grow, quantum machine access over the cloud is critical to both academic and industry researchers across the globe. And as cloud quantum computing demands increase exponentially, the analysis of resource consumption and execution characteristics are key to efficient management of jobs and resources at both the vendor-end as well as the client-end. While the analysis of resource consumption and management are popular in the classical HPC domain, it is severely lacking for more nascent technology like quantum computing. This paper is a first-of-its-kind academic study, analyzing various trends in job execution and resources consumption / utilization on quantum cloud systems. We focus on IBM Quantum systems and analyze characteristics over a two year period, encompassing over 6000 jobs which contain over 600,000 quantum circuit executions and correspond to almost 10 billion “shots” or trials over 20+ quantum machines. Specifically, we analyze trends focused on, but not limited to, execution times on quantum machines, queuing/waiting times in the cloud, circuit compilation times, machine utilization, as well as the impact of job and machine characteristics on all of these trends. Our analysis identifies several similarities and differences with classical HPC cloud systems. Based on our insights, we make recommendations and contributions to improve the management of resources and jobs on future quantum cloud systems.",2021,27,2021 IEEE International Symposium on Workload Characterization (IISWC),,39-50
Quantum Computing,6745a82c9236f0eec576904eb50ea700ca5a7d7c,Quantum computing with neutral atoms,https://www.semanticscholar.org/paper/6745a82c9236f0eec576904eb50ea700ca5a7d7c,Quantum,"['JournalArticle', 'Review']","The manipulation of neutral atoms by light is at the heart of countless scientific discoveries in the field of quantum physics in the last three decades. The level of control that has been achieved at the single particle level within arrays of optical traps, while preserving the fundamental properties of quantum matter (coherence, entanglement, superposition), makes these technologies prime candidates to implement disruptive computation paradigms. In this paper, we review the main characteristics of these devices from atoms / qubits to application interfaces, and propose a classification of a wide variety of tasks that can already be addressed in a computationally efficient manner in the Noisy Intermediate Scale Quantum\cite{Preskill_NISQ} era we are in. We illustrate how applications ranging from optimization challenges to simulation of quantum systems can be explored either at the digital level (programming gate-based circuits) or at the analog level (programming Hamiltonian sequences). We give evidence of the intrinsic scalability of neutral atom quantum processors in the 100-1,000 qubits range and introduce prospects for universal fault tolerant quantum computing and applications beyond quantum computing.",2020,138,Quantum,4,327
Quantum Computing,3b87dafd5a412e25e06761f181ec199ca88a7398,Bugs in Quantum computing platforms: an empirical study,https://www.semanticscholar.org/paper/3b87dafd5a412e25e06761f181ec199ca88a7398,Proc. ACM Program. Lang.,['JournalArticle'],"The interest in quantum computing is growing, and with it, the importance of software platforms to develop quantum programs. Ensuring the correctness of such platforms is important, and it requires a thorough understanding of the bugs they typically suffer from. To address this need, this paper presents the first in-depth study of bugs in quantum computing platforms. We gather and inspect a set of 223 real-world bugs from 18 open-source quantum computing platforms. Our study shows that a significant fraction of these bugs (39.9%) are quantum-specific, calling for dedicated approaches to prevent and find them. The bugs are spread across various components, but quantum-specific bugs occur particularly often in components that represent, compile, and optimize quantum programming abstractions. Many quantum-specific bugs manifest through unexpected outputs, rather than more obvious signs of misbehavior, such as crashes. Finally, we present a hierarchy of recurrent bug patterns, including ten novel, quantum-specific patterns. Our findings not only show the importance and prevalence bugs in quantum computing platforms, but they help developers to avoid common mistakes and tool builders to tackle the challenge of preventing, finding, and fixing these bugs.",2021,24,Proceedings of the ACM on Programming Languages,6,1 - 27
Quantum Computing,6be56f559a74c0124526242e70cbdfd16cbc60a7,Quantum Computing - from NISQ to PISQ,https://www.semanticscholar.org/paper/6be56f559a74c0124526242e70cbdfd16cbc60a7,IEEE Micro,['JournalArticle'],"Given the impeding timeline of developing good quality quantum processing units, it is the moment to rethink the approach to advance quantum computing research. Rather than waiting for quantum hardware technologies to mature, we need to start assessing in tandem the impact of the occurrence of quantum computing in various scientific fields.However, to this purpose, we need to use a complementary but quite different approach than proposed by the NISQ vision, which is heavily focused on and burdened by the engineering challenges.That is why we propose and advocate the PISQ-approach: Perfect Intermediate-Scale Quantum computing based on the already known concept of perfect qubits.This will allow researchers to focus much more on the development of new applications by defining the algorithms in terms of perfect qubits and evaluate them on quantum computing simulators that are executed on supercomputers.It is not the long-term solution but will currently allow universities to research on quantum logic and algorithms and companies can already start developing their internal know-how on quantum solutions.",2021,21,IEEE Micro,41,24-32
Quantum Computing,76f87dfb737ac0e44df1fc331b422de2b9f0a632,Quantum Computing: Towards Industry Reference Problems,https://www.semanticscholar.org/paper/76f87dfb737ac0e44df1fc331b422de2b9f0a632,Digitale Welt,['JournalArticle'],,2021,23,Digitale Welt,5,38 - 45
Quantum Computing,3d82552eb483e5ea84b577a0e8d5f157a6085824,The prospects of quantum computing in computational molecular biology,https://www.semanticscholar.org/paper/3d82552eb483e5ea84b577a0e8d5f157a6085824,WIREs Computational Molecular Science,['Review'],"Quantum computers can in principle solve certain problems exponentially more quickly than their classical counterparts. We have not yet reached the advent of useful quantum computation, but when we do, it will affect nearly all scientific disciplines. In this review, we examine how current quantum algorithms could revolutionize computational biology and bioinformatics. There are potential benefits across the entire field, from the ability to process vast amounts of information and run machine learning algorithms far more efficiently, to algorithms for quantum simulation that are poised to improve computational calculations in drug discovery, to quantum algorithms for optimization that may advance fields from protein structure prediction to network analysis. However, these exciting prospects are susceptible to “hype,” and it is also important to recognize the caveats and challenges in this new technology. Our aim is to introduce the promise and limitations of emerging quantum computing technologies in the areas of computational molecular biology and bioinformatics.",2020,122,Wiley Interdisciplinary Reviews: Computational Molecular Science,11,
Quantum Computing,ed935c6b359a7a486c28240d796e84897d095125,Improving the Variational Quantum Eigensolver Using Variational Adiabatic Quantum Computing,https://www.semanticscholar.org/paper/ed935c6b359a7a486c28240d796e84897d095125,ACM Transactions on Quantum Computing,,"The variational quantum eigensolver (VQE) is a hybrid quantum-classical algorithm for finding the minimum eigenvalue of a Hamiltonian that involves the optimization of a parameterized quantum circuit. Since the resulting optimization problem is in general nonconvex, the method can converge to suboptimal parameter values that do not yield the minimum eigenvalue. In this work, we address this shortcoming by adopting the concept of variational adiabatic quantum computing (VAQC) as a procedure to improve VQE. In VAQC, the ground state of a continuously parameterized Hamiltonian is approximated via a parameterized quantum circuit. We discuss some basic theory of VAQC to motivate the development of a hybrid quantum-classical homotopy continuation method. The proposed method has parallels with a predictor-corrector method for numerical integration of differential equations. While there are theoretical limitations to the procedure, we see in practice that VAQC can successfully find good initial circuit parameters to initialize VQE. We demonstrate this with two examples from quantum chemistry. Through these examples, we provide empirical evidence that VAQC, combined with other techniques (an adaptive termination criteria for the classical optimizer and a variance-based resampling method for the expectation evaluation), can provide more accurate solutions than “plain” VQE, for the same amount of effort.",2021,16,ACM Transactions on Quantum Computing,3,1 - 20
Quantum Computing,e75cb933d387ecb184010ff07d0ee43fc1750e2a,Models in quantum computing: a systematic review,https://www.semanticscholar.org/paper/e75cb933d387ecb184010ff07d0ee43fc1750e2a,Quantum Information Processing,"['JournalArticle', 'Review']",,2021,18,Quantum Information Processing,20,
Quantum Computing,795550a5294eb05ea4f3b14f0b1c21a405493d85,Universal Quantum Computing with Twist-Free and Temporally Encoded Lattice Surgery,https://www.semanticscholar.org/paper/795550a5294eb05ea4f3b14f0b1c21a405493d85,PRX Quantum,,"Lattice surgery protocols allow for the efficient implementation of universal gate sets with two-dimensional topological codes where qubits are constrained to interact with one another locally. In this work, we first introduce a decoder capable of correcting spacelike and timelike errors during lattice surgery protocols. Afterwards, we compute logical failure rates of a lattice surgery protocol for a biased circuit-level noise model. We then provide a new protocol for performing twist-free lattice surgery, where we avoid twist defects in the bulk of the lattice. Our twist-free protocol eliminates the extra circuit components and gate scheduling complexities associated with the measurement of higher weight stabilizers when using twist defects. We also provide a protocol for temporally encoded lattice surgery that can be used to reduce both runtimes and the total space-time costs of quantum algorithms. Lastly, we propose a layout for a quantum processor that is more efficient for rectangular surface codes exploiting noise bias, and which is compatible with the other techniques mentioned above.",2021,43,PRX Quantum,,
Quantum Computing,9675f7484a4d3d278a5a637f75a1b81d7d008c4e,Biology begins to tangle with quantum computing,https://www.semanticscholar.org/paper/9675f7484a4d3d278a5a637f75a1b81d7d008c4e,Nature Methods,['JournalArticle'],,2021,20,Nature Methods,18,715 - 719
Quantum Computing,e7a7735104448371dde788542ebfc6af6485ea43,Silicon photonic quantum computing with spin qubits,https://www.semanticscholar.org/paper/e7a7735104448371dde788542ebfc6af6485ea43,APL Photonics,,"Universal quantum computing holds the promise to fundamentally change today’s information-based society, yet a hardware platform that will provide a clear path to fault-tolerant quantum computing remains elusive. One recently proposed platform involves the use of circuit-bound photons to build cluster states and perform one-way measurement-based quantum computations on arrays of long-coherence-time solid-state spin qubits. Herein, we discuss the challenges that are faced during any practical implementation of this architecture by itemizing the key physical building blocks and the constraints imposed on the spin qubits and the photonic circuit components by the requirements of fault-tolerant performance. These considerations point to silicon as a leading candidate to host such a platform, and a roadmap for developing a silicon photonic circuit-based platform for measurement-based, fault-tolerant universal quantum computing is offered.",2021,23,APL Photonics,,
Quantum Computing,390bcf15a1b13cb0d5966859c35c69a31238e838,Optimized Compiler for Distributed Quantum Computing,https://www.semanticscholar.org/paper/390bcf15a1b13cb0d5966859c35c69a31238e838,ACM Transactions on Quantum Computing,['JournalArticle'],"Practical distributed quantum computing requires the development of efficient compilers, able to make quantum circuits compatible with some given hardware constraints. This problem is known to be tough, even for local computing. Here, we address it on distributed architectures. As generally assumed in this scenario, telegates represent the fundamental remote (inter-processor) operations. Each telegate consists of several tasks: (i) entanglement generation and distribution, (ii) local operations, and (iii) classical communications. Entanglement generations and distribution is an expensive resource, as it is time-consuming. To mitigate its impact, we model an optimization problem that combines running-time minimization with the usage of distributed entangled states. Specifically, we formulated the distributed compilation problem as a dynamic network flow. To enhance the solution space, we extend the formulation, by introducing a predicate that manipulates the circuit given in input and parallelizes telegate tasks. To evaluate our framework, we split the problem into three sub-problems, and solve it by means of an approximation routine. Experiments demonstrate that the run-time is resistant to the problem size scaling. Moreover, we apply the proposed algorithm to compile circuits under different topologies, showing that topologies with a higher ratio between edges and nodes give rise to shallower circuits.",2021,22,ACM Transactions on Quantum Computing,4,1 - 29
Quantum Computing,1dec1180add808a482a45f9afd15cc70129d6bbe,SpinQ Gemini: a desktop quantum computing platform for education and research,https://www.semanticscholar.org/paper/1dec1180add808a482a45f9afd15cc70129d6bbe,EPJ Quantum Technology,,,2021,13,EPJ Quantum Technology,8,
Quantum Computing,43eea2a73997294193228d50f9ff25fc5345664b,Quantum Algorithms and Simulation for Parallel and Distributed Quantum Computing,https://www.semanticscholar.org/paper/43eea2a73997294193228d50f9ff25fc5345664b,2021 IEEE/ACM Second International Workshop on Quantum Computing Software (QCS),['JournalArticle'],"A viable approach for building large-scale quantum computers is to interlink small-scale quantum computers with a quantum network to create a larger distributed quantum computer. When designing quantum algorithms for such a distributed quantum computer, one can make use of the added parallelization and distribution abilities inherent in the system. An added difficulty to then overcome for distributed quantum computing is that a complex control system to orchestrate the various components is required. In this work, we aim to address these issues. We explicitly define what it means for a quantum algorithm to be distributed and then present various quantum algorithms that fit the definition. We discuss potential benefits and propose a high-level scheme for controlling the system. With this, we present our software framework called Interlin-q, a simulation platform that aims to simplify designing and verifying parallel and distributed quantum algorithms. We demonstrate Interlin-q by implementing some of the discussed algorithms using Interlin-q and layout future steps for developing Interlin-q into a control system for distributed quantum computers.",2021,17,2021 IEEE/ACM Second International Workshop on Quantum Computing Software (QCS),,9-19
Quantum Computing,3e53b6d0d30be2a802c6b7b34b75f6e67ab8204f,A Leap among Quantum Computing and Quantum Neural Networks: A Survey,https://www.semanticscholar.org/paper/3e53b6d0d30be2a802c6b7b34b75f6e67ab8204f,ACM Computing Surveys,"['JournalArticle', 'Review']","In recent years, Quantum Computing witnessed massive improvements in terms of available resources and algorithms development. The ability to harness quantum phenomena to solve computational problems is a long-standing dream that has drawn the scientific community’s interest since the late ’80s. In such a context, we propose our contribution. First, we introduce basic concepts related to quantum computations, and then we explain the core functionalities of technologies that implement the Gate Model and Adiabatic Quantum Computing paradigms. Finally, we gather, compare, and analyze the current state-of-the-art concerning Quantum Perceptrons and Quantum Neural Networks implementations.",2021,19,ACM Computing Surveys,55,1 - 37
Quantum Computing,787ae2c51cd82b904bb4fb9ccb15266381af5436,State preparation and evolution in quantum computing: A perspective from Hamiltonian moments,https://www.semanticscholar.org/paper/787ae2c51cd82b904bb4fb9ccb15266381af5436,International Journal of Quantum Chemistry,['Review'],"Quantum algorithms on the noisy intermediate-scale quantum (NISQ) devices are expected to simulate quantum systems that are classically intractable to demonstrate quantum advantages. However, the non-negligible gate error on the NISQ devices impedes the conventional quantum algorithms to be implemented. Practical strategies usually exploit hybrid quantum classical algorithms to demonstrate potentially useful applications of quantum computing in the NISQ era. Among the numerous hybrid algorithms, recent efforts highlight the development of quantum algorithms based upon quantum computed Hamiltonian moments, $\langle \phi | \hat{\mathcal{H}}^n | \phi \rangle$ ($n=1,2,\cdots$), with respect to quantum state $|\phi\rangle$. In this tutorial, we will give a brief review of these quantum algorithms with focuses on the typical ways of computing Hamiltonian moments using quantum hardware and improving the accuracy of the estimated state energies based on the quantum computed moments. Furthermore, we will present a tutorial to show how we can measure and compute the Hamiltonian moments of a four-site Heisenberg model, and compute the energy and magnetization of the model utilizing the imaginary time evolution in the real IBM-Q NISQ hardware environment. Along this line, we will further discuss some practical issues associated with these algorithms. We will conclude this tutorial review by overviewing some possible developments and applications in this direction in the near future.",2021,15,International Journal of Quantum Chemistry,,
Quantum Computing,980858461df7c4349f17b427686c5bcbcffbdc04,Molecular Quantum Dynamics: A Quantum Computing Perspective.,https://www.semanticscholar.org/paper/980858461df7c4349f17b427686c5bcbcffbdc04,Accounts of Chemical Research,"['JournalArticle', 'Review']","ConspectusSimulating molecular dynamics (MD) within a comprehensive quantum framework has been a long-standing challenge in computational chemistry. An exponential scaling of computational cost renders solving the time dependent Schrödinger equation (TDSE) of a molecular Hamiltonian, including both electronic and nuclear degrees of freedom (DOFs), as well as their couplings, infeasible for more than a few DOFs. In the Born-Oppenheimer (BO), or adiabatic, picture, electronic and nuclear parts of the wave function are decoupled and treated separately. Within this framework, the nuclear wave function evolves along potential energy surfaces (PESs) computed as solutions to the electronic Schrödinger equation parametrized in the nuclear DOFs. This approximation, together with increasingly elaborate numerical approaches to solve the nuclear time dependent Schrödinger equation (TDSE), enabled the treatment of up to a few dozens of degrees of freedom (DOFs). However, for particular applications, such as photochemistry, the BO approximation breaks down. In this regime of non-adiabatic dynamics, solving the full molecular problem including electron-nuclear couplings becomes essential, further increasing the complexity of the numerical solution. Although valuable methods such as multiconfigurational time-dependent Hartree (MCTDH) have been proposed for the solution of the coupled electron-nuclear dynamics, they remain hampered by an exponential scaling in the number of nuclear DOFs and by the difficulty of finding universal variational forms.In this Account, we present a perspective on novel quantum computational algorithms, aiming to alleviate the exponential scaling inherent to the simulation of many-body quantum dynamics. In particular, we focus on the derivation and application of quantum algorithms for adiabatic and non-adiabatic quantum dynamics, which include efficient approaches for the calculation of the BO potential energy surfaces (PESs). Thereafter, we study the time-evolution of a model system consisting of two coupled PESs in first and second quantization. In a first application, we discuss a recently introduced quantum algorithm for the evolution of a wavepacket in first quantization and exploit the potential quantum advantage of mapping its spatial grid representation to logarithmically many qubits. For the second demonstration, we move to the second quantization framework and review the scaling properties of two alternative time-evolution algorithms, namely, a variational quantum algorithm (VQA) (based on the McLachlan variational principle) and conventional Trotter-type evolution (based on a Lie-Trotter-Suzuki formula). Both methods clearly demonstrate the potential of quantum algorithms and their favorable scaling compared to the available classical approaches. However, a clear demonstration of quantum advantage in the context of molecular quantum dynamics may require the implementation of these algorithms in fault-tolerant quantum computers, while their application in near-term, noisy quantum devices is still unclear and deserves further investigation.",2021,39,Accounts of chemical research,,
Quantum Computing,3faeb21fe256b99391d69570053a8c2d91e9f348,Conveyor-mode single-electron shuttling in Si/SiGe for a scalable quantum computing architecture,https://www.semanticscholar.org/paper/3faeb21fe256b99391d69570053a8c2d91e9f348,npj Quantum Information,,,2021,43,npj Quantum Information,8,1-7
Quantum Computing,3c68025d95970a9b9aa1b742a678704cd09d2bf4,Scaling silicon-based quantum computing using CMOS technology,https://www.semanticscholar.org/paper/3c68025d95970a9b9aa1b742a678704cd09d2bf4,Nature Electronics,['Review'],,2020,99,Nature Electronics,4,872 - 884
Quantum Computing,82973c5f56681190a0dbb4c4449ed60d5f805135,EQC: ensembled quantum computing for variational quantum algorithms,https://www.semanticscholar.org/paper/82973c5f56681190a0dbb4c4449ed60d5f805135,International Symposium on Computer Architecture,"['Book', 'JournalArticle', 'Conference']","Variational quantum algorithm (VQA), which is comprised of a classical optimizer and a parameterized quantum circuit, emerges as one of the most promising approaches for harvesting the power of quantum computers in the noisy intermediate scale quantum (NISQ) era. However, the deployment of VQAs on contemporary NISQ devices often faces considerable system and time-dependant noise and prohibitively slow training speeds. On the other hand, the expensive supporting resources and infrastructure make quantum computers extremely keen on high utilization. In this paper, we propose a virtualized way of building up a quantum backend for variational quantum algorithms: rather than relying on a single physical device which tends to introduce ever-changing device-specific noise with less reliable performance as time-since-calibration grows, we propose to constitute a quantum ensemble, which dynamically distributes quantum tasks asynchronously across a set of physical devices, and adjusts the ensemble configuration with respect to machine status. In addition to reduced machine-dependant noise, the ensemble can provide significant speedups for VQA training. With this idea, we build a novel VQA training framework called EQC - a distributed gradient-based processor-performance-aware optimization system - that comprises: (i) a system architecture for asynchronous parallel VQA cooperative training; (ii) an analytical model for assessing the quality of a circuit output concerning its architecture, transpilation, and runtime conditions; (iii) a weighting mechanism to adjust the quantum ensemble's computational contribution according to the systems' current performance. Evaluations comprising 500K times' circuit evaluations across 10 IBMQ NISQ devices using a VQE and a QAOA applications demonstrate that EQC can attain error rates very close to the most performant device of the ensemble, while boosting the training speed by 10.5X on average (up to 86X and at least 5.2x). EQC is available at https://github.com/pnnl/eqc.",2021,29,Proceedings of the 49th Annual International Symposium on Computer Architecture,,
Quantum Computing,182180bd69ea6d2f59225ded5ddc900b8558ab9f,Deterministic multi-mode gates on a scalable photonic quantum computing platform,https://www.semanticscholar.org/paper/182180bd69ea6d2f59225ded5ddc900b8558ab9f,Nature Physics,,,2020,83,Nature Physics,17,1018 - 1023
Quantum Computing,f62ab3fcc45eb787f4eb3213a3ffcae97799e9e5,A Game of Surface Codes: Large-Scale Quantum Computing with Lattice Surgery,https://www.semanticscholar.org/paper/f62ab3fcc45eb787f4eb3213a3ffcae97799e9e5,Quantum,,"Given a quantum gate circuit, how does one execute it in a fault-tolerant architecture with as little overhead as possible? In this paper, we discuss strategies for surface-code quantum computing on small, intermediate and large scales. They are strategies for space-time trade-offs, going from slow computations using few qubits to fast computations using many qubits. Our schemes are based on surface-code patches, which not only feature a low space cost compared to other surface-code schemes, but are also conceptually simple~--~simple enough that they can be described as a tile-based game with a small set of rules. Therefore, no knowledge of quantum error correction is necessary to understand the schemes in this paper, but only the concepts of qubits and measurements.",2018,224,Quantum,,
Quantum Computing,2bc9d6830610e18f110aa7984f7c0271d6b17eeb,Solving Burgers’ equation with quantum computing,https://www.semanticscholar.org/paper/2bc9d6830610e18f110aa7984f7c0271d6b17eeb,Quantum Information Processing,['JournalArticle'],,2021,18,Quantum Information Processing,21,
Quantum Computing,07b01d665646009439ca206378cc35e095ec6cd2,Quantum Computing Technology,https://www.semanticscholar.org/paper/07b01d665646009439ca206378cc35e095ec6cd2,International Electron Devices Meeting,,"Quantum Computing has inspired scientists as well as hardware and software developers and is fundamentally changing the landscape of information technology. Quantum computing systems are built from the bottom up reaching the limits of what can be classically simulated. The IBM Quantum Development Roadmap describes our vision of creating a quantum computing ecosystem delivering quantum applications through the cloud. This requires developing the entire quantum computing stack starting from the qubit and quantum processor technology, control electronics to software, algorithms and applications for quantum computing, implemented in the cloud and integrated with high performance computing. Though today's noisy near-term quantum computing systems are still limited, the roadmap targets to achieve an inflection point benefiting of continuous improvements across the stack driving quantum performance described by more qubits, higher quantum volume and speed.",2021,12,2021 IEEE International Electron Devices Meeting (IEDM),,1.3.1-1.3.7
Quantum Computing,ade9a900acc3c138021070537840488526796d35,A comparative study of universal quantum computing models: towards a physical unification,https://www.semanticscholar.org/paper/ade9a900acc3c138021070537840488526796d35,Quantum Engineering,['JournalArticle'],"Quantum computing has been a fascinating research field in quantum physics. Recent progresses motivate us to study in depth the universal quantum computing models (UQCM), which lie at the foundation of quantum computing and have tight connections with fundamental physics. Although being developed decades ago, a physically concise principle or picture to formalize and understand UQCM is still lacking. This is challenging given the diversity of still-emerging models, but important to understand the difference between classical and quantum computing. In this work, we carried out a primary attempt to unify UQCM by classifying a few of them as two categories, hence making a table of models. With such a table, some known models or schemes appear as hybridization or combination of models, and more importantly, it leads to new schemes that have not been explored yet. Our study of UQCM also leads to some insights into quantum algorithms. This work reveals the importance and feasibility of systematic study of computing models.",2021,12,Quantum Eng.,3,
Quantum Computing,aa9bf8b4c4ce8c28b9f47d7ce4f416aa9726bb0d,Quantum computing with exciton-polariton condensates,https://www.semanticscholar.org/paper/aa9bf8b4c4ce8c28b9f47d7ce4f416aa9726bb0d,,,,2020,71,npj Quantum Information,6,1-6
Quantum Computing,48c73c389c3f36d70407eb8309a0b41578c15fc8,QProv: A provenance system for quantum computing,https://www.semanticscholar.org/paper/48c73c389c3f36d70407eb8309a0b41578c15fc8,IET Quantum Communication,['JournalArticle'],"Quantum computing promises breakthroughs in various application areas, such as machine learning, chemistry, or simulations. However, today’s quantum computers are error ‐ prone and have limited capabilities. This leads to various challenges when developing and executing quantum algorithms, for example, the mitigation of occurring errors or the selection of a suitable quantum computer to execute a certain quantum circuit. To address these challenges, detailed information about the quantum circuit to be executed as well as past executions, and the up ‐ to ‐ date information about the available quantum computers are required. Thus, this data must be continuously collected and stored in the long ‐ term, which is currently not supported. To overcome this problem, a provenance approach is introduced for quantum computing. Therefore, relevant provenance attributes that should be gathered in the area of quantum computing are identified. Furthermore, QProv, a provenance system that automatically collects the identified provenance attributes and provides them in a uniform manner to the user is introduced. Finally, a case study with the collected provenance data and corresponding use cases that can benefit from this provenance data are presented here.",2021,10,IET Quantum Commun.,2,171-181
Quantum Computing,baafed5f8968118af04dbbb1cf172f1c10bede25,Toward large-scale fault-tolerant universal photonic quantum computing,https://www.semanticscholar.org/paper/baafed5f8968118af04dbbb1cf172f1c10bede25,APL Photonics,,"Photonic quantum computing is one of the leading approaches to universal quantum computation. However, large-scale implementation of photonic quantum computing has been hindered by its intrinsic difficulties, such as probabilistic entangling gates for photonic qubits and lack of scalable ways to build photonic circuits. Here we discuss how to overcome these limitations by taking advantage of two key ideas which have recently emerged. One is a hybrid qubit-continuous variable approach for realizing a deterministic universal gate set for photonic qubits. The other is time-domain multiplexing technique to perform arbitrarily large-scale quantum computing without changing the configuration of photonic circuits. These ideas together will enable scalable implementation of universal photonic quantum computers in which hardware-efficient error correcting codes can be incorporated. Furthermore, all-optical implementation of such systems can increase the operational bandwidth beyond THz in principle, utimately enabling large-scale fault-tolerant universal quantum computers with ultra-high operation frequency.",2019,138,APL Photonics,,
Quantum Computing,b2f8df88de24fe0ef74bda0eec1a0c3e7329b9f9,Microwaves in Quantum Computing,https://www.semanticscholar.org/paper/b2f8df88de24fe0ef74bda0eec1a0c3e7329b9f9,IEEE Journal of Microwaves,"['JournalArticle', 'Review']","Quantum information processing systems rely on a broad range of microwave technologies and have spurred development of microwave devices and methods in new operating regimes. Here we review the use of microwave signals and systems in quantum computing, with specific reference to three leading quantum computing platforms: trapped atomic ion qubits, spin qubits in semiconductors, and superconducting qubits. We highlight some key results and progress in quantum computing achieved through the use of microwave systems, and discuss how quantum computing applications have pushed the frontiers of microwave technology in some areas. We also describe open microwave engineering challenges for the construction of large-scale, fault-tolerant quantum computers.",2020,59,IEEE journal of microwaves,1,
Quantum Computing,05f0ab01e15147f15dfc00343305cdd127e2b252,"Application-Motivated, Holistic Benchmarking of a Full Quantum Computing Stack",https://www.semanticscholar.org/paper/05f0ab01e15147f15dfc00343305cdd127e2b252,Quantum,['JournalArticle'],"Quantum computing systems need to be benchmarked in terms of practical tasks they would be expected to do. Here, we propose 3 ""application-motivated"" circuit classes for benchmarking: deep (relevant for state preparation in the variational quantum eigensolver algorithm), shallow (inspired by IQP-type circuits that might be useful for near-term quantum machine learning), and square (inspired by the quantum volume benchmark). We quantify the performance of a quantum computing system in running circuits from these classes using several figures of merit, all of which require exponential classical computing resources and a polynomial number of classical samples (bitstrings) from the system. We study how performance varies with the compilation strategy used and the device on which the circuit is run. Using systems made available by IBM Quantum, we examine their performance, showing that noise-aware compilation strategies may be beneficial, and that device connectivity and noise levels play a crucial role in the performance of the system according to our benchmarks.",2020,33,Quantum,5,415
Quantum Computing,6a4ae4b2f667c00789d88b0399e79ff0368a8681,Shortcuts to Adiabaticity in Digitized Adiabatic Quantum Computing,https://www.semanticscholar.org/paper/6a4ae4b2f667c00789d88b0399e79ff0368a8681,,,"Shortcuts to adiabaticity are well-known methods for controlling the quantum dynamics beyond the adiabatic criteria, where counter-diabatic (CD) driving provides a promising means to speed up quantum many-body systems. In this work, we show the applicability of CD driving to enhance the digitized adiabatic quantum computing paradigm in terms of fidelity and total simulation time. We study the state evolution of an Ising spin chain using the digitized version of the standard CD driving and its variants derived from the variational approach. We apply this technique in the preparation of Bell and Greenberger-Horne-Zeilinger states with high fidelity using a very shallow quantum circuit. We implement this proposal in the IBM quantum computer, proving its usefulness for the speed up of adiabatic quantum computing in noisy intermediate-scale quantum devices.",2020,59,arXiv: Quantum Physics,,
Quantum Computing,008068e3d9e9e3d417bf21a4c0688b6af4515aec,Gate-based superconducting quantum computing,https://www.semanticscholar.org/paper/008068e3d9e9e3d417bf21a4c0688b6af4515aec,Journal of Applied Physics,['Review'],"In this tutorial, we introduce basic conceptual elements to understand and build a gate-based superconducting quantum computing system.",2020,60,Journal of Applied Physics,,
Quantum Computing,be082d70534db088315f2cc5b42c2fdcd58c1b8c,Optimality Study of Existing Quantum Computing Layout Synthesis Tools,https://www.semanticscholar.org/paper/be082d70534db088315f2cc5b42c2fdcd58c1b8c,IEEE transactions on computers,['JournalArticle'],"Layout synthesis, an important step in quantum computing, processes quantum circuits to satisfy device layout constraints. In this paper, we construct QUEKO benchmarks for this problem, which have known optimal depths and gate counts. We use QUEKO to evaluate the optimality of current layout synthesis tools, including Cirq from Google, Qiskit from IBM, <inline-formula><tex-math notation=""LaTeX"">$\mathsf {t}|\mathsf {ket}\rangle$</tex-math><alternatives><mml:math><mml:mrow><mml:mi mathvariant=""sans-serif"">t</mml:mi><mml:mo>|</mml:mo><mml:mi mathvariant=""sans-serif"">ket</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=""tan-ieq1-3009140.gif""/></alternatives></inline-formula> from Cambridge Quantum Computing, and a recent academic work. To our surprise, despite over a decade of research and development by academia and industry on compilation and synthesis for quantum circuits, we are still able to demonstrate large optimality gaps: 1.5-12x on average on a smaller device and 5-45x on average on a larger device. This suggests substantial room for improvement of the efficiency of quantum computer by better layout synthesis tools. Finally, we also prove the NP-completeness of the layout synthesis problem for quantum computing. We have made the QUEKO benchmarks open-source.",2020,58,IEEE Transactions on Computers,70,1363-1373
Quantum Computing,43ccf5d54ed038738af54009a5a9166af05471c7,Quantum Computing with Rotation-Symmetric Bosonic Codes,https://www.semanticscholar.org/paper/43ccf5d54ed038738af54009a5a9166af05471c7,Physical Review X,,"Bosonic rotation codes, introduced here, are a broad class of bosonic error-correcting codes based on phase-space rotation symmetry. We present a universal quantum computing scheme applicable to a subset of this class--number-phase codes--which includes the well-known cat and binomial codes, among many others. The entangling gate in our scheme is code-agnostic and can be used to interface different rotation-symmetric encodings. In addition to a universal set of operations, we propose a teleportation-based error correction scheme that allows recoveries to be tracked entirely in software. Focusing on cat and binomial codes as examples, we compute average gate fidelities for error correction under simultaneous loss and dephasing noise and show numerically that the error-correction scheme is close to optimal for error-free ancillae and ideal measurements. Finally, we present a scheme for fault-tolerant, universal quantum computing based on concatenation of number-phase codes and Bacon-Shor subsystem codes.",2019,101,Physical Review X,,
Graph Database,2c3eef2f17369912e330281d54b535675077e4ca,Representing Paths in Graph Database Pattern Matching,https://www.semanticscholar.org/paper/2c3eef2f17369912e330281d54b535675077e4ca,Proceedings of the VLDB Endowment,['JournalArticle'],"
 Modern graph database query languages such as GQL, SQL/PGQ, and their academic predecessor G-Core promote paths to first-class citizens in the sense that their pattern matching facility can return
 paths
 , as opposed to only nodes and edges. This is challenging for database engines, since graphs can have a large number of paths between a given node pair, which can cause huge intermediate results in query evaluation.
 
 
 We introduce the concept of
 path multiset representations (PMRs)
 , which can represent multisets of paths exponentially succinctly and therefore bring significant advantages for representing intermediate results. We give a detailed theoretical analysis that shows that they are especially well-suited for representing results of regular path queries and extensions thereof involving counting, random sampling, and unions. Our experiments show that they drastically improve scalability for regular path query evaluation, with speedups of several orders of magnitude.
",2023,6,Proc. VLDB Endow.,16,1790-1803
Graph Database,a2a514ed839dafdd0fb76d6c2615f25f35bf8087,Testing Graph Database Engines via Query Partitioning,https://www.semanticscholar.org/paper/a2a514ed839dafdd0fb76d6c2615f25f35bf8087,International Symposium on Software Testing and Analysis,"['JournalArticle', 'Book', 'Conference']","Graph Database Management Systems (GDBMSs) store data as graphs and allow the efficient querying of nodes and their relationships. Logic bugs are bugs that cause a GDBMS to return an incorrect result for a given query (e.g., by returning incorrect nodes or relationships). The impact of such bugs can be severe, as they often go unnoticed. The core insight of this paper is that Query Partitioning, a test oracle that has been proposed to test Relational Database Systems, is applicable to testing GDBMSs as well. The core idea of Query Partitioning is that, given a query, multiple queries are derived whose results can be combined to reconstruct the given query’s result. Any discrepancy in the result indicates a logic bug. We have implemented this approach as a practical tool named GDBMeter and evaluated GDBMeter on three popular GDBMSs and found a total of 40 unique, previously unknown bugs. We consider 14 of them to be logic bugs, the others being error or crash bugs. Overall, 27 of the bugs have been fixed, and 35 confirmed. We compared our approach to the state-of-the-art approach to testing GDBMS, which relies on differential testing; we found that it results in a high number of false alarms, while Query Partitioning reported actual logic bugs without any false alarms. Furthermore, despite the previous efforts in testing Neo4j and JanusGraph, we found 18 additional bugs. The developers appreciate our work and plan to integrate GDBMeter into their testing process. We expect that this simple, yet effective approach and the practical tool will be used to test other GDBMSs.",2023,8,Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,,
Graph Database,6c755fc901d0b41a5d73c265f64a5aacf62e83b8,GDsmith: Detecting Bugs in Cypher Graph Database Engines,https://www.semanticscholar.org/paper/6c755fc901d0b41a5d73c265f64a5aacf62e83b8,International Symposium on Software Testing and Analysis,"['JournalArticle', 'Book', 'Conference']","Graph database engines stand out in the era of big data for their efficiency of modeling and processing linked data. To assure high quality of graph database engines, it is highly critical to conduct automatic test generation for graph database engines, e.g., random test generation, the most commonly adopted approach in practice. However, random test generation faces the challenge of generating complex inputs (i.e., property graphs and queries) for producing non-empty query results; generating such type of inputs is important especially for detecting wrong-result bugs. To address this challenge, in this paper, we propose GDsmith, the first approach for testing Cypher graph database engines. GDsmith ensures that each randomly generated query satisfies the semantic requirements. To increase the probability of producing complex queries that return non-empty results, GDsmith includes two new techniques: graph-guided generation of complex pattern combinations and data-guided generation of complex conditions. Our evaluation results demonstrate that GDsmith is effective and efficient for producing complex queries that return non-empty results for bug detection, and substantially outperforms the baselines. GDsmith successfully detects 28 bugs on the released versions of three highly popular open-source graph database engines and receives positive feedback from their developers.",2023,7,Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis,,
Graph Database,e67a2817089312746d69b38ce9abfdc4b1bc69c3,Finding bugs in Gremlin-based graph database systems via Randomized differential testing,https://www.semanticscholar.org/paper/e67a2817089312746d69b38ce9abfdc4b1bc69c3,International Symposium on Software Testing and Analysis,"['Book', 'JournalArticle', 'Conference']","Graph database systems (GDBs) allow efficiently storing and retrieving graph data, and have become the critical component in many applications, e.g., knowledge graphs, social networks, and fraud detection. It is important to ensure that GDBs operate correctly. Logic bugs can occur and make GDBs return an incorrect result for a given query. These bugs are critical and can easily go unnoticed by developers when the graph and queries become complicated. Despite the importance of GDBs, logic bugs in GDBs have received less attention than those in relational database systems. In this paper, we present Grand, an approach for automatically finding logic bugs in GDBs that adopt Gremlin as their query language. The core idea of Grand is to construct semantically equivalent databases for multiple GDBs, and then compare the results of a Gremlin query on these databases. If the return results of a query on multiple GDBs are different, the likely cause is a logic bug in these GDBs. To effectively test GDBs, we propose a model-based query generation approach to generate valid Gremlin queries that can potentially return non-empty results, and a data mapping approach to unify the format of query results for different GDBs. We evaluate Grand on six widely-used GDBs, e.g., Neo4j and HugeGraph. In total, we have found 21 previously-unknown logic bugs in these GDBs. Among them, developers have confirmed 18 bugs, and fixed 7 bugs.",2022,13,Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis,,
Graph Database,fe4c5074f021cd1c810892c1b6bc267b23aa6e5c,Fraud detection in the distributed graph database,https://www.semanticscholar.org/paper/fe4c5074f021cd1c810892c1b6bc267b23aa6e5c,Cluster Computing,['JournalArticle'],,2022,9,Cluster Computing,26,515-537
Graph Database,2af8907d4a974ae41044581f5e5d67317cb08568,KÙZU ∗ Graph Database Management System,https://www.semanticscholar.org/paper/2af8907d4a974ae41044581f5e5d67317cb08568,,,"Datasets and workloads of popular applications that use graph database management systems (GDBMSs) require a set of storage and query processing features that RDBMSs do not traditionally optimize for. These include optimizations for: (i) many-to-many (m-n) joins; (ii) cyclic joins; (iii) recursive joins; (iv) semi-structured data storage; and (v) support for universal resource identifiers. We present Kùzu, a new GDBMS we are developing at University of Waterloo that aims to integrate state-of-art storage, indexing, and query processing techniques to highly optimize for this feature set. This paper serves the dual role of describing our vision for Kùzu and the system’s factorized query processor, which is based on two design goals: (i) achieving good factorization structures under m-n joins; and (ii) ensuring sequential scans that avoid entire scans of columns and join indices when possible. As we show these two goals can sometimes conflict and we describe our core binary and worst-case optimal (multiway) join operators that simultaneously achieve both goals. Kùzu is actively being developed to be a fully functional open-source DBMS with the goal of wide user adoption.",2022,7,,,
Graph Database,371a343457a4fbff00000bf4faa29b2b2f85744c,Nebula Graph: An open source distributed graph database,https://www.semanticscholar.org/paper/371a343457a4fbff00000bf4faa29b2b2f85744c,arXiv.org,"['JournalArticle', 'Review']","This paper introduces the recent work of Nebula Graph, an open-source, distributed, scalable, and native graph database. We present a system design trade-oﬀ and a comprehensive overview of Nebula Graph internals, including graph data models, partitioning strategies, secondary indexes, optimizer rules, storage-side transactions, graph query languages, observability, graph processing frameworks, and visualization tool-kits. In addition, three sets of large-scale graph benchmark tests are conducted.",2022,5,ArXiv,abs/2206.07278,
Graph Database,2bc2f02f3b6125fec42357ba08c29f27d0ff314d,An Approach to Converting Relational Database to Graph Database: from MySQL to Neo4j,https://www.semanticscholar.org/paper/2bc2f02f3b6125fec42357ba08c29f27d0ff314d,"2022 IEEE 2nd International Conference on Power, Electronics and Computer Applications (ICPECA)",['Conference'],"At present, there are few research methods that can convert any relational database into a graph database, and most of them are based on a specific field data set to build a relational database, and then perform simple conversion through the characteristics of the data set.Aiming at this problem, a universal conversion method is proposed. Firstly, converted the most basic component tables name, records, and fields in the relational database into labels, nodes, and corresponding attributes of the nodes under the graph database; secondly, used the intermediate connection table method to convert the foreign keys in the relational database into the relationship of a graph database between the nodes; then some constraint issues in relational databases, such as multiple primary key issues, indexes, and no default values, were optimized to form a final graph database model that met expectations; finally, Realized the effective migration of large quantities of data in the relational database to the constructed graph database model. In the experiment, the above method was used to successfully convert a relational database to a graph database, and the database construction, data import, SQL query and Cypher language query were performed for the database before and after the conversion, and through the analysis and comparison of data integrity, time cost, result validity,which shows that the integrity and operability of the database before and after conversion are consistent, and the data processing efficiency of the database is much higher than that of the relational database, which verifies that the method in this paper is feasible.",2022,3,"2022 IEEE 2nd International Conference on Power, Electronics and Computer Applications (ICPECA)",,674-680
Graph Database,83ea80a9393177ecf84928f4bd1120fb679f180c,NO SQL Database: Graph database,https://www.semanticscholar.org/paper/83ea80a9393177ecf84928f4bd1120fb679f180c,Egyptian Journal of Artificial Intelligence,['Review'],": The database of NoSQL is considered one the most significant technology in the current era of computer science especially, with the emergency of big data. The issue of processing and storing data is solved by utilizing the NoSQL databases. Planning to offer references to the users of No SQL databases, this survey examines the characterization, categories, and hypothetical premise of NoSQL dependent on the introduction of the rise, improvement, and development of relational database to NoSQL and the examination of its restrictions of relational databases in the current era. Also, this survey points to a type of NoSQL database called graph database. It can be characterized as those in which the architecture for instances and schema are demonstrated as graphs and data control is described by graph oriented processes and activities and type constructors. It started in eighties and nineties close by object arranged models. Their impact slowly ceased to exist with the rise of other models, specifically XML, spatial, and semi-structured. Lately, the requirement to manipulate information with graph like nature has restored the relationship of this field. The fundamental goal of this review is to introduce the work that has been proposed in the field of graph database.",2022,1,Egyptian Journal of Artificial Intelligence,,
Graph Database,d1ae4ab5047489c2b010c7ce72262982ad66ad60,ByteGraph: A High-Performance Distributed Graph Database in ByteDance,https://www.semanticscholar.org/paper/d1ae4ab5047489c2b010c7ce72262982ad66ad60,Proceedings of the VLDB Endowment,['JournalArticle'],"Most products at ByteDance, e.g., TikTok, Douyin, and Toutiao, naturally generate massive amounts of graph data. To efficiently store, query and update massive graph data is challenging for the broad range of products at ByteDance with various performance requirements. We categorize graph workloads at ByteDance into three types: online analytical, transaction, and serving processing, where each workload has its own characteristics. Existing graph databases have different performance bottlenecks in handling these workloads and none can efficiently handle the scale of graphs at ByteDance. We developed ByteGraph to process these graph workloads with high throughput, low latency and high scalability. There are several key designs in ByteGraph that make it efficient for processing our workloads, including edge-trees to store adjacency lists for high parallelism and low memory usage, adaptive optimizations on thread pools and indexes, and geographic replications to achieve fault tolerance and availability. ByteGraph has been in production use for several years and its performance has shown to be robust for processing a wide range of graph workloads at ByteDance.",2022,6,Proc. VLDB Endow.,15,3306-3318
Graph Database,1cff064f815111a71a98afda7aee1867ad617901,Digital Contact Tracing Based on a Graph Database Algorithm for Emergency Management During the COVID-19 Epidemic: Case Study,https://www.semanticscholar.org/paper/1cff064f815111a71a98afda7aee1867ad617901,JMIR mHealth and uHealth,['JournalArticle'],"Background The COVID-19 epidemic is still spreading globally. Contact tracing is a vital strategy in epidemic emergency management; however, traditional contact tracing faces many limitations in practice. The application of digital technology provides an opportunity for local governments to trace the contacts of individuals with COVID-19 more comprehensively, efficiently, and precisely. Objective Our research aimed to provide new solutions to overcome the limitations of traditional contact tracing by introducing the organizational process, technical process, and main achievements of digital contact tracing in Hainan Province. Methods A graph database algorithm, which can efficiently process complex relational networks, was applied in Hainan Province; this algorithm relies on a governmental big data platform to analyze multisource COVID-19 epidemic data and build networks of relationships among high-risk infected individuals, the general population, vehicles, and public places to identify and trace contacts. We summarized the organizational and technical process of digital contact tracing in Hainan Province based on interviews and data analyses. Results An integrated emergency management command system and a multi-agency coordination mechanism were formed during the emergency management of the COVID-19 epidemic in Hainan Province. The collection, storage, analysis, and application of multisource epidemic data were realized based on the government’s big data platform using a centralized model. The graph database algorithm is compatible with this platform and can analyze multisource and heterogeneous big data related to the epidemic. These practices were used to quickly and accurately identify and trace 10,871 contacts among hundreds of thousands of epidemic data records; 378 closest contacts and a number of public places with high risk of infection were identified. A confirmed patient was found after quarantine measures were implemented by all contacts. Conclusions During the emergency management of the COVID-19 epidemic, Hainan Province used a graph database algorithm to trace contacts in a centralized model, which can identify infected individuals and high-risk public places more quickly and accurately. This practice can provide support to government agencies to implement precise, agile, and evidence-based emergency management measures and improve the responsiveness of the public health emergency response system. Strengthening data security, improving tracing accuracy, enabling intelligent data collection, and improving data-sharing mechanisms and technologies are directions for optimizing digital contact tracing.",2021,15,JMIR mHealth and uHealth,9,
Graph Database,21042565ec941f4fa31ac5a0af85a1a84ff21f1b,Integration Strategy and Tool between Formal Ontology and Graph Database Technology,https://www.semanticscholar.org/paper/21042565ec941f4fa31ac5a0af85a1a84ff21f1b,Electronics,,"Ontologies, and especially formal ones, have traditionally been investigated as a means to formalize an application domain so as to carry out automated reasoning on it. The union of the terminological part of an ontology and the corresponding assertional part is known as a Knowledge Graph. On the other hand, database technology has often focused on the optimal organization of data so as to boost efficiency in their storage, management and retrieval. Graph databases are a recent technology specifically focusing on element-driven data browsing rather than on batch processing. While the complementarity and connections between these technologies are patent and intuitive, little exists to bring them to full integration and cooperation. This paper aims at bridging this gap, by proposing an intermediate format that can be easily mapped onto the formal ontology on one hand, so as to allow complex reasoning, and onto the graph database on the other, so as to benefit from efficient data handling.",2021,18,Electronics,,
Graph Database,27beaa5db6c37c611f082855c6385b264874b8f5,SynLethDB 2.0: a web-based knowledge graph database on synthetic lethality for novel anticancer drug discovery,https://www.semanticscholar.org/paper/27beaa5db6c37c611f082855c6385b264874b8f5,bioRxiv,['JournalArticle'],"Two genes are synthetic lethal if mutations in both genes result in impaired cell viability, while mutation of either gene does not affect the cell survival. The potential usage of synthetic lethality (SL) in anticancer therapeutics has attracted many researchers to identify synthetic lethal gene pairs. To include newly identified SLs and more related knowledge, we present a new version of the SynLethDB database to facilitate the discovery of clinically relevant SLs. We extended the first version of SynLethDB database significantly by including new SLs identified through CRISPR screening, a knowledge graph about human SLs, and new web interface, etc. Over 16,000 new SLs and 26 types of other relationships have been added, encompassing relationships among 14,100 genes, 53 cancers, and 1,898 drugs, etc. Moreover, a brand-new web interface has been developed to include modules such as SL query by disease or compound, SL partner gene set enrichment analysis and knowledge graph browsing through a dynamic graph viewer. The data can be downloaded directly from the website or through the RESTful APIs. The database is accessible online at http://synlethdb.sist.shanghaitech.edu.cn/v2.",2021,16,Database: The Journal of Biological Databases and Curation,2022,
Graph Database,a6b7b5dbd1eb6ac765cdb9c9f70b90aa11e45854,"MillenniumDB: A Persistent, Open-Source, Graph Database",https://www.semanticscholar.org/paper/a6b7b5dbd1eb6ac765cdb9c9f70b90aa11e45854,arXiv.org,['JournalArticle'],"In this systems paper, we present MillenniumDB: a novel graph database engine that is modular, persistent, and open source. MillenniumDB is based on a graph data model, which we call domain graphs, that provides a simple abstraction upon which a variety of popular graph models can be supported. The engine itself is founded on a combination of tried and tested techniques from relational data management, state-of-the-art algorithms for worst-case-optimal joins, as well as graph-specific algorithms for evaluating path queries. In this paper, we present the main design principles underlying MillenniumDB, describing the abstract graph model and query semantics supported, the concrete data model and query syntax implemented, as well as the storage, indexing, query planning and query evaluation techniques used. We evaluate MillenniumDB over real-world data and queries from the Wikidata knowledge graph, where we find that it outperforms other popular persistent graph database engines (including both enterprise and open source alternatives) that support similar query features.",2021,12,ArXiv,abs/2111.01540,
Graph Database,e4b52a1a00e9db941326fc857b95245cbfb60bce,Reactome graph database: Efficient access to complex pathway data,https://www.semanticscholar.org/paper/e4b52a1a00e9db941326fc857b95245cbfb60bce,PLoS Comput. Biol.,"['JournalArticle', 'Review']","Reactome is a free, open-source, open-data, curated and peer-reviewed knowledgebase of biomolecular pathways. One of its main priorities is to provide easy and efficient access to its high quality curated data. At present, biological pathway databases typically store their contents in relational databases. This limits access efficiency because there are performance issues associated with queries traversing highly interconnected data. The same data in a graph database can be queried more efficiently. Here we present the rationale behind the adoption of a graph database (Neo4j) as well as the new ContentService (REST API) that provides access to these data. The Neo4j graph database and its query language, Cypher, provide efficient access to the complex Reactome data model, facilitating easy traversal and knowledge discovery. The adoption of this technology greatly improved query efficiency, reducing the average query time by 93%. The web service built on top of the graph database provides programmatic access to Reactome data by object oriented queries, but also supports more complex queries that take advantage of the new underlying graph-based data storage. By adopting graph database technology we are providing a high performance pathway data resource to the community. The Reactome graph database use case shows the power of NoSQL database engines for complex biological data types.",2018,513,PLoS Computational Biology,14,
Graph Database,f4cfc7cbad257f1688772d59f694c16189dba811,Columnar Storage and List-based Processing for Graph Database Management Systems,https://www.semanticscholar.org/paper/f4cfc7cbad257f1688772d59f694c16189dba811,Proceedings of the VLDB Endowment,['JournalArticle'],"We revisit column-oriented storage and query processing techniques in the context of contemporary graph database management systems (GDBMSs). Similar to column-oriented RDBMSs, GDBMSs support read-heavy analytical workloads that however have fundamentally different data access patterns than traditional analytical workloads. We first derive a set of desiderata for optimizing storage and query processors of GDBMS based on their access patterns. We then present the design of columnar storage, compression, and query processing techniques based on these desiderata. In addition to showing direct integration of existing techniques from columnar RDBMSs, we also propose novel ones that are optimized for GDBMSs. These include a novel list-based query processor, which avoids expensive data copies of traditional block-based processors under many-to-many joins, a new data structure we call single-indexed edge property pages and an accompanying edge ID scheme, and a new application of Jacobson's bit vector index for compressing NULL values and empty lists. We integrated our techniques into the GraphflowDB in-memory GDBMS. Through extensive experiments, we demonstrate the scalability and query performance benefits of our techniques.",2021,11,Proc. VLDB Endow.,14,2491-2504
Graph Database,7bb477077968d68aa7a6059d8d6d801fb28274da,Credit Card Fraud Detection Technique by Applying Graph Database Model,https://www.semanticscholar.org/paper/7bb477077968d68aa7a6059d8d6d801fb28274da,The Arabian journal for science and engineering,,,2021,11,Arabian Journal for Science and Engineering,46,1 - 20
Graph Database,9b3e8d202488dc29e601fc471a25a2af9002659e,IFC-Based 4D Construction Management Information Model of Prefabricated Buildings and Its Application in Graph Database,https://www.semanticscholar.org/paper/9b3e8d202488dc29e601fc471a25a2af9002659e,Applied Sciences,,"Effective data interoperability and schedule analysis play a significant role in improving the management of prefabricated buildings. However, there is a lack of efficient strategies and comprehensive approaches for data interoperability and data-based automated schedule analysis. This paper intends to promote prefabricated buildings’ management by solving these two problems via developing an IFC-based framework consisting of three parts. Firstly, this framework proposed a mechanism to establish an IFC-based 4D construction management information model of prefabricated buildings. Furthermore, a non-relational database—graph database—is introduced to twin this model into a task-centered network to realize the interoperation of construction information among different participants. Finally, graph database-based strategies to update data, automatically analyze construction schedules and visualize the 4D construction management information model are described. The proposed framework is validated in a prefabricated engineering case. In this case, an IFC-based and graph database-based 4D construction management information model is established through IFC standard’s extension. The graph database-based analysis of the model automatically recognizes the engineering case’s critical path information, delay analysis information, and schedule network analysis information. It is illustrated that this framework can successfully establish a unified IFC-based information model of prefabricated buildings’ construction management to prompt effective data interoperability. In addition, the application of this IFC-based information model in graph database can automatically analyze the construction schedules to prevent possible delays in advance. In short, the significance of this paper is to innovatively propose an IFC-based and graph data-based information model to solve the difficulties of ineffective data interoperation and unautomated schedule analysis in prefabricated buildings’ construction management. This study can be the digital foundation of further IFC-based digital twin.",2021,8,Applied Sciences,,
Graph Database,6b3756d32ab5b0a5715a5cfc3672290d2d643017,A Graph Database Representation of Portuguese Criminal-Related Documents,https://www.semanticscholar.org/paper/6b3756d32ab5b0a5715a5cfc3672290d2d643017,Informatics,['JournalArticle'],"Organizations have been challenged by the need to process an increasing amount of data, both structured and unstructured, retrieved from heterogeneous sources. Criminal investigation police are among these organizations, as they have to manually process a vast number of criminal reports, news articles related to crimes, occurrence and evidence reports, and other unstructured documents. Automatic extraction and representation of data and knowledge in such documents is an essential task to reduce the manual analysis burden and to automate the discovering of names and entities relationships that may exist in a case. This paper presents SEMCrime, a framework used to extract and classify named-entities and relations in Portuguese criminal reports and documents, and represent the data retrieved into a graph database. A 5WH1 (Who, What, Why, Where, When, and How) information extraction method was applied, and a graph database representation was used to store and visualize the relations extracted from the documents. Promising results were obtained with a prototype developed to evaluate the framework, namely a name-entity recognition with an F-Measure of 0.73, and a 5W1H information extraction performance with an F-Measure of 0.65.",2021,7,Informatics,8,37
Graph Database,6a85b59bb66e9f70c6e201a265d58a7f3aeb3aeb,UniKG: A Unified Interoperable Knowledge Graph Database System,https://www.semanticscholar.org/paper/6a85b59bb66e9f70c6e201a265d58a7f3aeb3aeb,IEEE International Conference on Data Engineering,"['JournalArticle', 'Conference']","Knowledge graph currently has two main data models: RDF graph and property graph. The query language on RDF graph is SPARQL, while the query language on property graph is mainly Cypher. Different data models and query languages hinder the wider application of knowledge graphs. In this demonstration, we propose a unified interoperable knowledge graph database system, UniKG. (1) Based on the relational model, a unified storage scheme is utilized to efficiently store RDF graphs and property graphs, and support the query requirements of knowledge graphs. (2) Using the characteristicset-based method, the storage problem of untyped entities is addressed in UniKG. (3) UniKG realizes the interoperability of SPARQL and Cypher, and enables them to interchangeably operate on the same knowledge graph. (4) With a unified Web interface, users are allowed to query with two different languages over the same knowledge graph and visualize query results and explanations.",2021,7,2021 IEEE 37th International Conference on Data Engineering (ICDE),,2681-2684
Graph Database,64306bbddb4da7a4e06f990a0167d55fbbbbec82,LinkedImm: a linked data graph database for integrating immunological data,https://www.semanticscholar.org/paper/64306bbddb4da7a4e06f990a0167d55fbbbbec82,BMC Bioinformatics,['JournalArticle'],,2021,4,BMC Bioinformatics,22,
Graph Database,09f54c64b39f5f7e7570f9f4ce3e3af544401e14,A Quantitative Analysis of Student Solutions to Graph Database Problems,https://www.semanticscholar.org/paper/09f54c64b39f5f7e7570f9f4ce3e3af544401e14,Annual Conference on Innovation and Technology in Computer Science Education,"['JournalArticle', 'Book', 'Conference']","As data grow both in size and in connectivity, the interest to use graph databases in the industry has been proliferating. However, there has been little research on graph database education. In response to the need to introduce college students to graph databases, this paper is the first to analyze students' errors in homework submissions of queries written in Cypher, the query language for Neo4j---the most prominent graph database. Based on 40,093 student submissions from homework assignments in an upper-level computer science database course at one university, this paper provides a quantitative analysis of students' learning when solving graph database problems. The data shows that students struggle the most to correctly use Cypher's WITH clause to define variable names before referencing in the WHERE clause and these errors persist over multiple homework problems requiring the same techniques, and we suggest a further improvement on the classification of syntactic errors.",2021,4,Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1,,
Graph Database,5ea7bf772fecf95cbf53b2c7f719c9440322a115,GRANEF: Utilization of a Graph Database for Network Forensics,https://www.semanticscholar.org/paper/5ea7bf772fecf95cbf53b2c7f719c9440322a115,International Conference on Security and Cryptography,"['JournalArticle', 'Conference']","Understanding the information in captured network traffic, extracting the necessary data, and performing incident investigations are principal tasks of network forensics. The analysis of such data is typically performed by tools allowing manual browsing, filtering, and aggregation or tools based on statistical analyses and visualizations facilitating data comprehension. However, the human brain is used to perceiving the data in associations, which these tools can provide only in a limited form. We introduce a GRANEF toolkit that demonstrates a new approach to exploratory network data analysis based on associations stored in a graph database. In this article, we describe data transformation principles, utilization of a scalable graph database, and data analysis techniques. We then discuss and evaluate our proposed approach using a realistic dataset. Although we are at the beginning of our research, the current results show the great potential of association-based analysis.",2021,4,,,785-790
Graph Database,0a71dd8bec060195e14eb9d0a7abbc08d960d4d5,Research on Data Asset Management System of Graph Database Based on Internet of Things,https://www.semanticscholar.org/paper/0a71dd8bec060195e14eb9d0a7abbc08d960d4d5,Journal of Physics: Conference Series,['Conference'],"With the development of the times and the progress of society, the popularization rate of computer network technology and information technology in China is accelerating, and the Internet of things technology also appears in people’s vision, and is gradually known by people. In the context of this era of big data, it has brought great challenges to all walks of life. The development of everything must conform to the development theme of the times. In order to meet the challenge of the research and development of the data asset management system of the graph database in the new era, this paper puts forward the method of applying the Internet of things technology to the research and development of the data asset management system of the graph database. Combining with the foreign research and development plans of the data asset management system of the graph database, the data resources of the graph database are carried out from the platform system, the management structure and the organization arrangement Based on the research and analysis of production management system, a research scheme of data asset management system of graph database which can meet the development requirements of the new era is worked out. Through long-term research and analysis, we can find that the Internet of things technology analysis method proposed in this paper can effectively provide new development ideas for the research and development of data asset management system based on graph database under the Internet of things technology.",2021,4,Journal of Physics: Conference Series,1802,
Graph Database,db6084fdb3baceddacdc726474722debe1ef7e65,TigerGraph: A Native MPP Graph Database,https://www.semanticscholar.org/paper/db6084fdb3baceddacdc726474722debe1ef7e65,arXiv.org,['JournalArticle'],"We present TigerGraph, a graph database system built from the ground up to support massively parallel computation of queries and analytics. 
TigerGraph's high-level query language, GSQL, is designed for compatibility with SQL, while simultaneously allowing NoSQL programmers to continue thinking in Bulk-Synchronous Processing (BSP) terms and reap the benefits of high-level specification. 
GSQL is sufficiently high-level to allow declarative SQL-style programming, yet sufficiently expressive to concisely specify the sophisticated iterative algorithms required by modern graph analytics and traditionally coded in general-purpose programming languages like C++ and Java. 
We report very strong scale-up and scale-out performance over a benchmark we published on GitHub for full reproducibility.",2019,53,ArXiv,abs/1901.08248,
Graph Database,b0b770fb8c7760749c88e3c83ae173cdb07f7bd5,An Attack Path Generation Methods Based on Graph Database,https://www.semanticscholar.org/paper/b0b770fb8c7760749c88e3c83ae173cdb07f7bd5,"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",['Conference'],"With the popularity of network technology and the expansion of network scale, the network security risks are increasingly serious. Network vulnerability assessment methods, a technology of active network security defense, have attracted many researchers. Most existing network vulnerability assessment methods store different types of data in different ways, which makes querying and analyzing inefficient, especially in the complex large-scale network environment. In order to solve this problem, this paper proposes a method of network vulnerability assessment based on graph database. The network host information, association relationship between hosts and vulnerability information of the target network are stored in the graph database, the query and analysis are carried out by using the graph database query language. Graph database stores the information of the network hosts, association relationship among hosts and vulnerabilities of the target network. The graph database query language supports querying and analysis. Visualizing the network topology, vulnerability information and all possible attack paths provides a reference to develop the network security protection strategy. Experiments' results illustrate that the method runs efficiently and helps with querying and analysis, which is applicable to large-scale complex network environment.",2020,13,"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",1,1905-1910
Graph Database,91d6e8ba5dd90b02fe3bd870b19da13a6167af53,The Property Graph Database Model,https://www.semanticscholar.org/paper/91d6e8ba5dd90b02fe3bd870b19da13a6167af53,Alberto Mendelzon Workshop on Foundations of Data Management,['JournalArticle'],"Most of the current graph database systems have been designed to support property graphs. Surprisingly, there is no standard specification of the database model behind such systems. This paper presents a formal definition of the property graph database model. Specifically, we define the property graph data structure, basic notions of integrity constraints (e.g. graph schema), and a graph query language.",2018,122,,,
Graph Database,a604aa1f2a2ca1a6a0b09013e71b83d36cc0f358,An Empirical Study on Recent Graph Database Systems,https://www.semanticscholar.org/paper/a604aa1f2a2ca1a6a0b09013e71b83d36cc0f358,"Knowledge Science, Engineering and Management","['JournalArticle', 'Review']",,2020,11,,,328-340
Graph Database,b613887337a5d2e8fc8773037116be81e6346835,A1: A Distributed In-Memory Graph Database,https://www.semanticscholar.org/paper/b613887337a5d2e8fc8773037116be81e6346835,SIGMOD Conference,"['Book', 'JournalArticle', 'Conference']","A1 is an in-memory distributed database used by the Bing search engine to support complex queries over structured data. The key enablers for A1 are availability of cheap DRAM and high speed RDMA (Remote Direct Memory Access) networking in commodity hardware. A1 uses FaRM [11,12] as its underlying storage layer and builds the graph abstraction and query engine on top. The combination of in-memory storage and RDMA access requires rethinking how data is allocated, organized and queried in a large distributed system. A single A1 cluster can store tens of billions of vertices and edges and support a throughput of 350+ million of vertex reads per second with end to end query latency in single digit milliseconds. In this paper we describe the A1 data model, RDMA optimized data structures and query execution.",2020,22,Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data,,
Graph Database,6fb020754f6de564c3a0a07bb656c0a90be1f87d,Incorruptible Auditing: Blockchain-Powered Graph Database Management,https://www.semanticscholar.org/paper/6fb020754f6de564c3a0a07bb656c0a90be1f87d,International Conference on Blockchain,"['JournalArticle', 'Conference']","In modern and interconnected world, information is accumulatively stored digitally, making the process of exchanging, gathering and querying the information much easier. Continuously, it has introduced new challenges about how to ensure its consistency and reliability due to the sheer volume of data. A blockchain-based information system can provide an incorruptible record of history, enabling better auditing and data management practices. The paper describes how to combine an Exonum blockchain and a Neo4j graph database into a system that can provide a verifiable audit trail of data integrity and its modifications for information stored in a graph database.",2020,10,2020 IEEE International Conference on Blockchain and Cryptocurrency (ICBC),,1-3
Graph Database,33e332837e91c1048c3ed165cd16bf7607c3bf06,Issues and Concepts of Graph Database and a Comparative Analysis on list of Graph Database tools,https://www.semanticscholar.org/paper/33e332837e91c1048c3ed165cd16bf7607c3bf06,International Conference on Computational Collective Intelligence,"['Conference', 'Review']","The work is review in nature and focuses on basic concepts and example on Graph Database with a special focus on list of standard computerized tools available for handling the queries using graph database structure. The implementation benefits of each tool and a comparative analysis on various functionalities has been presented in this work. This work also elaborates on popular Graph Databases tool that includes Allegro Graph, ArangoDB, OrientDB, Infinite Graph ,Neo4j, Titan, FlockDB, Bitsy, StarDog, MongoDB and investigate their acceptance for solving day to day problems.",2020,9,2020 International Conference on Computer Communication and Informatics (ICCCI),,1-6
Graph Database,b067177b1e17287185eb3b82ccc3d7c646b3ec40,Which Category Is Better: Benchmarking Relational and Graph Database Management Systems,https://www.semanticscholar.org/paper/b067177b1e17287185eb3b82ccc3d7c646b3ec40,Data Science and Engineering,['JournalArticle'],,2019,28,Data Science and Engineering,4,309 - 322
Graph Database,0601e9e434b30320c316c76228b97c093fa98ad6,GDBAlive: A Temporal Graph Database Built on Top of a Columnar Data Store,https://www.semanticscholar.org/paper/0601e9e434b30320c316c76228b97c093fa98ad6,Journal of Advances in Information Technology,,"Although graph databases have extensively found applications in the relationship-centered era, a time-version support is seldom provided. While current storage systems capture the most recently updated snapshot of the underlying graph, most real world graphs embed a dynamic behavior translating the fact that vertices or edges can join or leave the graph at any time instant. Regarding that, a graph database should faithfully maintain the state of every graph's element permitting the analysis and prediction of the underlying system's performance. Since physical deletions are forbidden in such a scenario, the outgrowing size of data is a crippling restriction steering the interest in this area towards the optimization of the persistent storage. However, capturing and storing the state of the graph as full snapshots adds a storage overhead traded by faster query responses. Accordingly, the choice of an appropriate storage engine should be adapted with the threshold of accepted query latencies and the available storage resources. This paper will recognize the anterior academic work in the era of temporal graph databases while highlighting the existing tradeoff between storage and computation time costs. The implementation of GDBAlive, a temporal graph database using two state-of-the-art techniques Copy+Log and Log, is provided relying on a robust column oriented data store. In order to optimize the responsiveness of temporal queries in terms of computation times, we will introduce two fetching strategies ""AsyncFS"" and ""Forced Fetch"" and prove their efficiency on a real dataset.",2020,9,Journal of Advances in Information Technology,,
Graph Database,72afe82af4c2ca100c36eb35292e85d806527f0a,Construction of typhoon disaster knowledge graph based on graph database Neo4j,https://www.semanticscholar.org/paper/72afe82af4c2ca100c36eb35292e85d806527f0a,Chinese Control and Decision Conference,['Conference'],"The typhoon knowledge graph can correlate various kinds of information in the typhoon data, conduct overall and related analysis, and finally provide effective assistance for typhoon prevention and post-disaster protection. The data of typhoon landing in China from 2000 to 2015 were selected to build a typhoon knowledge graph based on Neo4j graph database platform. The typhoon knowledge graph can be used to understand the occurrence of historical typhoons and obtain the distribution of typhoon data in time and space.",2020,8,2020 Chinese Control And Decision Conference (CCDC),,3612-3616
Graph Database,cde39ce861e4c7514ee07fd91b6b8aac50cbf01b,RedisGraph GraphBLAS Enabled Graph Database,https://www.semanticscholar.org/paper/cde39ce861e4c7514ee07fd91b6b8aac50cbf01b,"IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum",['JournalArticle'],"RedisGraph is a Redis module developed by Redis Labs to add graph database functionality to the Redis database. RedisGraph represents connected data as adjacency matrices. By representing the data as sparse matrices and employing the power of GraphBLAS (a highly optimized library for sparse matrix operations), RedisGraph delivers a fast and efficient way to store, manage and process graphs. Initial benchmarks indicate that RedisGraph is significantly faster than comparable graph databases.",2019,22,2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW),,285-286
Graph Database,7904b3446775ed8c79f4f94001a16b706989c462,GraphSE²: An Encrypted Graph Database for Privacy-Preserving Social Search,https://www.semanticscholar.org/paper/7904b3446775ed8c79f4f94001a16b706989c462,ACM Asia Conference on Computer and Communications Security,"['JournalArticle', 'Book', 'Conference']","In this paper, we propose GraphSE\textsuperscript2, an encrypted graph database for online social network services to address massive data breaches. GraphSE\textsuperscript2 ~preserves the functionality of social search, a key enabler for quality social network services, where social search queries are conducted on a large-scale social graph and meanwhile perform set and computational operations on user-generated contents. To enable efficient privacy-preserving social search, GraphSE\textsuperscript2 ~provides an encrypted structural data model to facilitate parallel and encrypted graph data access. It is also designed to decompose complex social search queries into atomic operations and realise them via interchangeable protocols in a fast and scalable manner. We build GraphSE\textsuperscript2 ~with various queries supported in the Facebook graph search engine and implement a full-fledged prototype. Extensive evaluations on Azure Cloud demonstrate that GraphSE\textsuperscript2 ~is practical for querying a social graph with a million of users.",2019,27,Proceedings of the 2019 ACM Asia Conference on Computer and Communications Security,,
Graph Database,33ce8103b129149eb78ca2fa48538e25c9242c08,Neo4j Graph Database Implementation for LinkedIn,https://www.semanticscholar.org/paper/33ce8103b129149eb78ca2fa48538e25c9242c08,International Journal of Scientific Research in Computer Science Engineering and Information Technology,,The presented article mainly circumspect the idea for the use and implementation of graph database in the most social media of today. Currently many companies are using neo4j graph database for their workouts for data management. We shall stick with social media for this particular paper. We have used neo4j graph database for maintaining data of LinkedIn user and pages in a very systematic manner. Facebook and Twitter do currently use graph databases so we thought of implementing the same for LinkedIn.,2020,3,"International Journal of Scientific Research in Computer Science, Engineering and Information Technology",,
Graph Database,a281d563261c738f13b9e58a525e7e265a619c93,Suitability of Graph Database Technology for the Analysis of Spatio-Temporal Data,https://www.semanticscholar.org/paper/a281d563261c738f13b9e58a525e7e265a619c93,Future Internet,['JournalArticle'],"Every day large quantities of spatio-temporal data are captured, whether by Web-based companies for social data mining or by other industries for a variety of applications ranging from disaster relief to marine data analysis. Making sense of all this data dramatically increases the need for intelligent backend systems to provide realtime query response times while scaling well (in terms of storage and performance) with increasing quantities of structured or semi-structured, multi-dimensional data. Currently, relational database solutions with spatial extensions such as PostGIS, seem to come to their limits. However, the use of graph database technology has been rising in popularity and has been found to handle graph-like spatio-temporal data much more effectively. Motivated by the need to effectively store multi-dimensional, interconnected data, this paper investigates whether or not graph database technology is better suited when compared to the extended relational approach. Three database technologies will be investigated using real world datasets namely: PostgreSQL, JanusGraph, and TigerGraph. The datasets used are the Yelp challenge dataset and an ambulance response simulation dataset, thus combining real world spatial data with realistic simulations offering more control over the dataset. Our extensive evaluation is based on how each database performs under practical data analysis scenarios similar to those found on enterprise level.",2020,5,Future Internet,12,78
Graph Database,ce54e3b89a2570035b70885e6901ad4c92ae41c9,Construction of power projects knowledge graph based on graph database Neo4j,https://www.semanticscholar.org/paper/ce54e3b89a2570035b70885e6901ad4c92ae41c9,"International Conference on Computer, Information and Telecommunication Systems","['JournalArticle', 'Conference']","In ""The Belt and Road"", China’s overseas power projects grow more and more, which is associated with a large number of dispersing project information. Construction of power project knowledge graph based on graph database Neo4j can facilitate the management of overseas power projects and to have an intuitive understanding of the relationships between projects for further overall planning. Meanwhile, enterprises can describe the spatial distribution characteristics of countries along the ""The Belt and Road"" according to the knowledge graph of overseas power projects, so as to understand the space and potential of future power investment development in different countries.",2020,5,"2020 International Conference on Computer, Information and Telecommunication Systems (CITS)",,1-4
Graph Database,b09139c153bac8893e8faea2b3a59159234caadc,A Graph Database Approach to Wireless IIoT Workcell Performance Evaluation,https://www.semanticscholar.org/paper/b09139c153bac8893e8faea2b3a59159234caadc,International Conference on Industrial Technology,"['JournalArticle', 'Conference']","The workcell is considered a main building block of various industrial settings. Hence, it is examined as a primary testing environment for studying wireless communication techniques in factory automation processes. A new testbed was recently designed and developed to facilitate such studies in workcells by replicating various data flows in an emulated production environment. In this paper, an approach to storing and analyzing network performance data from a manufacturing factory workcell is introduced. A robotic testbed was constructed using two collaborative grade robot arms, machine emulators, and wireless communication devices. A graph database approach was implemented to capture network and operational event data among the components within the testbed. A schema is proposed, developed, and elaborated; a database is then populated with events from the testbed, and the resulting graph is presented. Query commands are then presented as a means to examine and analyze network performance and relationships within the components of the network. Additionally, we demonstrate how to extract correlations between receive signal power and network delay within the testbed using the graph database query language. Finally, using the inherently interconnected nature of the graph database, we discuss applying the graph database approach toward examining more complex relationships between the wireless communications network and the operational system.",2020,5,2020 IEEE International Conference on Industrial Technology (ICIT),,251-258
Graph Database,957f5b1e7ca48891c2e279aefbfa0f04d989c21e,In-Depth Benchmarking of Graph Database Systems with the Linked Data Benchmark Council (LDBC) Social Network Benchmark (SNB),https://www.semanticscholar.org/paper/957f5b1e7ca48891c2e279aefbfa0f04d989c21e,arXiv.org,['JournalArticle'],"In this study, we present the first results of a complete implementation of the LDBC SNB benchmark -- interactive short, interactive complex, and business intelligence -- in two native graph database systems---Neo4j and TigerGraph. In addition to thoroughly evaluating the performance of all of the 46 queries in the benchmark on four scale factors -- SF-1, SF-10, SF-100, and SF-1000 -- and three computing architectures -- on premise and in the cloud -- we also measure the bulk loading time and storage size. Our results show that TigerGraph is consistently outperforming Neo4j on the majority of the queries---by two or more orders of magnitude (100X factor) on certain interactive complex and business intelligence queries. The gap increases with the size of the data since only TigerGraph is able to scale to SF-1000---Neo4j finishes only 12 of the 25 business intelligence queries in reasonable time. Nonetheless, Neo4j is generally faster at bulk loading graph data up to SF-100. A key to our study is the active involvement of the vendors in the tuning of their platforms. In order to encourage reproducibility, we make all the code, scripts, and configuration parameters publicly available online.",2019,13,ArXiv,abs/1907.07405,
Graph Database,ee6f23590783adec7cf6b2030c6a46f3117a708e,A semantic graph database for the interoperability of 3D GIS data,https://www.semanticscholar.org/paper/ee6f23590783adec7cf6b2030c6a46f3117a708e,Applied Geomatics,,,2020,14,Applied Geomatics,14,53 - 66
Graph Database,e248993daede136713e93929816df92b48ccddfb,Graph Database and Relational Database Performance Comparison on a Transportation Network,https://www.semanticscholar.org/paper/e248993daede136713e93929816df92b48ccddfb,ICACDS,['JournalArticle'],,2020,7,,,407-418
Graph Database,8ef0c1c2030aa265a4e7c836d080c2e2088efde6,(Graph Database: A Survey),https://www.semanticscholar.org/paper/8ef0c1c2030aa265a4e7c836d080c2e2088efde6,"2020 International Conference on Computer, Electrical & Communication Engineering (ICCECE)","['Conference', 'Review']","The advantages of Relational Database Management System (RDBMS) model and design methodology are being utilized by industry/institutions for any software design and implementation. The future of RDBMS certainly will be the Graph Databases with NoSql methodologies, which is emerging as beyond of relational model. In this paper, there is a need to highlight all the databases evolved after RDBMS. They couldn’t stay in market for so long period and survey has been made to highlight those databases after RDBMS. Relational Database Management System has certain advantages like (i) Storing in Tables, Column and Rows (ii) Data Storing in Normal Form (iii) Easy to use via SQL to retrieve information via complex join operators (iv) Maintainability via Reverse Engineering (v) Indexing and quick search. Due to these inherent features of RDBMS and SQL, it is necessary to explore and compare RDBMS with NoSQL methods to avoid complex join operation. Recently, numerous software industries and research institutions are trying their old RDBMS system to be re-engineered into some other architecture via nodes, edges and relationships where different type of information can be stored easily. So, it is a big challenges for any industry and institutions how quickly they can re-engineer their old RDBMS into Graph Databases which is also called now-a-days the future of databases. In this project, it is highlighted that the importance of the re-engineering work lies in three different directions such as (i) Comparison of RDBMS with GDBMS (Graph Database Management System) where face book, twitter, Amazon, Google are adopting (ii) Survey work of Graph Databases and (iii) Graph Database Models have increasingly become a topic of interest. The representation of data in the form of a graph lends itself well to structure a data with a schema. No standard system of query languages yet had been found to have been unique and stable for graph databases. Research and industry adoptions will determine the future direction of graph databases.(iv) Beyond RDBMS artifacts were established by industry and academics. It feeds a series of recycling collectives trying to eke out an existence of positive incentives and principles.",2020,7,"2020 International Conference on Computer, Electrical & Communication Engineering (ICCECE)",,1-8
Graph Database,834cdfca7cc041a6fa0db3da5493c6754bea845b,A Graph Database-Based Approach to Analyze Network Log Files,https://www.semanticscholar.org/paper/834cdfca7cc041a6fa0db3da5493c6754bea845b,International Conference on Network and System Security,"['JournalArticle', 'Review']",,2019,12,,,53-73
Graph Database,9712624bb61abb0da989514cae558cfab61bb9d2,Using Twitter Mentions and a Graph Database to Analyse Social Network Centrality,https://www.semanticscholar.org/paper/9712624bb61abb0da989514cae558cfab61bb9d2,2019 6th International Conference on Soft Computing & Machine Intelligence (ISCMI),['Conference'],"Social networks are one category of social media that facilitates the formation of communities, sharing of content, and meeting people. Twitter is a popular microblogging and social networking service. Social media marketers within business organisations, are interested in identifying popular social network users, known as influencers who can be targeted for purposes of word-of-mouth branding. For Twitter, influencers are those users who have many followers. Influencers are typically identified through graph mining of social networks data. This type of mining involves the analysis of links between the graph nodes which store data for social network members. Follows relationships are commonly used to analyse Twitter social networks. The purpose of this paper is to demonstrate how mentioned relationships in Twitter data can be used to create a social networks graph database. Centrality measures are then used to analyse the social networks. It is demonstrated that the analysis of social networks based on the mentioned relationships can provide more information about influencers compared to the analysis of social networks based on the follows relationships.",2019,10,2019 6th International Conference on Soft Computing & Machine Intelligence (ISCMI),,155-159
Graph Database,d0238f2fa88b0316ab862f843a5521eff0fd9bf5,Improving Performance using Relational and Graph Database,https://www.semanticscholar.org/paper/d0238f2fa88b0316ab862f843a5521eff0fd9bf5,International journal of recent technology and engineering,,"Paper Relational database model (also called SQL databases) are one of the prevalent databases that are used with structured data. Currently news demands are arising owing to the magnitude with which the internet and social networks are getting used which brought importance to graph-structured data. Graph database (a nosql database) deal more naturally with highly connected data and are thus becoming popular and efficient choice. Due to limitations faced by relational databases in handling relationships (highly connected data), enterprise information systems find graph database as a promising alternative. According to the form of queries and property of data both relational and graph databases have vitality and flaws. Since most of the data is available in relational schema in this context, the conversion of an application from a relational to a graph format is very beneficial. Thus, this paper develops a dual database system through migration, which unifies the strengths of both relational databases and graph databases. Experimental results have shown that, this hybrid system has efficient performance.",2019,4,International Journal of Recent Technology and Engineering,,
Graph Database,e7b0e2710821a9fe1e3d2b9a09dd94514b2d5ea5,Graph Database Solution for Higher-order Spatial Statistics in the Era of Big Data,https://www.semanticscholar.org/paper/e7b0e2710821a9fe1e3d2b9a09dd94514b2d5ea5,Astrophysical Journal Supplement Series,['Review'],"We present an algorithm for the fast computation of the general N-point spatial correlation functions of any discrete point set embedded within an Euclidean space of . Utilizing the concepts of kd-trees and graph databases, we describe how to count all possible N-tuples in binned configurations within a given length scale, e.g., all pairs of points or all triplets of points with side lengths < rMAX. Through benchmarking, we show the computational advantage of our new graph-based algorithm over more traditional methods. We show measurements of the three-point correlation function up to scales of ∼200 Mpc (beyond the baryon acoustic oscillation scale in physical units) using current Sloan Digital Sky Survey (SDSS) data. Finally, we present a preliminary exploration of the small-scale four-point correlation function of 568,776 SDSS Constant (stellar) Mass (CMASS) galaxies in the northern Galactic cap over the redshift range of 0.43 < z < 0.7. We present the publicly available code GRAMSCI (GRAph Made Statistics for Cosmological Information; bitbucket.org/csabiu/gramsci), under a Gnu is Not Unix (GNU) General Public License.",2019,20,The Astrophysical Journal Supplement Series,242,
Graph Database,dadfb3ff45e19dc22456a645f441bbeb17c93c9c,SeQuery: an interactive graph database for visualizing the GPCR superfamily,https://www.semanticscholar.org/paper/dadfb3ff45e19dc22456a645f441bbeb17c93c9c,Database J. Biol. Databases Curation,['JournalArticle'],"Abstract The rate at which new protein and gene sequences are being discovered has grown explosively in the omics era, which has increasingly complicated the efficient characterization and analysis of their biological properties. In this study, we propose a web-based graphical database tool, SeQuery, for intuitively visualizing proteome/genome networks by integrating the sequential, structural and functional information of sequences. As a demonstration of our tool’s effectiveness, we constructed a graph database of G protein-coupled receptor (GPCR) sequences by integrating data from the UniProt, GPCRdb and RCSB PDB databases. Our tool attempts to achieve two goals: (i) given the sequence of a query protein, correctly and efficiently identify whether the protein is a GPCR, and, if so, define its sequential and functional roles in the GPCR superfamily; and (ii) present a panoramic view of the GPCR superfamily and its network centralities that allows users to explore the superfamily at various resolutions. Such a bottom-up-to-top-down view can provide the users with a comprehensive understanding of the GPCR superfamily through interactive navigation of the graph database. A test of SeQuery with the GPCR2841 dataset shows that it correctly identifies 99 out of 100 queried protein sequences. The developed tool is readily applicable to other biological networks, and we aim to expand SeQuery by including additional biological databases in the near future.",2019,7,Database: The Journal of Biological Databases and Curation,2019,
Graph Database,537f5e8e4139392cd2d108f32495e5b2b80151ac,Implementation of a HL7-CQL Engine Using the Graph Database Neo4J,https://www.semanticscholar.org/paper/537f5e8e4139392cd2d108f32495e5b2b80151ac,"Jahrestagung der Deutschen Gesellschaft für Medizinische Informatik, Biometrie und Epidemiologie",['JournalArticle'],"The Clinical Quality Language (CQL) is a useful tool for defining search requests for data stores containing FHIR data. Unfortunately, there are only few execution engines that are able to evaluate CQL queries. As FHIR data represents a graph structure, the authors pursue the approach of storing all data contained in a FHIR server in the graph database Neo4J and to translate CQL queries into Neo4J's query language Cypher. The query results returned by the graph database are retranslated into their FHIR representation and returned to the querying user. The approach has been positively tested on publicly available FHIR servers with a handcrafted set of example CQL queries.",2019,5,Studies in health technology and informatics,267,"
          46-51
        "
Graph Database,a357f1ff27e184d9a5ef69e665e8ca891032bf71,A spatially-pruned vertex expansion operator in the Neo4j graph database system,https://www.semanticscholar.org/paper/a357f1ff27e184d9a5ef69e665e8ca891032bf71,GeoInformatica,['JournalArticle'],,2019,7,GeoInformatica,,1-27
Graph Database,45674df7143e43bc589cfabd26dd194c2a7f090d,Computational Modelling for Bankruptcy Prediction: Semantic Data Analysis Integrating Graph Database and Financial Ontology,https://www.semanticscholar.org/paper/45674df7143e43bc589cfabd26dd194c2a7f090d,Conference on Business Informatics,"['JournalArticle', 'Conference']","In this paper, we propose a novel intelligent methodology to construct a Bankruptcy Prediction Computation Model, which is aimed to execute a company's financial status analysis accurately. Based on the semantic data analysis and management, our methodology considers Semantic Database System as the core of the system. It comprises three layers: an Ontology of Bankruptcy Prediction, Semantic Search Engine, and a Semantic Analysis Graph Database system. The Ontological layer defines the basic concepts of the financial risk management as well as the objects that serve as sources of knowledge for predicting a company's bankruptcy. The Graph Database layer utilises a powerful semantic data technology, which serves as a semantic data repository for our model. The article provides a detailed description of the construction of the Ontology and its informal conceptual representation. We also present a working prototype of the Graph Database system, constructed using the Neo4j application, and show the connection between well-known financial ratios. We argue that this methodology which utilises state of the art semantic data management mechanisms enables data processing and relevant computations in a more efficient way than approaches using the traditional relational database. These give us solid grounds to build a system that is capable of tackling the data of any complexity level.",2019,8,2019 IEEE 21st Conference on Business Informatics (CBI),01,84-93
Graph Database,099043827df60225cf33c820052716cce64d49e9,A Review on Graph Database and its representation,https://www.semanticscholar.org/paper/099043827df60225cf33c820052716cce64d49e9,2019 International Conference on Recent Advances in Energy-efficient Computing and Communication (ICRAECC),"['Conference', 'Review']","Extensively, facts are represented characteristically as a table for the purpose of making it indexed with increased readability. Currently, the tendencies are altering as Graph databases are rapidly attaining popularity. Actually, it is appropiately termed as ""the outlook of DBMS"". The demonstration of facts within the procedure of a graph advances within the circumstances sound for the prearranged facts through a dynamic schema. This paper discusses the backbone of graph database as to why they are gaining much popularity in present situations illustrating the dissimilar types available and their distinction. Owing to the extensive usage of graph algorithms with models, neither a standardised system nor query language has been dispossessed with graph databases. Research and industry acceptance will regulate the upcoming course of graph databases. The authors have tried in representing the graph database with a real life scenario.",2019,7,2019 International Conference on Recent Advances in Energy-efficient Computing and Communication (ICRAECC),,1-5
Graph Database,5107c83173e43f51d1bdebf6cafda525a7c26bf0,Duplicate Management Using Graph Database Systems: A Case Study,https://www.semanticscholar.org/paper/5107c83173e43f51d1bdebf6cafda525a7c26bf0,Brazilian Symposium on Information Systems,"['Book', 'JournalArticle']","The presence of multiple representations of an object of information, referred to as duplicates, is a ubiquitous problem in information system databases. Besides corrupting analysis results, such inconsistencies may compromise the functionality of applications that need to correlate information from different sources, such as auditing and fraud detection systems. The traditional approach to this problem has two steps: first, duplicates are identified in a typically semi-automatic process and, then, each group of duplicates is fused into a single consolidated representation. However, this strategy may result in information loss if records have been erroneously classified as duplicates. This article presents a case study on a different approach, which consists of using graph database systems to model similarity relationships between data objects. In this way, possible duplicates can be dynamically identified using basic operations on graphs. The study was carried out within the scope of the Controladoria Geral do Estado de Goiás, as part of the development of an application to detect evidence of fraud in public bids. Initial results indicate that the proposed approach is effective and efficient in discovering links involving possible duplicates.",2019,8,Proceedings of the XV Brazilian Symposium on Information Systems,,
Graph Database,c2528e88d5554e9df9f9d482ad46cb5331c4d794,Benchmarking Graph Database Backends - What Works Well with Wikidata?,https://www.semanticscholar.org/paper/c2528e88d5554e9df9f9d482ad46cb5331c4d794,Acta Cybernetica,['JournalArticle'],"Knowledge bases often utilize graphs as logical model. RDF-based knowledge bases (KB) are prime examples, as RDF (Resource Description Framework) does use graph as logical model. Graph databases are an emerging breed of NoSQL-type databases, offering graph as the logical model. Although there are specialized databases, the so-called triple stores, for storing RDF data, graph databases can also be promising candidates for storing knowledge. In this paper, we benchmark different graph database implementations loaded with Wikidata, a real-life, large-scale knowledge base. Graph databases come in all shapes and sizes, offer different APIs and graph models. Hence we used a measurement system, that can abstract away the API differences. For the modeling aspect, we made measurements with different graph encodings previously suggested in the literature, in order to observe the impact of the encoding aspect on the overall performance. 
 ",2019,8,Acta Cybern.,24,43-60
Graph Database,a0367346bc355c36badec2d2c47ce55a320cd75e,The study on data migration from relational database to graph database,https://www.semanticscholar.org/paper/a0367346bc355c36badec2d2c47ce55a320cd75e,Journal of Physics: Conference Series,['Conference'],"Under the background of big data, using relational databases to manage massive data may have some problems just like storage capacity and query efficiency. So, there is a new kind of databases called NoSQL to store data. However, the data models of NoSQL databases are different from relation databases. In order to finish migrating historical data from relational databases to NoSQL databases, in terms of graph database in the NoSQL databases, this paper takes ER diagram as the original model, graph model as target, and makes some transformational rules by using the relationships of entities. And this paper proposes an algorithm which can finish data migration by traversing ER diagram and using the transformational rules. This method can reduce the impact of model differences between relational databases and graph databases, ensure the integrity constraint of data, and automatically complete data migration. The experimental results show the validity and correctness of the data migration.",2019,7,Journal of Physics: Conference Series,1345,
Graph Database,223187cf10a24b62b9b0cf5b146cc83526df2ea5,From DIKW pyramid to graph database: a tool for machine processing of nutritional epidemiologic research data,https://www.semanticscholar.org/paper/223187cf10a24b62b9b0cf5b146cc83526df2ea5,2019 IEEE International Conference on Big Data (Big Data),"['JournalArticle', 'Conference']","There is an increased interest in the application of information technology to advance nutritional research. In nutrition science, a graph database enables the creation of multilateral logic relationships throughout the database, which can be used to electronically store, visualize, and scale the outputs of nutritional research. It provides a knowledge structure to standardize nutritional research outputs, which is both human- and machine-readable in a Resource Description Framework format. However, the development of various specific graph databases may cause difficulties for data integration and decrease human-readability. In this article, we propose an approach to develop a graph database according to the Data, Information, Knowledge, and Wisdom or “DIKW” pyramid for nutritional epidemiologic data. Then, authoritative ontologies are suggested to construct the nodes and edges of the graph database to facilitate data integration. Finally, the findability and re-usability of the knowledge in the graph database are showcased using the SPARQL and SQWRL query languages.",2019,7,2019 IEEE International Conference on Big Data (Big Data),,5202-5205
Graph Database,f3b8a3ffa0bdfe5578e0f0f44ea3b66cad38c032,"Graph Database Approach for Data Storing, Presentation and Manipulation",https://www.semanticscholar.org/paper/f3b8a3ffa0bdfe5578e0f0f44ea3b66cad38c032,"International Convention on Information and Communication Technology, Electronics and Microelectronics",['JournalArticle'],"An increasing number of IoT systems and a generation of unstructured data make it difficult to choose and apply a suitable database model. Using a NoSQL database on a test data model shows the advantages of storing, manipulating, and presenting the required data. A test data model was created on a relational database and on a graph database to compare the options of manipulating and presenting the same data. A comparison of these two models was made on a small sample, and the results were displayed on the same query as the default for both types of databases. Simpler query syntax and better visualization of data are some of the benefits presented by this model on the graph database.",2019,6,"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)",,1548-1552
Graph Database,10b4b926904ad153f791ec680218e1610747a0c8,SQL Database with physical database tuning technique and NoSQL graph database comparisons,https://www.semanticscholar.org/paper/10b4b926904ad153f791ec680218e1610747a0c8,"2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",['Conference'],"Relational databases are used in many organizations of various natures from last three decades such as Education, health, businesses and in many other applications. SQL databases are designed to manage structured data and show tremendous performance. Atomicity, Consistency Isolation, Durability (ACID) property of Relational databases is used to manage data integrity and consistency. Physical database techniques are used to increase the performance of relational databases. Tablespaces also called subfolder is one of the physical database technique used by Oracle SQL database. Tablespaces are used to store the data logically in separate data files. Now-a-days huge amount and varied nature (unstructured and semi structured) of data is generated by the various organizations i.e., videos, images, blogs etc. This large amount of data is not handled by the SQL databases efficiently. NoSQL databases are used to process and analyze the large amount of data efficiently. Four different types of NoSQL databases are used in the industry according to the organization requirement. In this article, first, we do the physical database tuning of the Oracle Relational database and then compared with NoSQL Graph database. Relational database performance is increased up to 50% due to physical database tuning technique (Tablespaces). Besides, physical database tuning approach of relational database NoSQL graph database performed better in all our proposed scenarios.",2019,21,"2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)",,110-116
Graph Database,f295157f37cfb43cd8d8d2690ea124edc5ea59c2,Beyond Macrobenchmarks: Microbenchmark-based Graph Database Evaluation,https://www.semanticscholar.org/paper/f295157f37cfb43cd8d8d2690ea124edc5ea59c2,Proceedings of the VLDB Endowment,['JournalArticle'],"
 Despite the increasing interest in graph databases their requirements and specifications are not yet fully understood by everyone, leading to a great deal of variation in the supported functionalities and the achieved performances. In this work, we provide a comprehensive study of the existing graph database systems. We introduce a novel microbenchmarking framework that provides insights on their performance that go beyond what macro-benchmarks can offer. The framework includes the largest set of queries and operators so far considered. The graph database systems are evaluated on synthetic and real data, from different domains, and at scales much larger than any previous work. The framework is materialized as an open-source suite and is easily extended to new datasets, systems, and queries
 1
 .
",2018,47,Proc. VLDB Endow.,12,390-403
Graph Database,dcbaf58b16ac7ef947879ea37c021466357b291a,Use of Graph Database for the Integration of Heterogeneous Biological Data,https://www.semanticscholar.org/paper/dcbaf58b16ac7ef947879ea37c021466357b291a,Genomics & Informatics,['JournalArticle'],"Understanding complex relationships among heterogeneous biological data is one of the fundamental goals in biology. In most cases, diverse biological data are stored in relational databases, such as MySQL and Oracle, which store data in multiple tables and then infer relationships by multiple-join statements. Recently, a new type of database, called the graph-based database, was developed to natively represent various kinds of complex relationships, and it is widely used among computer science communities and IT industries. Here, we demonstrate the feasibility of using a graph-based database for complex biological relationships by comparing the performance between MySQL and Neo4j, one of the most widely used graph databases. We collected various biological data (protein-protein interaction, drug-target, gene-disease, etc.) from several existing sources, removed duplicate and redundant data, and finally constructed a graph database containing 114,550 nodes and 82,674,321 relationships. When we tested the query execution performance of MySQL versus Neo4j, we found that Neo4j outperformed MySQL in all cases. While Neo4j exhibited a very fast response for various queries, MySQL exhibited latent or unfinished responses for complex queries with multiple-join statements. These results show that using graph-based databases, such as Neo4j, is an efficient way to store complex biological relationships. Moreover, querying a graph database in diverse ways has the potential to reveal novel relationships among heterogeneous biological data.",2017,76,Genomics & Informatics,15,19 - 27
Graph Database,32c1e0f9ef6f1e337fe4aa2a4907314e5a3f4a5b,Graphflow: An Active Graph Database,https://www.semanticscholar.org/paper/32c1e0f9ef6f1e337fe4aa2a4907314e5a3f4a5b,SIGMOD Conference,"['Book', 'JournalArticle', 'Conference']","Many applications detect the emergence or deletion of certain subgraphs in their input graphs continuously. In order to evaluate such continuous subgraph queries, these applications resort to inefficient or highly specialized solutions because existing graph databases are passive systems that only support one-time subgraph queries. We demonstrate Graphflow, a prototype active graph data-base that evaluates general one-time and continuous subgraph queries. Graphflow supports the property graph data model and the Cypher++ query language, which extends Neo4j's declarative Cypher language with subgraph-condition-action triggers. At the core of Graphflow's query processor are two worst-case optimal join algorithms called Generic Join and our new Delta Generic Join algorithm for one-time and continuous subgraph queries, respectively.",2017,107,Proceedings of the 2017 ACM International Conference on Management of Data,,
Graph Database,1b0aa15937fdf59103a5213bccf09cff83d0ee3e,BioGraph: a web application and a graph database for querying and analyzing bioinformatics resources,https://www.semanticscholar.org/paper/1b0aa15937fdf59103a5213bccf09cff83d0ee3e,BMC Systems Biology,['JournalArticle'],,2018,26,BMC Systems Biology,12,
Graph Database,4cd033a56b19f87f6adfefeef5fcc990306ecf40,Neo4j graph database realizes efficient storage performance of oilfield ontology,https://www.semanticscholar.org/paper/4cd033a56b19f87f6adfefeef5fcc990306ecf40,PLoS ONE,['JournalArticle'],"The integration of oilfield multidisciplinary ontology is increasingly important for the growth of the Semantic Web. However, current methods encounter performance bottlenecks either in storing data and searching for information when processing large amounts of data. To overcome these challenges, we propose a domain-ontology process based on the Neo4j graph database. In this paper, we focus on data storage and information retrieval of oilfield ontology. We have designed mapping rules from ontology files to regulate the Neo4j database, which can greatly reduce the required storage space. A two-tier index architecture, including object and triad indexing, is used to keep loading times low and match with different patterns for accurate retrieval. Therefore, we propose a retrieval method based on this architecture. Based on our evaluation, the retrieval method can save 13.04% of the storage space and improve retrieval efficiency by more than 30 times compared with the methods of relational databases.",2018,34,PLoS ONE,13,
Graph Database,40416ac3bf78583eea37661b1b446e9939245b3e,A Survey on Graph Database Management Techniques for Huge Unstructured Data,https://www.semanticscholar.org/paper/40416ac3bf78583eea37661b1b446e9939245b3e,,['Review'],"Data analysis, data management, and big data play a major role in both social and business perspective, in the last decade. Nowadays, the graph database is the hottest and trending research topic. A graph database is preferred to deal with the dynamic and complex relationships in connected data and offer better results. Every data element is represented as a node. For example, in social media site, a person is represented as a node, and its properties name, age, likes, and dislikes, etc and the nodes are connected with the relationships via edges. Use of graph database is expected to be beneficial in business, and social networking sites that generate huge unstructured data as that Big Data requires proper and efficient computational techniques to handle with. This paper reviews the existing graph data computational techniques and the research work, to offer the future research line up in graph database management.",2018,27,International Journal of Electrical and Computer Engineering,8,1140-1149
Graph Database,9a0965beef113cc37491004b1848149e00300561,A Graph Database Model for Knowledge Extracted from Place Descriptions,https://www.semanticscholar.org/paper/9a0965beef113cc37491004b1848149e00300561,ISPRS Int. J. Geo Inf.,['JournalArticle'],"Everyday place descriptions provide a rich source of knowledge about places and their relative locations. This research proposes a place graph model for modelling this spatial, non-spatial, and contextual knowledge from place descriptions. The model extends a prior place graph, and overcomes a number of limitations. The model is implemented using a graph database, and a management system has also been developed that allows operations including querying, mapping, and visualizing the stored knowledge in an extended place graph. Then three experimental tasks, namely georeferencing, reasoning, and querying, are selected to demonstrate the superiority of the extended model.",2018,21,ISPRS Int. J. Geo Inf.,7,221
Graph Database,eef23d76e175c0cff8e81ffcb2721c10539c8cbd,CIM/E Oriented Graph Database Model Architecture and Parallel Network Topology Processing,https://www.semanticscholar.org/paper/eef23d76e175c0cff8e81ffcb2721c10539c8cbd,IEEE Power & Energy Society General Meeting,['JournalArticle'],"CIM/E is an easy and efficient electric power model exchange standard between different Energy Management System vendors. With the rapid growth of data size and system complexity, the traditional relational database is not the best option to store and process the data. In contrast, the graph database and graph computation show their potential advantages to handle the power system data and perform real-time data analytics and computation. The graph concept fits power grid data naturally because of the fundamental structure similarity. Vertex and edge in the graph database can act as both a parallel storage unit and a computation unit. In this paper, the CIM/E data is modeled into the graph database. Based on this model, the parallel network topology processing algorithm is established and conducted by applying graph computation. The modeling and parallel network topology processing have been demonstrated in the modified IEEE test cases and practical Sichuan power network. The processing efficiency is greatly improved using the proposed method.",2018,16,2018 IEEE Power & Energy Society General Meeting (PESGM),,1-5
Graph Database,6422f4b9e3bedf585170bffc7105ffe2061e87ae,Graph database-based network security situation awareness data storage method,https://www.semanticscholar.org/paper/6422f4b9e3bedf585170bffc7105ffe2061e87ae,EURASIP Journal on Wireless Communications and Networking,['JournalArticle'],,2018,15,EURASIP Journal on Wireless Communications and Networking,2018,
Graph Database,c84aa52bee5116f80c7740503edff4b08f733c3b,Migration of data from relational database to graph database,https://www.semanticscholar.org/paper/c84aa52bee5116f80c7740503edff4b08f733c3b,International Conference on Information and Software Technologies,,"Relational databases have been widely used in many applications until today and they have met needs for data-intensive domains and transactions, but today data is growing faster than ever and extracting information from this huge data is becoming more challenging. Growing size of data and number of connections between data items reduces performance because relational databases use many complex join operations to query and access data. As a solution, graph database store these connections between entities and provide traversing connections fast and easily and accessing data efficiently. This article reports on our experience of migration of document-based, parent-child hierarchical data from relational database to graph database. It also reports comparison of data access processes and performance between relational database and graph database.",2018,13,,,6
Graph Database,5f7f10f913ecc478ff7ba304c265fd3c700b47d7,Modeling Graph Database Schema,https://www.semanticscholar.org/paper/5f7f10f913ecc478ff7ba304c265fd3c700b47d7,IT Professional,['JournalArticle'],"The authors present a new method for creating a graph database schema (GDBS) based on an entity-relationship diagram (ERD) of the application domain, which is mapped to a GDBS in a two-step process. First, the original ERD is adjusted to a semantically equivalent ERD (enabling it to be mapped in step two). In the second step, the adjusted ERD is mapped to a GDBS according to specific rules. The resulting GDBS includes integrity constraints that enrich existing graph databases.",2017,35,IT Professional,19,34-43
Graph Database,ce3285bf1853f00c00535325851df5c33a0fc5d6,The Fragment Network: A Chemistry Recommendation Engine Built Using a Graph Database.,https://www.semanticscholar.org/paper/ce3285bf1853f00c00535325851df5c33a0fc5d6,Journal of Medicinal Chemistry,['JournalArticle'],"The hit validation stage of a fragment-based drug discovery campaign involves probing the SAR around one or more fragment hits. This often requires a search for similar compounds in a corporate collection or from commercial suppliers. The Fragment Network is a graph database that allows a user to efficiently search chemical space around a compound of interest. The result set is chemically intuitive, naturally grouped by substitution pattern and meaningfully sorted according to the number of observations of each transformation in medicinal chemistry databases. This paper describes the algorithms used to construct and search the Fragment Network and provides examples of how it may be used in a drug discovery context.",2017,29,Journal of medicinal chemistry,60 14,"
          6440-6450
        "
Graph Database,7c24234042988e2f820a4350f43422ed2ad6fc52,Graph Database,https://www.semanticscholar.org/paper/7c24234042988e2f820a4350f43422ed2ad6fc52,Encyclopedia of Database Systems,,,2018,49,,,
Graph Database,448959eff044f02040ded5afd483b7c4e811b0ac,Engineering Knowledge Graph from Patent Database,https://www.semanticscholar.org/paper/448959eff044f02040ded5afd483b7c4e811b0ac,Journal of Computing and Information Science in Engineering,['JournalArticle'],"
 We propose a large, scalable engineering knowledge graph, comprising sets of real-world engineering “facts” as < entity, relationship, entity > triples that are found in the patent database. We apply a set of rules based on the syntactic and lexical properties of claims in a patent document to extract facts. We aggregate these facts within each patent document and integrate the aggregated sets of facts across the patent database to obtain an engineering knowledge graph. Such a knowledge graph is expected to support inference, reasoning, and recalling in various engineering tasks. The knowledge graph has a greater size and coverage in comparison with the previously used knowledge graphs and semantic networks in the engineering literature.",2021,41,J. Comput. Inf. Sci. Eng.,22,
Graph Database,155eeede0c070f1f017ba5c9f6cacd7ae0b098aa,Efficient Authorization of Graph Database Queries in an Attribute-Supporting ReBAC Model,https://www.semanticscholar.org/paper/155eeede0c070f1f017ba5c9f6cacd7ae0b098aa,Conference on Data and Application Security and Privacy,"['JournalArticle', 'Book']","Neo4j is a popular graph database that offers two versions; a paid enterprise edition and a free community edition. The enterprise edition offers customizable Role-Based Access Control (RBAC) features through custom developed procedures, while the community edition does not offer any access control support. Being a graph database, Neo4j is a natural application for Relationship-Based Access Control (ReBAC), an access control paradigm where authorization decisions are based on relationships between subjects and resources in the system. In this paper we present AReBAC, an attribute-supporting ReBAC model for Neo4j (applicable to both editions) that provides finer grained access control. AReBAC employs Nano-Cypher, a declarative policy language based on Neo4j»s Cypher query language, the result of which allows us to weave database queries with access control policies and evaluate both simultaneously. Evaluating the combined query and policy produces a result that i) matches the search criteria, and ii) the requesting subject has access to. Our experiments show that our evaluation algorithm performs faster than Neo4j»s query evaluation engine when evaluating queries that are expressible using Nano-Cypher.",2018,8,Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy,,
Graph Database,31d7d7b9c7b776c639316027e6ae5f2ff2673da2,Fast Dual Simulation Processing of Graph Database Queries,https://www.semanticscholar.org/paper/31d7d7b9c7b776c639316027e6ae5f2ff2673da2,IEEE International Conference on Data Engineering,"['JournalArticle', 'Conference']","Graph database query languages feature expressive yet computationally expensive pattern matching capabilities. Answering optional query clauses in SPARQL for instance renders the query evaluation problem immediately PSPACE-complete. Light-weight graph pattern matching relations, such as simulation, have recently been investigated as promising alternatives to more expensive query mechanisms like, e.g., computing subgraph isomorphism. Still, pattern matching alone lacks expressive query capabilities: graph patterns may be combined by usual inner joins. However, including more sophisticated operators is inevitable to make solutions more useful for emerging applications. In this paper we bridge this gap by introducing a new dual simulation process operating on SPARQL queries. In addition to supporting the full syntactic structure of SPARQL queries, it features polynomial-time pattern matching to compute an overapproximation of the query results. Moreover, to achieve running times competing with state-of-the-art database systems, we develop a novel algorithmic solution to dual simulation graph pattern matching, based on a system of inequalities that allows for several optimization heuristics. Finally, we achieve soundness of our process for SPARQL queries including UNION, AND and OPTIONAL operators not restricted to well-designed patterns. Our experiments on synthetic and real-world graph data promise a clear gain for graph database systems when incorporating the new dual simulation techniques.",2018,8,2019 IEEE 35th International Conference on Data Engineering (ICDE),,244-255
Graph Database,dad8965c5a4c0a0ea1eb3837c6a9c3b42597c2ce,A SEMANTIC GRAPH DATABASE FOR BIM-GIS INTEGRATED INFORMATION MODEL FOR AN INTELLIGENT URBAN MOBILITY WEB APPLICATION,https://www.semanticscholar.org/paper/dad8965c5a4c0a0ea1eb3837c6a9c3b42597c2ce,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",,"Abstract. Over the recent years, the usage of semantic web technologies and Resources Description Framework (RDF) data models have been notably increased in many fields. Multiple systems are using RDF data to describe information resources and semantic associations. RDF data plays a very important role in advanced information retrieval, and graphs are efficient ways to visualize and represent real world data by providing solutions to many real-time scenarios that can be simulated and implemented using graph databases, and efficiently query graphs with multiple attributes representing different domains of knowledge. Given that graph databases are schema less with efficient storage for semi-structured data, they can provide fast and deep traversals instead of slow RDBMS SQL based joins allowing Atomicity, Consistency, Isolation and durability (ACID) transactions with rollback support, and by utilizing mathematics of graph they can enormous potential for fast data extraction and storage of information in the form of nodes and relationships. In this paper, we are presenting an architectural design with complete implementation of BIM-GIS integrated RDF graph database. The proposed integration approach is composed of four main phases: ontological BIM and GIS model’s construction, mapping and semantic integration using interoperable data formats, then an import into a graph database with querying and filtering capabilities. The workflows and transformations of IFC and CityGML schemas into object graph databases model are developed and applied to an intelligent urban mobility web application on a game engine platform validate the integration methodology.
",2018,34,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",,
Graph Database,5778e56400f7113c2b1355fdbd6b638fa379885f,Relational database and graph database: A comparative analysis,https://www.semanticscholar.org/paper/5778e56400f7113c2b1355fdbd6b638fa379885f,,,": Since 1970, relational database models have been in use for storing, manipulating and retrieving data. The importance of relational databases is going to decrease due to the exponential growth of data as it is difficult to work with large number of joining tables. For such kinds of problems, one of the best solutions is to use graph database for storing data. The graph database can be used to store highly connected data. In this article, we are going to put forward a comparison between relational database and graph database with reference to an experiment performed.",2017,21,Journal of Process Management. New Technologies,5,1-9
Graph Database,746a81aa26d3ebfb81acfd6af958d6a21603cd21,Design and Implementation of Movie Recommender System Based on Graph Database,https://www.semanticscholar.org/paper/746a81aa26d3ebfb81acfd6af958d6a21603cd21,Web Information System and Application Conference,"['JournalArticle', 'Conference']","with the continuous development of Internet technology, information overload is becoming more and more serious. It's getting harder to get useful information from the network. Although the search engine can help users find information they need from the vast amounts of information in a certain extent, but cannot completely solve the problem of information overload, when users cannot accurately describe the information they need, you need to recommend system to help users find valuable information for users. So recommender systems are becoming more and more important. The movie recommender system implemented in this paper is based on the traditional user-based collaborative filtering algorithm, and the user project scoring matrix is pre filled. At the same time, database technology of this system uses graph database which is good at dealing with complex relations. In data visualization, the degree of recommendation of a movie is expressed by the size of the node and the thickness of the edge, so as to improve the user experience.",2017,17,2017 14th Web Information Systems and Applications Conference (WISA),,132-135
Graph Database,c6879e43828b293567f5e2da039d23845189d6a7,"Managing Cyber Threat Intelligence in a Graph Database: Methods of Analyzing Intrusion Sets, Threat Actors, and Campaigns",https://www.semanticscholar.org/paper/c6879e43828b293567f5e2da039d23845189d6a7,International Conference on Platform Technology and Service,['Conference'],"Efforts to cope jointly with the ever-increasing number of breach incidents have resulted in the establishment of the standard format and protocol and given birth to many consultative groups. In addition, various channels that distribute Cyber Threat Intelligence information free of charge have emerged, and studies on utilizing such channels have spread. As the market for sharing information professionally is expanding, the need to manage the shared information in various ways in order to achieve better result has arisen. This paper proposes a standardized management structure and method based on the standardized format and a meaning and standard of Cyber Threat Intelligence that can be shared outside when loading OSINT information collected from various channels into the graph database. This paper also proposes a method of supporting the detection provided by existing security equipment with the information saved in the graph database and an effective method of analysis. Lastly, the paper discusses the advantages that can be expected from saving cyber threat information in the graph database developed using information collected from the outside.",2018,9,2018 International Conference on Platform Technology and Service (PlatCon),,1-6
Graph Database,d9d325ca670a1aa215e3e39023f8abf17dae7584,Smart Application Development for IoT Asset Management Using Graph Database Modeling and High-Availability Web Services,https://www.semanticscholar.org/paper/d9d325ca670a1aa215e3e39023f8abf17dae7584,Hawaii International Conference on System Sciences,['JournalArticle'],"The rapid transition from purely physical or purely virtual systems, as we know them, to increasingly interconnected cyber-physical systems with high integration of the Internet-of-Things demands a paradigm shift in the development of information systems–smart applications–for the planning and operation of these systems. To address the demand of managing the integration of connected devices and enabling new business models from the heavily interconnected systems, current architectural reference models were considered and components of each synthesized into a proposed software stack for smart application development. This work lends its implementation approach to the utility of graph theory in modeling complex systems, and implements a graph database for managing and maintaining connected components that emphasize each component’s virtual and physical connectivity, technical functionalities, and state. The graph database microservice is then integrated with a highly available web framework and communication broker service in a multi-layered software framework to integrate Internet-of-Things devices and make services available over the web. The framework’s–and respective components’–feasibility and utility is demonstrated through a use case for modeling, connecting, and controlling interconnected homes in a modern smart grid, and abstracting transactional device data for new business models, such as demand response ancillary services.",2018,10,,,1-10
Graph Database,f4207bcad24fe4eaf3849d6c1fe38c36545b5cb3,A BFS-Based Pruning Algorithm for Disease-Symptom Knowledge Graph Database,https://www.semanticscholar.org/paper/f4207bcad24fe4eaf3849d6c1fe38c36545b5cb3,Information and Communication Technology for Intelligent Systems,,,2018,6,Information and Communication Technology for Intelligent Systems,,
Graph Database,e5a1cfcd07dcfd8b1feec9c635dadc858cde8166,A Common Information Model Oriented Graph Database Framework for Power Systems,https://www.semanticscholar.org/paper/e5a1cfcd07dcfd8b1feec9c635dadc858cde8166,IEEE Transactions on Power Systems,,"Common Information Model (CIM) is widely adopted by many utilities since it offers interoperability through standard information models. Storing, processing, retrieving, and providing concurrent access of the large power network models to the various power system applications in CIM framework are the current challenges faced by utility operators. As the power network models resemble largely connected-data sets, the design of CIM oriented database has to support high-speed data retrieval of the connected-data and efficient storage for processing. The graph database is gaining wide acceptance for storing and processing of largely connected-data for various applications. This paper presents a design of CIM oriented graph database (CIMGDB) for storing and processing the largely connected-data of power system applications. Three significant advantages of the CIMGDB are efficient data retrieval and storage, agility to adapt dynamic changes in CIM profile, and greater flexibility of modeling CIM unified modeling language (UML) in GDB. The CIMGDB does not need a predefined database schema. Therefore, the CIM semantics needs to be added to the artifacts of GDB for every instance of CIM objects storage. A CIM based object-graph mapping methodology is proposed to automate the process. An integration of CIMGDB and power system applications is discussed by an implementation architecture. The data-intensive network topology processing (NTP) is implemented, and demonstrated for six IEEE test networks and one practical 400 kV Maharashtra network. Results such as computation time of executing network topology processing evaluate the performance of the CIMGDB.",2017,20,IEEE Transactions on Power Systems,32,2560-2569
Graph Database,e89c37b7c2ff465db43c4b9f674867ec4b98aa8b,EpiGeNet: A Graph Database of Interdependencies Between Genetic and Epigenetic Events in Colorectal Cancer,https://www.semanticscholar.org/paper/e89c37b7c2ff465db43c4b9f674867ec4b98aa8b,J. Comput. Biol.,['JournalArticle'],"The development of colorectal cancer (CRC)-the third most common cancer type-has been associated with deregulations of cellular mechanisms stimulated by both genetic and epigenetic events. StatEpigen is a manually curated and annotated database, containing information on interdependencies between genetic and epigenetic signals, and specialized currently for CRC research. Although StatEpigen provides a well-developed graphical user interface for information retrieval, advanced queries involving associations between multiple concepts can benefit from more detailed graph representation of the integrated data. This can be achieved by using a graph database (NoSQL) approach. Data were extracted from StatEpigen and imported to our newly developed EpiGeNet, a graph database for storage and querying of conditional relationships between molecular (genetic and epigenetic) events observed at different stages of colorectal oncogenesis. We illustrate the enhanced capability of EpiGeNet for exploration of different queries related to colorectal tumor progression; specifically, we demonstrate the query process for (i) stage-specific molecular events, (ii) most frequently observed genetic and epigenetic interdependencies in colon adenoma, and (iii) paths connecting key genes reported in CRC and associated events. The EpiGeNet framework offers improved capability for management and visualization of data on molecular events specific to CRC initiation and progression.",2017,19,Journal of computational biology : a journal of computational molecular cell biology,24 10,"
          969-980
        "
Graph Database,9ce948246c918e2c1846c3fc76d3e1c9ab1b0c2a,Graph Database for Recipe Recommendations,https://www.semanticscholar.org/paper/9ce948246c918e2c1846c3fc76d3e1c9ab1b0c2a,"2018 7th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",['Conference'],"Graph databases represent a paradigm shift from relational databases with a strong support for “ relationships”. As compared to relational databases which compute relationships at runtime, graph databases persist relationships for fast querying and data retrieval. This work presents a recipe recommender as a graph database, Neo4j application. Given any set of ingredients, this application recommends a variety of recipes with the help of a data set containing thousands of ingredients. Further based on availability of ingredients with a user, this application helps discover the list of possible dishes with these ingredients. In order to implement this application, ingredients and recipes have been crawled from cookery based websites using Python scripts. The crawled data has been inserted into the Neo4j database and subsequently inter-relationships between ingredients and recipes nodes have been analyzed. Execution of self designed queries has verified the time-efficiency of the proposed approach.",2018,4,"2018 7th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",,1-6
Graph Database,ce51eff5b529ee572dab1c1f38f20adc8e89bab2,System G Distributed Graph Database,https://www.semanticscholar.org/paper/ce51eff5b529ee572dab1c1f38f20adc8e89bab2,arXiv.org,['JournalArticle'],"Motivated by the need to extract knowledge and value frominterconnected data, graph analytics on big data is a veryactive area of research in both industry and academia. Tosupport graph analytics efficiently a large number of in mem-ory graph libraries, graph processing systems and graphdatabases have emerged. Projects in each of these cate-gories focus on particular aspects such as static versus dy-namic graphs, off line versus on line processing, small versuslarge graphs, etc.While there has been much advance in graph processingin the past decades, there is still a need for a fast graph pro-cessing, using a cluster of machines with distributed storage.In this paper, we discuss a novel distributed graph databasecalled System G designed for efficient graph data storage andprocessing on modern computing architectures. In particu-lar we describe a single node graph database and a runtimeand communication layer that allows us to compose a dis-tributed graph database from multiple single node instances.From various industry requirements, we find that fast inser-tions and large volume concurrent queries are critical partsof the graph databases and we optimize our database forsuch features. We experimentally show the efficiency ofSystem G for storing data and processing graph queries onstate-of-the-art platforms.",2018,4,ArXiv,abs/1802.03057,
Graph Database,bbb52447f2f38aad9613ba026f88b57637ffcbea,Towards FAIRer Biological Knowledge Networks Using a Hybrid Linked Data and Graph Database Approach,https://www.semanticscholar.org/paper/bbb52447f2f38aad9613ba026f88b57637ffcbea,Journal of Integrative Bioinformatics,['JournalArticle'],"Abstract The speed and accuracy of new scientific discoveries – be it by humans or artificial intelligence – depends on the quality of the underlying data and on the technology to connect, search and share the data efficiently. In recent years, we have seen the rise of graph databases and semi-formal data models such as knowledge graphs to facilitate software approaches to scientific discovery. These approaches extend work based on formalised models, such as the Semantic Web. In this paper, we present our developments to connect, search and share data about genome-scale knowledge networks (GSKN). We have developed a simple application ontology based on OWL/RDF with mappings to standard schemas. We are employing the ontology to power data access services like resolvable URIs, SPARQL endpoints, JSON-LD web APIs and Neo4j-based knowledge graphs. We demonstrate how the proposed ontology and graph databases considerably improve search and access to interoperable and reusable biological knowledge (i.e. the FAIRness data principles).",2018,20,Journal of Integrative Bioinformatics,15,
Graph Database,cf523942d56e90db182c5788845f6502da9a307d,3D Mapping Database Aided GNSS Based Collaborative Positioning Using Factor Graph Optimization,https://www.semanticscholar.org/paper/cf523942d56e90db182c5788845f6502da9a307d,IEEE transactions on intelligent transportation systems (Print),['JournalArticle'],"The recent development in vehicle-to-everything (V2X) communication opens a new opportunity to improve the positioning performance of the road users. We explore the benefit of connecting the raw data of the global navigation satellite system (GNSS) from the agents. In urban areas, GNSS positioning is highly degraded due to signal blockage and reflection. 3D building model can play a major role in mitigating the GNSS multipath and non-line-of-sight (NLOS) effects. To combine the benefits of 3D models and V2X, we propose a novel 3D mapping aided (3DMA) GNSS-based collaborative positioning method that makes use of the available surrounding GNSS receivers’ measurements. By complementarily integrating the ray-tracing based 3DMA GNSS and the double difference technique, the random errors (such as multipath and NLOS) are mitigated while eliminating the systematic errors (such as atmospheric delay and satellite clock/orbit biases) between road user. To improve the accuracy and robustness of the collaborative algorithm, factor graph optimization (FGO) is employed to optimize the positioning solutions among agents. Multiple low-cost GNSS receivers are used to collect both static and dynamic data in Hong Kong and to evaluate the proposed algorithm by post-processing. We reduce the GNSS positioning error from over 30 meters to less than 10 meters for road users in a deep urban canyon.",2021,26,IEEE Transactions on Intelligent Transportation Systems,22,6175-6187
Graph Database,2396dbcfe1f7f9dafc6696c3c06b16fd3029f7a0,Topology Modeling and Analysis of a Power Grid Network Using a Graph Database,https://www.semanticscholar.org/paper/2396dbcfe1f7f9dafc6696c3c06b16fd3029f7a0,International Journal of Computational Intelligence Systems,['JournalArticle'],"We introduce a new method for storing, modeling, and analyzing power grid data. First, we present an architecture for building the network model for a power grid using the open source graph database Neo4j. Second, we design singleand multi-threading systems for initial energization analysis of the power grid network. We design the shortest path search function and conditional search function based on Neo4j. Finally, we compare the functionality and efficiency of our graph database with a traditional relational database in system initial energization analysis and the shortest path function problems on small to large data sets. The results demonstrate the efficiency and effectiveness of topology modeling and analysis using graph database for a power grid network.",2017,14,Int. J. Comput. Intell. Syst.,10,1355-1363
Graph Database,fb8e253b8b0358a7b95ddc9ac4c74f93513a9c53,GeaBase: A High-Performance Distributed Graph Database for Industry-Scale Applications,https://www.semanticscholar.org/paper/fb8e253b8b0358a7b95ddc9ac4c74f93513a9c53,International Conference on Advanced Cloud and Big Data,"['JournalArticle', 'Conference']","Graph analytics have been gaining tractions rapidly in the past few years. It has a wide array of application areas in the industry, ranging from e-commerce, social network and recommendation systems to fraud detection and virtually any problem that requires insights into data connections, not just data itself. In this paper, we present GeaBase, a new distributed graph database that provides the capability to store and analyze graph-structured data in real-time at massive scale. We describe the details of the system and the implementation, including a novel update architecture, called Update Center (UC), and a new language that is suitable for both graph traversal and analytics. We also compare the performance of GeaBase to a widely used open-source graph database Titan. Experiments show that GeaBase is up to 182x faster than Titan in our testing scenarios. We also achieves 22x higher throughput on social network workloads in the comparison.",2017,12,2017 Fifth International Conference on Advanced Cloud and Big Data (CBD),,170-175
Graph Database,3dd7f7118ee174265889d00d100cfe2a02871be8,Pheno4J: a gene to phenotype graph database,https://www.semanticscholar.org/paper/3dd7f7118ee174265889d00d100cfe2a02871be8,bioRxiv,['JournalArticle'],"Summary Efficient storage and querying of large amounts of genetic and phenotypic data is crucial to contemporary clinical genetic research. This introduces computational challenges for classical relational databases, due to the sparsity and sheer volume of the data. Our Java based solution loads annotated genetic variants and well phenotyped patients into a graph database to allow fast efficient storage and querying of large volumes of structured genetic and phenotypic data. This abstracts technical problems away and lets researchers focus on the science rather than the implementation. We have also developed an accompanying webserver with end-points to facilitate querying of the database. Availability and Implementation The Java code and python code is available at https://github.com/phenopolis/pheno4i Contact n.pontikos@ucl.ac.uk",2017,9,bioRxiv,,
Graph Database,332e0eab5fba8e6940f3e481f542a99ac17b9717,Graph Database: A Complete GDBMS Survey,https://www.semanticscholar.org/paper/332e0eab5fba8e6940f3e481f542a99ac17b9717,,['Review'],"In the time of enormous information, information examination, business knowledge database administration assumes an imperative part from specialized business administration and exploration perspective. Over numerous decades, database administration has been a subject of dynamic examination. There are distinctive kind of database administration framework have been proposed over a time frame yet Relational Database Management System (RDBMS) is the one which has been most prevalently utilized as a part of scholastic examination and technical setup. As of late, Graphs databases recovered enthusiasm among the analysts for certain conspicuous reasons. A standout amongst the most critical explanations behind such an enthusiasm for a graph database is a result of the inalienable property of charts as a Graphs structure. Charts are available all around in the information structure, which speaks to the solid availability inside the information. The vast majority of the Graph database models are characterized in which information structure for graph and occasions are displayed as graph or speculation of a graph. In such graph database models, information controls are communicated by chart arranged operations and sort constructors. Presently days, the vast majority of this present reality applications can be demonstrated as a graph and one of the best genuine illustrations is social or organic system. This paper gives an outline of the diverse sort of graph databases, applications, and correlation between their models in view of a few properties.",2017,9,,,
Graph Database,7676c02ea839ff1ceb6e5e1427c42bc45e169bde,The Spatio-Temporal Data Modeling and Application Based on Graph Database,https://www.semanticscholar.org/paper/7676c02ea839ff1ceb6e5e1427c42bc45e169bde,International Conference on Information Science and Control Engineering,['Conference'],"Traditional spatio-temporal data model (STDM) is based on relational database, it is hard to convert problem domain model to relational model, which result in complicated query and low expansibility. In this regard, we propose the spatio-temporal data model based on graph database. The data model integrates TGIS's three key elements: space, time and attributes, and expressed spatio-temporal characteristics of TGIS explicitly. Finally, this paper gives a particular description of logistics distribution route optimization. Experimental results show that the model is proved to be appropriate for expressing the spatio-temporal process of world.",2017,8,2017 4th International Conference on Information Science and Control Engineering (ICISCE),,741-746
Graph Database,4875aa46599dc2d7e8292fc563347cf78fa12c8d,ChronoGraph: A Versioned TinkerPop Graph Database,https://www.semanticscholar.org/paper/4875aa46599dc2d7e8292fc563347cf78fa12c8d,International Conference on Data Technologies and Applications,['JournalArticle'],,2017,8,,,237-260
Graph Database,704011527f183b561ea6a75b21e4cefe5aa77fca,Book recommendation using Neo4j graph database in BibTeX book metadata,https://www.semanticscholar.org/paper/704011527f183b561ea6a75b21e4cefe5aa77fca,International Conference on Science in Information Technology,['Conference'],"In digital era, book has an important role in life. There are not only a lot of books for different purpose. But also, there are many book metadata which can use for another reason, such as book recommendation. By processing the book metadata, an information can be given to user that needs book recommendation. By combining BibTeX book metadata and Graph Database from Neo4j, data from metadata can be processed. Then, with cypher query by inputting author's parameter or book type's parameter, user can get book recommendation based on their input's criteria. The result is exactly the same with process the metadata manually in relational database. Neo4j, from this paper, takes 180 milliseconds to execute cypher query with author's criteria and takes 184 milliseconds to execute cypher query with book type's criteria.",2017,11,2017 3rd International Conference on Science in Information Technology (ICSITech),,47-52
Graph Database,d93bcf0685c15c45d078eafea565969c04daccd3,Goods recommendation based on retail knowledge in a Neo4j graph database combined with an inference mechanism implemented in jess,https://www.semanticscholar.org/paper/d93bcf0685c15c45d078eafea565969c04daccd3,"2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",['JournalArticle'],"Along with the extensive use of ontologies as a well-established means for knowledge representation, there is a pressing need for methods that can transform ontology information into knowledge stored in a Graph Database (GDB) which is considered human-like thinking in terms of objects and their relations. In this paper, we describe a two-layer knowledge graph database: a concept layer and an instance layer. The concept layer is the resulting graph representation transferred from an ontology representation. The instance layer is the instance data associated with concept nodes. In this research, we apply the two-layer approach to a retail business transaction data for business information query and reasoning. The two-layer structure is implemented in Neo4j GDB platform and information query and recommendation is implemented with a Jess reasoning engine. The query and recommendation results are represented and visualized in knowledge graph structures. The performance of the system is evaluated in terms of the time efficiency of answering queries of retail data using the GDB and the novelty of recommendations.",2017,11,"2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",,1-8
Graph Database,b889b1d6944213bc2ca29e3ad07ee65ede20892d,An X10-Based Distributed Streaming Graph Database Engine,https://www.semanticscholar.org/paper/b889b1d6944213bc2ca29e3ad07ee65ede20892d,International Conference on High Performance Computing,"['JournalArticle', 'Conference']","Streaming graph data mining has become a significant issue in high performance graph mining due to the increasing appearance of graph data sets as streams. In this paper we propose Acacia-Stream which is a scalable distributed streaming graph database engine developed with X10 programming language. Graph streams are partitioned using a streaming graph partitioner algorithm in Acacia-Stream and streaming graph processing queries are run on the graph streams. The partitioned data sets are persisted on secondary storage across X10 places. We investigate on the use of three different streaming graph partitioner algorithms called hash, Linear Deterministic Greedy, and Fennel algorithms and report their performance. Furthermore, to demonstrate Acacia-Stream's streaming graph processing capabilities we implement streaming triangle counting with Acacia-Stream. We present performance results gathered from Acacia-Stream with different large scale streaming data sets in both horizontal and vertical scalability experiments. Furthermore, we compare streaming graph loading performance of Acacia-Stream with Neo4j and Oracle's PGX graph database servers. From these experiments we observed that Acacia-Stream's Fennel partitioner based graph uploader can upload a 948MB rmat22 graph in 1283.42 seconds which is 38% faster than PGX graph database server and 12.8 times faster than Neo4j database server. Acacia-Stream's Streaming Partitioner's batch size adjustments based optimizations reduced the time used by the network communications almost by half.",2017,4,2017 IEEE 24th International Conference on High Performance Computing (HiPC),,243-252
Graph Database,78b2d392ebb100a220ceab6529d26909b27eaa32,"From Relational Database to Big Data: Converting Relational to Graph Database, MOOC Database as Example",https://www.semanticscholar.org/paper/78b2d392ebb100a220ceab6529d26909b27eaa32,J. Ubiquitous Syst. Pervasive Networks,['JournalArticle'],"Existing graph database management systems provide an efficient solution to data storage where graph models are widely used, the conversion of an existing application from a relational to graph data can be convenient but it is usually a hard task for database administrators. In this work, we propose a conversion tool from a relational to graph database. The approach supports the conversion of the schema and the data.",2017,5,J. Ubiquitous Syst. Pervasive Networks,8,15-20
Graph Database,37b9478b792fb1e7ad5f2c322ed4445b93df6c9e,The Graph Database: Jack of All Trades or Just Not SQL?,https://www.semanticscholar.org/paper/37b9478b792fb1e7ad5f2c322ed4445b93df6c9e,IT Professional Magazine,"['JournalArticle', 'Review']","This special issue of IT Professional focuses on the graph database. The graph database, a relatively new phenomenon, is well suited to the burgeoning information era in which we are increasingly becoming immersed. Here, the guest editors briefly explain how a graph database works, its relation to the relational database management system (RDBMS), and its quantitative and qualitative pros and cons, including how graph databases can be harnessed in a hybrid environment. They also survey the excellent articles submitted for this special issue.",2017,3,IT Prof.,19,21-25
Graph Database,41d6b6bd4bf44bf13b9157b603e33360e5e77a01,Semantic 3D City Database — An enabler for a dynamic geospatial knowledge graph,https://www.semanticscholar.org/paper/41d6b6bd4bf44bf13b9157b603e33360e5e77a01,,,,2021,26,,6,100106
Graph Database,621c2624fed596cec0fdefedd55c70e403521508,Spatio-Semantic Comparison of Large 3D City Models in CityGML Using a Graph Database,https://www.semanticscholar.org/paper/621c2624fed596cec0fdefedd55c70e403521508,,['Review'],"Abstract. A city may have multiple CityGML documents recorded at different times or surveyed by different users. To analyse the city’s evolution over a given period of time, as well as to update or edit the city model without negating modifications made by other users, it is of utmost importance to first compare, detect and locate spatio-semantic changes between CityGML datasets. This is however difficult due to the fact that CityGML elements belong to a complex hierarchical structure containing multi-level deep associations, which can basically be considered as a graph. Moreover, CityGML allows multiple syntactic ways to define an object leading to syntactic ambiguities in the exchange format. Furthermore, CityGML is capable of including not only 3D urban objects’ graphical appearances but also their semantic properties. Since to date, no known algorithm is capable of detecting spatio-semantic changes in CityGML documents, a frequent approach is to replace the older models completely with the newer ones, which not only costs computational resources, but also loses track of collaborative and chronological changes. Thus, this research proposes an approach capable of comparing two arbitrarily large-sized CityGML documents on both semantic and geometric level. Detected deviations are then attached to their respective sources and can easily be retrieved on demand. As a result, updating a 3D city model using this approach is much more efficient as only real changes are committed. To achieve this, the research employs a graph database as the main data structure for storing and processing CityGML datasets in three major steps: mapping, matching and updating. The mapping process transforms input CityGML documents into respective graph representations. The matching process compares these graphs and attaches edit operations on the fly. Found changes can then be executed using the Web Feature Service (WFS), the standard interface for updating geographical features across the web.",2017,15,"ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences",,99-106
